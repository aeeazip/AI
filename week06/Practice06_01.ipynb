{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNneDIvC5f+2ZOXLXGo31My"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OH3RwNeo6Z0U","outputId":"bb59c7d8-4579-4ba7-f3a6-6fb7a21f5d93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Epoch 1/100\n","47/47 [==============================] - 1s 2ms/step - loss: 30.0154 - accuracy: 0.1957\n","Epoch 2/100\n","47/47 [==============================] - 0s 2ms/step - loss: 1.5747 - accuracy: 0.8383\n","Epoch 3/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.9119 - accuracy: 0.7106\n","Epoch 4/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.7387 - accuracy: 0.7872\n","Epoch 5/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.8000\n","Epoch 6/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.8191\n","Epoch 7/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.8511\n","Epoch 8/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8404\n","Epoch 9/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8511\n","Epoch 10/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8532\n","Epoch 11/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8489\n","Epoch 12/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8532\n","Epoch 13/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8489\n","Epoch 14/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8298\n","Epoch 15/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.8170\n","Epoch 16/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8511\n","Epoch 17/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8447\n","Epoch 18/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8468\n","Epoch 19/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.8426\n","Epoch 20/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8532\n","Epoch 21/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.8447\n","Epoch 22/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8553\n","Epoch 23/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8511\n","Epoch 24/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8383\n","Epoch 25/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.8511\n","Epoch 26/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.8511\n","Epoch 27/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8298\n","Epoch 28/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8489\n","Epoch 29/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8532\n","Epoch 30/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8532\n","Epoch 31/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8489\n","Epoch 32/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8532\n","Epoch 33/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8383\n","Epoch 34/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8511\n","Epoch 35/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8468\n","Epoch 36/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.8468\n","Epoch 37/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8383\n","Epoch 38/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.8489\n","Epoch 39/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8511\n","Epoch 40/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8511\n","Epoch 41/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8468\n","Epoch 42/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.8234\n","Epoch 43/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8511\n","Epoch 44/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8447\n","Epoch 45/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8511\n","Epoch 46/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8511\n","Epoch 47/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8170\n","Epoch 48/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8447\n","Epoch 49/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8468\n","Epoch 50/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8447\n","Epoch 51/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8468\n","Epoch 52/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8532\n","Epoch 53/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8468\n","Epoch 54/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8489\n","Epoch 55/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8426\n","Epoch 56/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8489\n","Epoch 57/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8447\n","Epoch 58/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8489\n","Epoch 59/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8489\n","Epoch 60/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8574\n","Epoch 61/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8574\n","Epoch 62/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8468\n","Epoch 63/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8511\n","Epoch 64/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8383\n","Epoch 65/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8553\n","Epoch 66/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8298\n","Epoch 67/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8489\n","Epoch 68/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8617\n","Epoch 69/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8383\n","Epoch 70/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8447\n","Epoch 71/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8511\n","Epoch 72/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8383\n","Epoch 73/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8489\n","Epoch 74/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8489\n","Epoch 75/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8468\n","Epoch 76/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8468\n","Epoch 77/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8383\n","Epoch 78/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8532\n","Epoch 79/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8340\n","Epoch 80/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8511\n","Epoch 81/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8383\n","Epoch 82/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8532\n","Epoch 83/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8511\n","Epoch 84/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8362\n","Epoch 85/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8468\n","Epoch 86/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8489\n","Epoch 87/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8383\n","Epoch 88/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8532\n","Epoch 89/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8447\n","Epoch 90/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8511\n","Epoch 91/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8340\n","Epoch 92/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8489\n","Epoch 93/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8447\n","Epoch 94/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8404\n","Epoch 95/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8532\n","Epoch 96/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8277\n","Epoch 97/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8255\n","Epoch 98/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8383\n","Epoch 99/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8596\n","Epoch 100/100\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8468\n","\n","-------------------------------------------------------------\n","1/1 [==============================] - 0s 83ms/step\n","\n","-------------------------------------------------------------\n","Actual Class: [0. 0. 1. 1. 0.]\n","Predict Class:\n"," [[0.03835592]\n"," [0.43477967]\n"," [0.25082025]\n"," [0.13504378]\n"," [0.245851  ]]\n","Epoch 옵션 증가\n","Epoch 1/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8489\n","Epoch 2/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8404\n","Epoch 3/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8596\n","Epoch 4/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8298\n","Epoch 5/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8532\n","Epoch 6/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8489\n","Epoch 7/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8489\n","Epoch 8/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8532\n","Epoch 9/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8383\n","Epoch 10/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8447\n","Epoch 11/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8489\n","Epoch 12/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8553\n","Epoch 13/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8383\n","Epoch 14/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8319\n","Epoch 15/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8553\n","Epoch 16/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8447\n","Epoch 17/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8298\n","Epoch 18/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8404\n","Epoch 19/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8404\n","Epoch 20/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8362\n","Epoch 21/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8489\n","Epoch 22/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8532\n","Epoch 23/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8489\n","Epoch 24/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8277\n","Epoch 25/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8468\n","Epoch 26/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8468\n","Epoch 27/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8298\n","Epoch 28/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8489\n","Epoch 29/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8404\n","Epoch 30/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8426\n","Epoch 31/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8447\n","Epoch 32/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8511\n","Epoch 33/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8362\n","Epoch 34/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8426\n","Epoch 35/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8468\n","Epoch 36/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8468\n","Epoch 37/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8511\n","Epoch 38/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8383\n","Epoch 39/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8553\n","Epoch 40/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8617\n","Epoch 41/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8468\n","Epoch 42/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8319\n","Epoch 43/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8468\n","Epoch 44/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8468\n","Epoch 45/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8447\n","Epoch 46/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8468\n","Epoch 47/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8234\n","Epoch 48/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8468\n","Epoch 49/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8404\n","Epoch 50/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8447\n","Epoch 51/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8532\n","Epoch 52/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8574\n","Epoch 53/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8511\n","Epoch 54/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8511\n","Epoch 55/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8468\n","Epoch 56/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8426\n","Epoch 57/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8468\n","Epoch 58/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8511\n","Epoch 59/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8468\n","Epoch 60/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8596\n","Epoch 61/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8617\n","Epoch 62/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8447\n","Epoch 63/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8511\n","Epoch 64/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.8489\n","Epoch 65/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8596\n","Epoch 66/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8362\n","Epoch 67/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8532\n","Epoch 68/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8617\n","Epoch 69/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8383\n","Epoch 70/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8532\n","Epoch 71/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8511\n","Epoch 72/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8319\n","Epoch 73/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8511\n","Epoch 74/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8532\n","Epoch 75/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8511\n","Epoch 76/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8489\n","Epoch 77/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8489\n","Epoch 78/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8617\n","Epoch 79/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8404\n","Epoch 80/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8596\n","Epoch 81/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8426\n","Epoch 82/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8511\n","Epoch 83/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8596\n","Epoch 84/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8404\n","Epoch 85/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8553\n","Epoch 86/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8489\n","Epoch 87/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8468\n","Epoch 88/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8532\n","Epoch 89/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8426\n","Epoch 90/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8574\n","Epoch 91/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8404\n","Epoch 92/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8489\n","Epoch 93/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8489\n","Epoch 94/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8532\n","Epoch 95/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8532\n","Epoch 96/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8404\n","Epoch 97/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8277\n","Epoch 98/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8426\n","Epoch 99/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8553\n","Epoch 100/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8511\n","Epoch 101/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8553\n","Epoch 102/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8574\n","Epoch 103/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8468\n","Epoch 104/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8511\n","Epoch 105/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8532\n","Epoch 106/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8553\n","Epoch 107/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8532\n","Epoch 108/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8511\n","Epoch 109/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8553\n","Epoch 110/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8426\n","Epoch 111/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8596\n","Epoch 112/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8574\n","Epoch 113/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8447\n","Epoch 114/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8553\n","Epoch 115/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8532\n","Epoch 116/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8511\n","Epoch 117/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8617\n","Epoch 118/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8532\n","Epoch 119/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8532\n","Epoch 120/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8553\n","Epoch 121/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8298\n","Epoch 122/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8511\n","Epoch 123/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8426\n","Epoch 124/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8532\n","Epoch 125/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8574\n","Epoch 126/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8553\n","Epoch 127/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8553\n","Epoch 128/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8298\n","Epoch 129/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8617\n","Epoch 130/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8213\n","Epoch 131/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8489\n","Epoch 132/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8617\n","Epoch 133/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8511\n","Epoch 134/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8532\n","Epoch 135/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8468\n","Epoch 136/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8383\n","Epoch 137/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8340\n","Epoch 138/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8638\n","Epoch 139/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8574\n","Epoch 140/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8532\n","Epoch 141/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8553\n","Epoch 142/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8340\n","Epoch 143/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8511\n","Epoch 144/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8596\n","Epoch 145/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8617\n","Epoch 146/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8617\n","Epoch 147/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8298\n","Epoch 148/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8489\n","Epoch 149/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8447\n","Epoch 150/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8489\n","Epoch 151/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8511\n","Epoch 152/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8340\n","Epoch 153/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8511\n","Epoch 154/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8596\n","Epoch 155/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8468\n","Epoch 156/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8404\n","Epoch 157/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8426\n","Epoch 158/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8617\n","Epoch 159/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8574\n","Epoch 160/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8553\n","Epoch 161/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8532\n","Epoch 162/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8766\n","Epoch 163/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8532\n","Epoch 164/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8511\n","Epoch 165/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8553\n","Epoch 166/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8553\n","Epoch 167/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8574\n","Epoch 168/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8532\n","Epoch 169/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8553\n","Epoch 170/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8617\n","Epoch 171/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8532\n","Epoch 172/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8574\n","Epoch 173/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8489\n","Epoch 174/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8511\n","Epoch 175/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8617\n","Epoch 176/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8362\n","Epoch 177/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8702\n","Epoch 178/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8447\n","Epoch 179/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8574\n","Epoch 180/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8447\n","Epoch 181/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8340\n","Epoch 182/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8532\n","Epoch 183/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8574\n","Epoch 184/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8511\n","Epoch 185/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8489\n","Epoch 186/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8532\n","Epoch 187/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8511\n","Epoch 188/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8532\n","Epoch 189/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8426\n","Epoch 190/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8319\n","Epoch 191/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8468\n","Epoch 192/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8553\n","Epoch 193/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8553\n","Epoch 194/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8660\n","Epoch 195/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8638\n","Epoch 196/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8489\n","Epoch 197/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8489\n","Epoch 198/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8574\n","Epoch 199/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8617\n","Epoch 200/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8638\n","Epoch 201/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8511\n","Epoch 202/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8596\n","Epoch 203/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8574\n","Epoch 204/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8447\n","Epoch 205/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8702\n","Epoch 206/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8468\n","Epoch 207/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8511\n","Epoch 208/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8532\n","Epoch 209/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8574\n","Epoch 210/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8426\n","Epoch 211/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8511\n","Epoch 212/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8447\n","Epoch 213/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8574\n","Epoch 214/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8383\n","Epoch 215/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8574\n","Epoch 216/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8617\n","Epoch 217/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8447\n","Epoch 218/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8596\n","Epoch 219/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8447\n","Epoch 220/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8489\n","Epoch 221/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8681\n","Epoch 222/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8468\n","Epoch 223/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8468\n","Epoch 224/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8511\n","Epoch 225/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8468\n","Epoch 226/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.8532\n","Epoch 227/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8532\n","Epoch 228/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8532\n","Epoch 229/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8489\n","Epoch 230/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8596\n","Epoch 231/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8681\n","Epoch 232/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8574\n","Epoch 233/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8596\n","Epoch 234/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.8319\n","Epoch 235/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8511\n","Epoch 236/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8532\n","Epoch 237/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8638\n","Epoch 238/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8617\n","Epoch 239/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8660\n","Epoch 240/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8596\n","Epoch 241/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8638\n","Epoch 242/1000\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8553\n","Epoch 243/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8681\n","Epoch 244/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8660\n","Epoch 245/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8574\n","Epoch 246/1000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8553\n","Epoch 247/1000\n"," 1/47 [..............................] - ETA: 0s - loss: 0.1594 - accuracy: 1.0000"]}],"source":["# 파일 선택을 통해 예제 데이터를 내 컴퓨터에서 불러옴\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","# 딥러닝을 구동하는 데 필요한 케라스 함수 호출\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# 필요한 라이브러리를 불러옴\n","import numpy as np\n","import tensorflow as tf\n","\n","# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n","np.random.seed(3)\n","tf.random.set_seed(3)\n","\n","# 준비된 수술 환자 데이터를 불러옴\n","Data_set = np.loadtxt(\"/content/drive/MyDrive/080228-master/deeplearning/dataset/ThoraricSurgery.csv\", delimiter=\",\")\n","\n","# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n","X = Data_set[:,0:17]\n","Y = Data_set[:,17]\n","\n","# ThoraricSurgery.csv 파일에서 앞부분 5개의 행들을 추출\n","test_X = X[:5, :]\n","test_Y = Y[:5]\n","\n","# 딥러닝 구조를 결정합니다(모델을 설정하고 실행하는 부분\n","model = Sequential()\n","model.add(Dense(30, input_dim=17, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# 딥러닝을 실행합니다. mean_squared_error\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(X, Y, epochs=100, batch_size=10)\n","\n","print()\n","print('-------------------------------------------------------------')\n","result = model.predict(test_X) # 타입 : numpy.ndarray(벡터)\n","\n","# 출력\n","print()\n","print('-------------------------------------------------------------')\n","print('Actual Class:', test_Y)\n","print('Predict Class:\\n', result)\n","\n","# epoch 옵션 증가\n","print(\"Epoch 옵션 증가\")\n","model.fit(X, Y, epochs=1000, batch_size=10)\n","\n","print()\n","print('-------------------------------------------------------------')\n","result1 = model.predict(test_X) # 타입 : numpy.ndarray(벡터)\n","\n","print()\n","print('-------------------------------------------------------------')\n","print('Actual Class:', test_Y)\n","print('Predict Class:\\n', result1)\n","\n","# batch_size 옵션 증가\n","print(\"batch_size 옵션 증가\")\n","model.fit(X, Y, epochs=100, batch_size=94)\n","\n","print()\n","print('-------------------------------------------------------------')\n","result2 = model.predict(test_X) # 타입 : numpy.ndarray(벡터)\n","\n","print()\n","print('-------------------------------------------------------------')\n","print('Actual Class:', test_Y)\n","print('Predict Class:\\n', result2)\n","\n","# epoch + batch_size 옵션 증가\n","print(\"batch_size 옵션 증가\")\n","model.fit(X, Y, epochs=1000, batch_size=94)\n","\n","print()\n","print('-------------------------------------------------------------')\n","result3 = model.predict(test_X) # 타입 : numpy.ndarray(벡터)\n","\n","print()\n","print('-------------------------------------------------------------')\n","print('Actual Class:', test_Y)\n","print('Predict Class:\\n', result3)"]}]}