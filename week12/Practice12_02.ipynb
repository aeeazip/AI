{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOcAscOzo9jazVISF3oj4gn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HkVqlG-qKxkS","executionInfo":{"status":"ok","timestamp":1717344224832,"user_tz":-540,"elapsed":16241,"user":{"displayName":"정채원","userId":"16403372842423495263"}},"outputId":"88bb2925-b530-4605-a97d-04fb42196bb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'hello': 1, 'hi there!': 2, 'how are you?': 3, \"i'm doing well, thanks\": 4, \"what's your name?\": 5, \"i'm a chatbot.\": 6}\n","[[1, 2], [3, 4], [5, 6]]\n","Input Seq:  [[]]\n","Max Input Len:  2\n","=============== 3\n","Size:  7\n","Epoch 1/50\n","1/1 [==============================] - 9s 9s/step - loss: 1.9454 - accuracy: 0.0000e+00\n","Epoch 2/50\n","1/1 [==============================] - 0s 26ms/step - loss: 1.9401 - accuracy: 0.6667\n","Epoch 3/50\n","1/1 [==============================] - 0s 30ms/step - loss: 1.9353 - accuracy: 0.6667\n","Epoch 4/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.9297 - accuracy: 0.6667\n","Epoch 5/50\n","1/1 [==============================] - 0s 32ms/step - loss: 1.9233 - accuracy: 0.6667\n","Epoch 6/50\n","1/1 [==============================] - 0s 24ms/step - loss: 1.9165 - accuracy: 0.6667\n","Epoch 7/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.9105 - accuracy: 0.6667\n","Epoch 8/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.9047 - accuracy: 0.6667\n","Epoch 9/50\n","1/1 [==============================] - 0s 25ms/step - loss: 1.8981 - accuracy: 0.6667\n","Epoch 10/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.8879 - accuracy: 0.6667\n","Epoch 11/50\n","1/1 [==============================] - 0s 24ms/step - loss: 1.8790 - accuracy: 0.6667\n","Epoch 12/50\n","1/1 [==============================] - 0s 25ms/step - loss: 1.8735 - accuracy: 0.6667\n","Epoch 13/50\n","1/1 [==============================] - 0s 26ms/step - loss: 1.8626 - accuracy: 0.6667\n","Epoch 14/50\n","1/1 [==============================] - 0s 25ms/step - loss: 1.8533 - accuracy: 0.6667\n","Epoch 15/50\n","1/1 [==============================] - 0s 25ms/step - loss: 1.8464 - accuracy: 0.6667\n","Epoch 16/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.8333 - accuracy: 0.6667\n","Epoch 17/50\n","1/1 [==============================] - 0s 24ms/step - loss: 1.8188 - accuracy: 0.6667\n","Epoch 18/50\n","1/1 [==============================] - 0s 27ms/step - loss: 1.8078 - accuracy: 0.6667\n","Epoch 19/50\n","1/1 [==============================] - 0s 29ms/step - loss: 1.7945 - accuracy: 0.6667\n","Epoch 20/50\n","1/1 [==============================] - 0s 31ms/step - loss: 1.7755 - accuracy: 0.6667\n","Epoch 21/50\n","1/1 [==============================] - 0s 31ms/step - loss: 1.7661 - accuracy: 0.6667\n","Epoch 22/50\n","1/1 [==============================] - 0s 28ms/step - loss: 1.7509 - accuracy: 0.6667\n","Epoch 23/50\n","1/1 [==============================] - 0s 27ms/step - loss: 1.7296 - accuracy: 0.6667\n","Epoch 24/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.7053 - accuracy: 0.6667\n","Epoch 25/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.6866 - accuracy: 0.6667\n","Epoch 26/50\n","1/1 [==============================] - 0s 22ms/step - loss: 1.6646 - accuracy: 0.6667\n","Epoch 27/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.6270 - accuracy: 0.6667\n","Epoch 28/50\n","1/1 [==============================] - 0s 30ms/step - loss: 1.6278 - accuracy: 0.6667\n","Epoch 29/50\n","1/1 [==============================] - 0s 26ms/step - loss: 1.5940 - accuracy: 0.6667\n","Epoch 30/50\n","1/1 [==============================] - 0s 32ms/step - loss: 1.5495 - accuracy: 0.6667\n","Epoch 31/50\n","1/1 [==============================] - 0s 35ms/step - loss: 1.5188 - accuracy: 0.6667\n","Epoch 32/50\n","1/1 [==============================] - 0s 26ms/step - loss: 1.4960 - accuracy: 0.6667\n","Epoch 33/50\n","1/1 [==============================] - 0s 29ms/step - loss: 1.4421 - accuracy: 0.6667\n","Epoch 34/50\n","1/1 [==============================] - 0s 31ms/step - loss: 1.4063 - accuracy: 0.6667\n","Epoch 35/50\n","1/1 [==============================] - 0s 20ms/step - loss: 1.3697 - accuracy: 0.6667\n","Epoch 36/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.3146 - accuracy: 0.6667\n","Epoch 37/50\n","1/1 [==============================] - 0s 17ms/step - loss: 1.2476 - accuracy: 0.6667\n","Epoch 38/50\n","1/1 [==============================] - 0s 15ms/step - loss: 1.1618 - accuracy: 0.6667\n","Epoch 39/50\n","1/1 [==============================] - 0s 17ms/step - loss: 1.1574 - accuracy: 0.6667\n","Epoch 40/50\n","1/1 [==============================] - 0s 16ms/step - loss: 1.1099 - accuracy: 0.6667\n","Epoch 41/50\n","1/1 [==============================] - 0s 16ms/step - loss: 1.0509 - accuracy: 0.6667\n","Epoch 42/50\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0061 - accuracy: 0.6667\n","Epoch 43/50\n","1/1 [==============================] - 0s 16ms/step - loss: 0.9051 - accuracy: 1.0000\n","Epoch 44/50\n","1/1 [==============================] - 0s 14ms/step - loss: 0.9509 - accuracy: 1.0000\n","Epoch 45/50\n","1/1 [==============================] - 0s 21ms/step - loss: 0.8836 - accuracy: 1.0000\n","Epoch 46/50\n","1/1 [==============================] - 0s 16ms/step - loss: 0.7479 - accuracy: 1.0000\n","Epoch 47/50\n","1/1 [==============================] - 0s 16ms/step - loss: 0.6984 - accuracy: 1.0000\n","Epoch 48/50\n","1/1 [==============================] - 0s 15ms/step - loss: 0.7724 - accuracy: 0.6667\n","Epoch 49/50\n","1/1 [==============================] - 0s 17ms/step - loss: 0.5977 - accuracy: 1.0000\n","Epoch 50/50\n","1/1 [==============================] - 0s 16ms/step - loss: 0.5510 - accuracy: 1.0000\n","input seq:  [[0 0]]\n","1/1 [==============================] - 2s 2s/step\n","Predict Output:  [[0.11198988 0.12071729 0.17745438 0.11868175 0.18041855 0.11370668\n","  0.17703143]]\n","Predict Index:  [4]\n","User: how are you?\n","Chatbot: i'm doing well, thanks\n"]}],"source":["# Chatbot Sample\n","import numpy as np\n","import tensorflow as tf\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout\n","\n","# Example dataset\n","conversations = [\n","    [\"Hello\", \"Hi there!\"],\n","    [\"How are you?\", \"I'm doing well, thanks\"],\n","    [\"What's your name?\", \"I'm a chatbot.\"]\n","]\n","\n","token = Tokenizer()\n","token.fit_on_texts(conversations)\n","print(token.word_index)\n","\n","sequences = token.texts_to_sequences(conversations)\n","print(sequences)\n","\n","user_input = \"How are you?\"\n","#user_input=\"Hello\"\n","input_seq = token.texts_to_sequences([user_input])\n","print(\"Input Seq: \", input_seq)\n","\n","max_sequence_len = max([len(seq) for seq in sequences])\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_len)\n","print(\"Max Input Len: \", max_sequence_len)\n","\n","print(\"===============\", len(sequences))\n","# X = []; y = []\n","# for idx in range(len(sequences)):\n","#   X.append(sequences[idx][0])\n","#   y.append(sequences[idx][1])\n","# print(X)\n","# print(y)\n","X = padded_sequences[:, :-1]\n","y = padded_sequences[:, -1]\n","\n","word_size = len(token.word_index) + 1\n","print(\"Size: \", word_size)\n","\n","# 모델의 설정\n","model = Sequential()\n","model.add(Embedding(word_size, 128, input_length=max_sequence_len, mask_zero=True))\n","model.add(LSTM(100, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(100))\n","model.add(Dropout(0.2))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(word_size, activation=\"softmax\"))\n","\n","# 모델의 컴파일\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","model.fit(X, y, epochs=50, verbose=1)\n","\n","def generate_response(input_text):\n","  input_seq = token.texts_to_sequences([input_text])\n","  input_seq = pad_sequences(input_seq, maxlen=max_sequence_len)\n","  print(\"input seq: \", input_seq)\n","  predicted_output = model.predict(input_seq)\n","  print(\"Predict Output: \", predicted_output)\n","\n","  predicted_word_index = tf.argmax(predicted_output, axis=-1).numpy().flatten()\n","  print(\"Predict Index: \", predicted_word_index)\n","  response = token.sequences_to_texts([predicted_word_index])\n","  return response[0]\n","\n","# Test the chatbot\n","user_input = \"how are you?\"\n","#user_input = \"Hello\"\n","response = generate_response(user_input)\n","print(f\"User: {user_input}\")\n","print(f\"Chatbot: {response}\")"]}]}