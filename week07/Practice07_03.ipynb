{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVKJQ79sIMg2WuYLTHguDH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_Klu1UBYyGwy","executionInfo":{"status":"ok","timestamp":1713460401318,"user_tz":-540,"elapsed":148173,"user":{"displayName":"정채원","userId":"16403372842423495263"}},"outputId":"47836126-0a8a-47ff-e32f-9242cc48a2d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","Epoch 1: val_loss improved from inf to 0.26430, saving model to ./model/01-0.2643.hdf5\n","\n","Epoch 2: val_loss improved from 0.26430 to 0.26065, saving model to ./model/02-0.2606.hdf5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3: val_loss improved from 0.26065 to 0.25683, saving model to ./model/03-0.2568.hdf5\n","\n","Epoch 4: val_loss improved from 0.25683 to 0.25314, saving model to ./model/04-0.2531.hdf5\n","\n","Epoch 5: val_loss improved from 0.25314 to 0.25066, saving model to ./model/05-0.2507.hdf5\n","\n","Epoch 6: val_loss improved from 0.25066 to 0.24928, saving model to ./model/06-0.2493.hdf5\n","\n","Epoch 7: val_loss improved from 0.24928 to 0.24863, saving model to ./model/07-0.2486.hdf5\n","\n","Epoch 8: val_loss improved from 0.24863 to 0.24853, saving model to ./model/08-0.2485.hdf5\n","\n","Epoch 9: val_loss did not improve from 0.24853\n","\n","Epoch 10: val_loss did not improve from 0.24853\n","\n","Epoch 11: val_loss did not improve from 0.24853\n","\n","Epoch 12: val_loss improved from 0.24853 to 0.24828, saving model to ./model/12-0.2483.hdf5\n","\n","Epoch 13: val_loss improved from 0.24828 to 0.24785, saving model to ./model/13-0.2479.hdf5\n","\n","Epoch 14: val_loss improved from 0.24785 to 0.24724, saving model to ./model/14-0.2472.hdf5\n","\n","Epoch 15: val_loss improved from 0.24724 to 0.24644, saving model to ./model/15-0.2464.hdf5\n","\n","Epoch 16: val_loss improved from 0.24644 to 0.24547, saving model to ./model/16-0.2455.hdf5\n","\n","Epoch 17: val_loss improved from 0.24547 to 0.24430, saving model to ./model/17-0.2443.hdf5\n","\n","Epoch 18: val_loss improved from 0.24430 to 0.24290, saving model to ./model/18-0.2429.hdf5\n","\n","Epoch 19: val_loss improved from 0.24290 to 0.24139, saving model to ./model/19-0.2414.hdf5\n","\n","Epoch 20: val_loss improved from 0.24139 to 0.23998, saving model to ./model/20-0.2400.hdf5\n","\n","Epoch 21: val_loss improved from 0.23998 to 0.23862, saving model to ./model/21-0.2386.hdf5\n","\n","Epoch 22: val_loss improved from 0.23862 to 0.23733, saving model to ./model/22-0.2373.hdf5\n","\n","Epoch 23: val_loss improved from 0.23733 to 0.23611, saving model to ./model/23-0.2361.hdf5\n","\n","Epoch 24: val_loss improved from 0.23611 to 0.23493, saving model to ./model/24-0.2349.hdf5\n","\n","Epoch 25: val_loss improved from 0.23493 to 0.23383, saving model to ./model/25-0.2338.hdf5\n","\n","Epoch 26: val_loss improved from 0.23383 to 0.23274, saving model to ./model/26-0.2327.hdf5\n","\n","Epoch 27: val_loss improved from 0.23274 to 0.23164, saving model to ./model/27-0.2316.hdf5\n","\n","Epoch 28: val_loss improved from 0.23164 to 0.23060, saving model to ./model/28-0.2306.hdf5\n","\n","Epoch 29: val_loss improved from 0.23060 to 0.22953, saving model to ./model/29-0.2295.hdf5\n","\n","Epoch 30: val_loss improved from 0.22953 to 0.22846, saving model to ./model/30-0.2285.hdf5\n","\n","Epoch 31: val_loss improved from 0.22846 to 0.22737, saving model to ./model/31-0.2274.hdf5\n","\n","Epoch 32: val_loss improved from 0.22737 to 0.22628, saving model to ./model/32-0.2263.hdf5\n","\n","Epoch 33: val_loss improved from 0.22628 to 0.22512, saving model to ./model/33-0.2251.hdf5\n","\n","Epoch 34: val_loss improved from 0.22512 to 0.22389, saving model to ./model/34-0.2239.hdf5\n","\n","Epoch 35: val_loss improved from 0.22389 to 0.22260, saving model to ./model/35-0.2226.hdf5\n","\n","Epoch 36: val_loss improved from 0.22260 to 0.22123, saving model to ./model/36-0.2212.hdf5\n","\n","Epoch 37: val_loss improved from 0.22123 to 0.21978, saving model to ./model/37-0.2198.hdf5\n","\n","Epoch 38: val_loss improved from 0.21978 to 0.21828, saving model to ./model/38-0.2183.hdf5\n","\n","Epoch 39: val_loss improved from 0.21828 to 0.21673, saving model to ./model/39-0.2167.hdf5\n","\n","Epoch 40: val_loss improved from 0.21673 to 0.21517, saving model to ./model/40-0.2152.hdf5\n","\n","Epoch 41: val_loss improved from 0.21517 to 0.21356, saving model to ./model/41-0.2136.hdf5\n","\n","Epoch 42: val_loss improved from 0.21356 to 0.21189, saving model to ./model/42-0.2119.hdf5\n","\n","Epoch 43: val_loss improved from 0.21189 to 0.21027, saving model to ./model/43-0.2103.hdf5\n","\n","Epoch 44: val_loss improved from 0.21027 to 0.20868, saving model to ./model/44-0.2087.hdf5\n","\n","Epoch 45: val_loss improved from 0.20868 to 0.20715, saving model to ./model/45-0.2071.hdf5\n","\n","Epoch 46: val_loss improved from 0.20715 to 0.20570, saving model to ./model/46-0.2057.hdf5\n","\n","Epoch 47: val_loss improved from 0.20570 to 0.20431, saving model to ./model/47-0.2043.hdf5\n","\n","Epoch 48: val_loss improved from 0.20431 to 0.20299, saving model to ./model/48-0.2030.hdf5\n","\n","Epoch 49: val_loss improved from 0.20299 to 0.20176, saving model to ./model/49-0.2018.hdf5\n","\n","Epoch 50: val_loss improved from 0.20176 to 0.20054, saving model to ./model/50-0.2005.hdf5\n","\n","Epoch 51: val_loss improved from 0.20054 to 0.19934, saving model to ./model/51-0.1993.hdf5\n","\n","Epoch 52: val_loss improved from 0.19934 to 0.19814, saving model to ./model/52-0.1981.hdf5\n","\n","Epoch 53: val_loss improved from 0.19814 to 0.19693, saving model to ./model/53-0.1969.hdf5\n","\n","Epoch 54: val_loss improved from 0.19693 to 0.19573, saving model to ./model/54-0.1957.hdf5\n","\n","Epoch 55: val_loss improved from 0.19573 to 0.19460, saving model to ./model/55-0.1946.hdf5\n","\n","Epoch 56: val_loss improved from 0.19460 to 0.19358, saving model to ./model/56-0.1936.hdf5\n","\n","Epoch 57: val_loss improved from 0.19358 to 0.19257, saving model to ./model/57-0.1926.hdf5\n","\n","Epoch 58: val_loss improved from 0.19257 to 0.19157, saving model to ./model/58-0.1916.hdf5\n","\n","Epoch 59: val_loss improved from 0.19157 to 0.19056, saving model to ./model/59-0.1906.hdf5\n","\n","Epoch 60: val_loss improved from 0.19056 to 0.18955, saving model to ./model/60-0.1895.hdf5\n","\n","Epoch 61: val_loss improved from 0.18955 to 0.18853, saving model to ./model/61-0.1885.hdf5\n","\n","Epoch 62: val_loss improved from 0.18853 to 0.18753, saving model to ./model/62-0.1875.hdf5\n","\n","Epoch 63: val_loss improved from 0.18753 to 0.18652, saving model to ./model/63-0.1865.hdf5\n","\n","Epoch 64: val_loss improved from 0.18652 to 0.18557, saving model to ./model/64-0.1856.hdf5\n","\n","Epoch 65: val_loss improved from 0.18557 to 0.18466, saving model to ./model/65-0.1847.hdf5\n","\n","Epoch 66: val_loss improved from 0.18466 to 0.18378, saving model to ./model/66-0.1838.hdf5\n","\n","Epoch 67: val_loss improved from 0.18378 to 0.18288, saving model to ./model/67-0.1829.hdf5\n","\n","Epoch 68: val_loss improved from 0.18288 to 0.18200, saving model to ./model/68-0.1820.hdf5\n","\n","Epoch 69: val_loss improved from 0.18200 to 0.18112, saving model to ./model/69-0.1811.hdf5\n","\n","Epoch 70: val_loss improved from 0.18112 to 0.18023, saving model to ./model/70-0.1802.hdf5\n","\n","Epoch 71: val_loss improved from 0.18023 to 0.17930, saving model to ./model/71-0.1793.hdf5\n","\n","Epoch 72: val_loss improved from 0.17930 to 0.17836, saving model to ./model/72-0.1784.hdf5\n","\n","Epoch 73: val_loss improved from 0.17836 to 0.17743, saving model to ./model/73-0.1774.hdf5\n","\n","Epoch 74: val_loss improved from 0.17743 to 0.17655, saving model to ./model/74-0.1766.hdf5\n","\n","Epoch 75: val_loss improved from 0.17655 to 0.17580, saving model to ./model/75-0.1758.hdf5\n","\n","Epoch 76: val_loss improved from 0.17580 to 0.17508, saving model to ./model/76-0.1751.hdf5\n","\n","Epoch 77: val_loss improved from 0.17508 to 0.17439, saving model to ./model/77-0.1744.hdf5\n","\n","Epoch 78: val_loss improved from 0.17439 to 0.17374, saving model to ./model/78-0.1737.hdf5\n","\n","Epoch 79: val_loss improved from 0.17374 to 0.17317, saving model to ./model/79-0.1732.hdf5\n","\n","Epoch 80: val_loss improved from 0.17317 to 0.17260, saving model to ./model/80-0.1726.hdf5\n","\n","Epoch 81: val_loss improved from 0.17260 to 0.17196, saving model to ./model/81-0.1720.hdf5\n","\n","Epoch 82: val_loss improved from 0.17196 to 0.17125, saving model to ./model/82-0.1713.hdf5\n","\n","Epoch 83: val_loss improved from 0.17125 to 0.17052, saving model to ./model/83-0.1705.hdf5\n","\n","Epoch 84: val_loss improved from 0.17052 to 0.16980, saving model to ./model/84-0.1698.hdf5\n","\n","Epoch 85: val_loss improved from 0.16980 to 0.16911, saving model to ./model/85-0.1691.hdf5\n","\n","Epoch 86: val_loss improved from 0.16911 to 0.16843, saving model to ./model/86-0.1684.hdf5\n","\n","Epoch 87: val_loss improved from 0.16843 to 0.16779, saving model to ./model/87-0.1678.hdf5\n","\n","Epoch 88: val_loss improved from 0.16779 to 0.16723, saving model to ./model/88-0.1672.hdf5\n","\n","Epoch 89: val_loss improved from 0.16723 to 0.16669, saving model to ./model/89-0.1667.hdf5\n","\n","Epoch 90: val_loss improved from 0.16669 to 0.16624, saving model to ./model/90-0.1662.hdf5\n","\n","Epoch 91: val_loss improved from 0.16624 to 0.16584, saving model to ./model/91-0.1658.hdf5\n","\n","Epoch 92: val_loss improved from 0.16584 to 0.16549, saving model to ./model/92-0.1655.hdf5\n","\n","Epoch 93: val_loss improved from 0.16549 to 0.16518, saving model to ./model/93-0.1652.hdf5\n","\n","Epoch 94: val_loss improved from 0.16518 to 0.16488, saving model to ./model/94-0.1649.hdf5\n","\n","Epoch 95: val_loss improved from 0.16488 to 0.16459, saving model to ./model/95-0.1646.hdf5\n","\n","Epoch 96: val_loss improved from 0.16459 to 0.16423, saving model to ./model/96-0.1642.hdf5\n","\n","Epoch 97: val_loss improved from 0.16423 to 0.16378, saving model to ./model/97-0.1638.hdf5\n","\n","Epoch 98: val_loss improved from 0.16378 to 0.16325, saving model to ./model/98-0.1633.hdf5\n","\n","Epoch 99: val_loss improved from 0.16325 to 0.16272, saving model to ./model/99-0.1627.hdf5\n","\n","Epoch 100: val_loss improved from 0.16272 to 0.16224, saving model to ./model/100-0.1622.hdf5\n","\n","Epoch 101: val_loss improved from 0.16224 to 0.16187, saving model to ./model/101-0.1619.hdf5\n","\n","Epoch 102: val_loss improved from 0.16187 to 0.16161, saving model to ./model/102-0.1616.hdf5\n","\n","Epoch 103: val_loss improved from 0.16161 to 0.16140, saving model to ./model/103-0.1614.hdf5\n","\n","Epoch 104: val_loss improved from 0.16140 to 0.16122, saving model to ./model/104-0.1612.hdf5\n","\n","Epoch 105: val_loss improved from 0.16122 to 0.16101, saving model to ./model/105-0.1610.hdf5\n","\n","Epoch 106: val_loss improved from 0.16101 to 0.16073, saving model to ./model/106-0.1607.hdf5\n","\n","Epoch 107: val_loss improved from 0.16073 to 0.16038, saving model to ./model/107-0.1604.hdf5\n","\n","Epoch 108: val_loss improved from 0.16038 to 0.15995, saving model to ./model/108-0.1600.hdf5\n","\n","Epoch 109: val_loss improved from 0.15995 to 0.15946, saving model to ./model/109-0.1595.hdf5\n","\n","Epoch 110: val_loss improved from 0.15946 to 0.15904, saving model to ./model/110-0.1590.hdf5\n","\n","Epoch 111: val_loss improved from 0.15904 to 0.15868, saving model to ./model/111-0.1587.hdf5\n","\n","Epoch 112: val_loss improved from 0.15868 to 0.15839, saving model to ./model/112-0.1584.hdf5\n","\n","Epoch 113: val_loss improved from 0.15839 to 0.15814, saving model to ./model/113-0.1581.hdf5\n","\n","Epoch 114: val_loss improved from 0.15814 to 0.15788, saving model to ./model/114-0.1579.hdf5\n","\n","Epoch 115: val_loss improved from 0.15788 to 0.15764, saving model to ./model/115-0.1576.hdf5\n","\n","Epoch 116: val_loss improved from 0.15764 to 0.15743, saving model to ./model/116-0.1574.hdf5\n","\n","Epoch 117: val_loss improved from 0.15743 to 0.15713, saving model to ./model/117-0.1571.hdf5\n","\n","Epoch 118: val_loss improved from 0.15713 to 0.15681, saving model to ./model/118-0.1568.hdf5\n","\n","Epoch 119: val_loss improved from 0.15681 to 0.15654, saving model to ./model/119-0.1565.hdf5\n","\n","Epoch 120: val_loss improved from 0.15654 to 0.15638, saving model to ./model/120-0.1564.hdf5\n","\n","Epoch 121: val_loss improved from 0.15638 to 0.15626, saving model to ./model/121-0.1563.hdf5\n","\n","Epoch 122: val_loss improved from 0.15626 to 0.15609, saving model to ./model/122-0.1561.hdf5\n","\n","Epoch 123: val_loss improved from 0.15609 to 0.15593, saving model to ./model/123-0.1559.hdf5\n","\n","Epoch 124: val_loss improved from 0.15593 to 0.15576, saving model to ./model/124-0.1558.hdf5\n","\n","Epoch 125: val_loss improved from 0.15576 to 0.15558, saving model to ./model/125-0.1556.hdf5\n","\n","Epoch 126: val_loss improved from 0.15558 to 0.15551, saving model to ./model/126-0.1555.hdf5\n","\n","Epoch 127: val_loss improved from 0.15551 to 0.15541, saving model to ./model/127-0.1554.hdf5\n","\n","Epoch 128: val_loss improved from 0.15541 to 0.15532, saving model to ./model/128-0.1553.hdf5\n","\n","Epoch 129: val_loss improved from 0.15532 to 0.15529, saving model to ./model/129-0.1553.hdf5\n","\n","Epoch 130: val_loss improved from 0.15529 to 0.15520, saving model to ./model/130-0.1552.hdf5\n","\n","Epoch 131: val_loss improved from 0.15520 to 0.15506, saving model to ./model/131-0.1551.hdf5\n","\n","Epoch 132: val_loss improved from 0.15506 to 0.15496, saving model to ./model/132-0.1550.hdf5\n","\n","Epoch 133: val_loss improved from 0.15496 to 0.15489, saving model to ./model/133-0.1549.hdf5\n","\n","Epoch 134: val_loss improved from 0.15489 to 0.15483, saving model to ./model/134-0.1548.hdf5\n","\n","Epoch 135: val_loss improved from 0.15483 to 0.15468, saving model to ./model/135-0.1547.hdf5\n","\n","Epoch 136: val_loss improved from 0.15468 to 0.15449, saving model to ./model/136-0.1545.hdf5\n","\n","Epoch 137: val_loss improved from 0.15449 to 0.15424, saving model to ./model/137-0.1542.hdf5\n","\n","Epoch 138: val_loss improved from 0.15424 to 0.15398, saving model to ./model/138-0.1540.hdf5\n","\n","Epoch 139: val_loss improved from 0.15398 to 0.15360, saving model to ./model/139-0.1536.hdf5\n","\n","Epoch 140: val_loss improved from 0.15360 to 0.15326, saving model to ./model/140-0.1533.hdf5\n","\n","Epoch 141: val_loss improved from 0.15326 to 0.15305, saving model to ./model/141-0.1530.hdf5\n","\n","Epoch 142: val_loss improved from 0.15305 to 0.15293, saving model to ./model/142-0.1529.hdf5\n","\n","Epoch 143: val_loss improved from 0.15293 to 0.15283, saving model to ./model/143-0.1528.hdf5\n","\n","Epoch 144: val_loss improved from 0.15283 to 0.15271, saving model to ./model/144-0.1527.hdf5\n","\n","Epoch 145: val_loss improved from 0.15271 to 0.15265, saving model to ./model/145-0.1526.hdf5\n","\n","Epoch 146: val_loss improved from 0.15265 to 0.15249, saving model to ./model/146-0.1525.hdf5\n","\n","Epoch 147: val_loss improved from 0.15249 to 0.15225, saving model to ./model/147-0.1523.hdf5\n","\n","Epoch 148: val_loss improved from 0.15225 to 0.15204, saving model to ./model/148-0.1520.hdf5\n","\n","Epoch 149: val_loss improved from 0.15204 to 0.15192, saving model to ./model/149-0.1519.hdf5\n","\n","Epoch 150: val_loss improved from 0.15192 to 0.15184, saving model to ./model/150-0.1518.hdf5\n","\n","Epoch 151: val_loss improved from 0.15184 to 0.15164, saving model to ./model/151-0.1516.hdf5\n","\n","Epoch 152: val_loss improved from 0.15164 to 0.15140, saving model to ./model/152-0.1514.hdf5\n","\n","Epoch 153: val_loss improved from 0.15140 to 0.15113, saving model to ./model/153-0.1511.hdf5\n","\n","Epoch 154: val_loss improved from 0.15113 to 0.15090, saving model to ./model/154-0.1509.hdf5\n","\n","Epoch 155: val_loss improved from 0.15090 to 0.15060, saving model to ./model/155-0.1506.hdf5\n","\n","Epoch 156: val_loss improved from 0.15060 to 0.15042, saving model to ./model/156-0.1504.hdf5\n","\n","Epoch 157: val_loss did not improve from 0.15042\n","\n","Epoch 158: val_loss did not improve from 0.15042\n","\n","Epoch 159: val_loss did not improve from 0.15042\n","\n","Epoch 160: val_loss did not improve from 0.15042\n","\n","Epoch 161: val_loss did not improve from 0.15042\n","\n","Epoch 162: val_loss did not improve from 0.15042\n","\n","Epoch 163: val_loss did not improve from 0.15042\n","\n","Epoch 164: val_loss did not improve from 0.15042\n","\n","Epoch 165: val_loss did not improve from 0.15042\n","\n","Epoch 166: val_loss did not improve from 0.15042\n","\n","Epoch 167: val_loss did not improve from 0.15042\n","\n","Epoch 168: val_loss did not improve from 0.15042\n","\n","Epoch 169: val_loss did not improve from 0.15042\n","\n","Epoch 170: val_loss did not improve from 0.15042\n","\n","Epoch 171: val_loss did not improve from 0.15042\n","\n","Epoch 172: val_loss did not improve from 0.15042\n","\n","Epoch 173: val_loss did not improve from 0.15042\n","\n","Epoch 174: val_loss did not improve from 0.15042\n","\n","Epoch 175: val_loss did not improve from 0.15042\n","\n","Epoch 176: val_loss did not improve from 0.15042\n","\n","Epoch 177: val_loss did not improve from 0.15042\n","\n","Epoch 178: val_loss did not improve from 0.15042\n","\n","Epoch 179: val_loss did not improve from 0.15042\n","\n","Epoch 180: val_loss did not improve from 0.15042\n","\n","Epoch 181: val_loss did not improve from 0.15042\n","\n","Epoch 182: val_loss did not improve from 0.15042\n","\n","Epoch 183: val_loss did not improve from 0.15042\n","\n","Epoch 184: val_loss did not improve from 0.15042\n","\n","Epoch 185: val_loss did not improve from 0.15042\n","\n","Epoch 186: val_loss did not improve from 0.15042\n","\n","Epoch 187: val_loss did not improve from 0.15042\n","\n","Epoch 188: val_loss did not improve from 0.15042\n","\n","Epoch 189: val_loss did not improve from 0.15042\n","\n","Epoch 190: val_loss did not improve from 0.15042\n","\n","Epoch 191: val_loss did not improve from 0.15042\n","\n","Epoch 192: val_loss did not improve from 0.15042\n","\n","Epoch 193: val_loss did not improve from 0.15042\n","\n","Epoch 194: val_loss did not improve from 0.15042\n","\n","Epoch 195: val_loss did not improve from 0.15042\n","\n","Epoch 196: val_loss did not improve from 0.15042\n","\n","Epoch 197: val_loss did not improve from 0.15042\n","\n","Epoch 198: val_loss did not improve from 0.15042\n","\n","Epoch 199: val_loss did not improve from 0.15042\n","\n","Epoch 200: val_loss did not improve from 0.15042\n","\n","Epoch 201: val_loss did not improve from 0.15042\n","\n","Epoch 202: val_loss did not improve from 0.15042\n","\n","Epoch 203: val_loss did not improve from 0.15042\n","\n","Epoch 204: val_loss did not improve from 0.15042\n","\n","Epoch 205: val_loss did not improve from 0.15042\n","\n","Epoch 206: val_loss did not improve from 0.15042\n","\n","Epoch 207: val_loss did not improve from 0.15042\n","\n","Epoch 208: val_loss did not improve from 0.15042\n","\n","Epoch 209: val_loss did not improve from 0.15042\n","\n","Epoch 210: val_loss did not improve from 0.15042\n","\n","Epoch 211: val_loss did not improve from 0.15042\n","\n","Epoch 212: val_loss did not improve from 0.15042\n","\n","Epoch 213: val_loss did not improve from 0.15042\n","\n","Epoch 214: val_loss did not improve from 0.15042\n","\n","Epoch 215: val_loss did not improve from 0.15042\n","\n","Epoch 216: val_loss did not improve from 0.15042\n","\n","Epoch 217: val_loss did not improve from 0.15042\n","\n","Epoch 218: val_loss did not improve from 0.15042\n","\n","Epoch 219: val_loss did not improve from 0.15042\n","\n","Epoch 220: val_loss did not improve from 0.15042\n","\n","Epoch 221: val_loss did not improve from 0.15042\n","\n","Epoch 222: val_loss did not improve from 0.15042\n","\n","Epoch 223: val_loss did not improve from 0.15042\n","\n","Epoch 224: val_loss did not improve from 0.15042\n","\n","Epoch 225: val_loss did not improve from 0.15042\n","\n","Epoch 226: val_loss did not improve from 0.15042\n","\n","Epoch 227: val_loss did not improve from 0.15042\n","\n","Epoch 228: val_loss did not improve from 0.15042\n","\n","Epoch 229: val_loss did not improve from 0.15042\n","\n","Epoch 230: val_loss did not improve from 0.15042\n","\n","Epoch 231: val_loss did not improve from 0.15042\n","\n","Epoch 232: val_loss did not improve from 0.15042\n","\n","Epoch 233: val_loss did not improve from 0.15042\n","\n","Epoch 234: val_loss did not improve from 0.15042\n","\n","Epoch 235: val_loss did not improve from 0.15042\n","\n","Epoch 236: val_loss did not improve from 0.15042\n","\n","Epoch 237: val_loss did not improve from 0.15042\n","\n","Epoch 238: val_loss did not improve from 0.15042\n","\n","Epoch 239: val_loss did not improve from 0.15042\n","\n","Epoch 240: val_loss did not improve from 0.15042\n","\n","Epoch 241: val_loss did not improve from 0.15042\n","\n","Epoch 242: val_loss did not improve from 0.15042\n","\n","Epoch 243: val_loss did not improve from 0.15042\n","\n","Epoch 244: val_loss improved from 0.15042 to 0.15007, saving model to ./model/244-0.1501.hdf5\n","\n","Epoch 245: val_loss improved from 0.15007 to 0.14955, saving model to ./model/245-0.1495.hdf5\n","\n","Epoch 246: val_loss improved from 0.14955 to 0.14892, saving model to ./model/246-0.1489.hdf5\n","\n","Epoch 247: val_loss improved from 0.14892 to 0.14853, saving model to ./model/247-0.1485.hdf5\n","\n","Epoch 248: val_loss improved from 0.14853 to 0.14845, saving model to ./model/248-0.1484.hdf5\n","\n","Epoch 249: val_loss improved from 0.14845 to 0.14841, saving model to ./model/249-0.1484.hdf5\n","\n","Epoch 250: val_loss improved from 0.14841 to 0.14806, saving model to ./model/250-0.1481.hdf5\n","\n","Epoch 251: val_loss improved from 0.14806 to 0.14746, saving model to ./model/251-0.1475.hdf5\n","\n","Epoch 252: val_loss improved from 0.14746 to 0.14659, saving model to ./model/252-0.1466.hdf5\n","\n","Epoch 253: val_loss improved from 0.14659 to 0.14583, saving model to ./model/253-0.1458.hdf5\n","\n","Epoch 254: val_loss improved from 0.14583 to 0.14529, saving model to ./model/254-0.1453.hdf5\n","\n","Epoch 255: val_loss improved from 0.14529 to 0.14477, saving model to ./model/255-0.1448.hdf5\n","\n","Epoch 256: val_loss improved from 0.14477 to 0.14424, saving model to ./model/256-0.1442.hdf5\n","\n","Epoch 257: val_loss improved from 0.14424 to 0.14370, saving model to ./model/257-0.1437.hdf5\n","\n","Epoch 258: val_loss improved from 0.14370 to 0.14314, saving model to ./model/258-0.1431.hdf5\n","\n","Epoch 259: val_loss improved from 0.14314 to 0.14261, saving model to ./model/259-0.1426.hdf5\n","\n","Epoch 260: val_loss improved from 0.14261 to 0.14210, saving model to ./model/260-0.1421.hdf5\n","\n","Epoch 261: val_loss improved from 0.14210 to 0.14168, saving model to ./model/261-0.1417.hdf5\n","\n","Epoch 262: val_loss improved from 0.14168 to 0.14122, saving model to ./model/262-0.1412.hdf5\n","\n","Epoch 263: val_loss improved from 0.14122 to 0.14082, saving model to ./model/263-0.1408.hdf5\n","\n","Epoch 264: val_loss improved from 0.14082 to 0.14049, saving model to ./model/264-0.1405.hdf5\n","\n","Epoch 265: val_loss improved from 0.14049 to 0.13998, saving model to ./model/265-0.1400.hdf5\n","\n","Epoch 266: val_loss improved from 0.13998 to 0.13950, saving model to ./model/266-0.1395.hdf5\n","\n","Epoch 267: val_loss improved from 0.13950 to 0.13921, saving model to ./model/267-0.1392.hdf5\n","\n","Epoch 268: val_loss improved from 0.13921 to 0.13893, saving model to ./model/268-0.1389.hdf5\n","\n","Epoch 269: val_loss improved from 0.13893 to 0.13839, saving model to ./model/269-0.1384.hdf5\n","\n","Epoch 270: val_loss improved from 0.13839 to 0.13753, saving model to ./model/270-0.1375.hdf5\n","\n","Epoch 271: val_loss improved from 0.13753 to 0.13687, saving model to ./model/271-0.1369.hdf5\n","\n","Epoch 272: val_loss improved from 0.13687 to 0.13666, saving model to ./model/272-0.1367.hdf5\n","\n","Epoch 273: val_loss improved from 0.13666 to 0.13634, saving model to ./model/273-0.1363.hdf5\n","\n","Epoch 274: val_loss improved from 0.13634 to 0.13587, saving model to ./model/274-0.1359.hdf5\n","\n","Epoch 275: val_loss improved from 0.13587 to 0.13526, saving model to ./model/275-0.1353.hdf5\n","\n","Epoch 276: val_loss improved from 0.13526 to 0.13478, saving model to ./model/276-0.1348.hdf5\n","\n","Epoch 277: val_loss improved from 0.13478 to 0.13410, saving model to ./model/277-0.1341.hdf5\n","\n","Epoch 278: val_loss improved from 0.13410 to 0.13352, saving model to ./model/278-0.1335.hdf5\n","\n","Epoch 279: val_loss improved from 0.13352 to 0.13290, saving model to ./model/279-0.1329.hdf5\n","\n","Epoch 280: val_loss improved from 0.13290 to 0.13218, saving model to ./model/280-0.1322.hdf5\n","\n","Epoch 281: val_loss improved from 0.13218 to 0.13178, saving model to ./model/281-0.1318.hdf5\n","\n","Epoch 282: val_loss improved from 0.13178 to 0.13123, saving model to ./model/282-0.1312.hdf5\n","\n","Epoch 283: val_loss improved from 0.13123 to 0.13048, saving model to ./model/283-0.1305.hdf5\n","\n","Epoch 284: val_loss improved from 0.13048 to 0.13003, saving model to ./model/284-0.1300.hdf5\n","\n","Epoch 285: val_loss improved from 0.13003 to 0.12991, saving model to ./model/285-0.1299.hdf5\n","\n","Epoch 286: val_loss improved from 0.12991 to 0.12959, saving model to ./model/286-0.1296.hdf5\n","\n","Epoch 287: val_loss improved from 0.12959 to 0.12897, saving model to ./model/287-0.1290.hdf5\n","\n","Epoch 288: val_loss improved from 0.12897 to 0.12840, saving model to ./model/288-0.1284.hdf5\n","\n","Epoch 289: val_loss improved from 0.12840 to 0.12821, saving model to ./model/289-0.1282.hdf5\n","\n","Epoch 290: val_loss improved from 0.12821 to 0.12820, saving model to ./model/290-0.1282.hdf5\n","\n","Epoch 291: val_loss improved from 0.12820 to 0.12782, saving model to ./model/291-0.1278.hdf5\n","\n","Epoch 292: val_loss improved from 0.12782 to 0.12718, saving model to ./model/292-0.1272.hdf5\n","\n","Epoch 293: val_loss improved from 0.12718 to 0.12678, saving model to ./model/293-0.1268.hdf5\n","\n","Epoch 294: val_loss improved from 0.12678 to 0.12635, saving model to ./model/294-0.1264.hdf5\n","\n","Epoch 295: val_loss improved from 0.12635 to 0.12596, saving model to ./model/295-0.1260.hdf5\n","\n","Epoch 296: val_loss improved from 0.12596 to 0.12545, saving model to ./model/296-0.1254.hdf5\n","\n","Epoch 297: val_loss improved from 0.12545 to 0.12510, saving model to ./model/297-0.1251.hdf5\n","\n","Epoch 298: val_loss improved from 0.12510 to 0.12468, saving model to ./model/298-0.1247.hdf5\n","\n","Epoch 299: val_loss improved from 0.12468 to 0.12414, saving model to ./model/299-0.1241.hdf5\n","\n","Epoch 300: val_loss improved from 0.12414 to 0.12361, saving model to ./model/300-0.1236.hdf5\n","\n","Epoch 301: val_loss improved from 0.12361 to 0.12306, saving model to ./model/301-0.1231.hdf5\n","\n","Epoch 302: val_loss improved from 0.12306 to 0.12243, saving model to ./model/302-0.1224.hdf5\n","\n","Epoch 303: val_loss improved from 0.12243 to 0.12202, saving model to ./model/303-0.1220.hdf5\n","\n","Epoch 304: val_loss improved from 0.12202 to 0.12185, saving model to ./model/304-0.1219.hdf5\n","\n","Epoch 305: val_loss improved from 0.12185 to 0.12168, saving model to ./model/305-0.1217.hdf5\n","\n","Epoch 306: val_loss improved from 0.12168 to 0.12114, saving model to ./model/306-0.1211.hdf5\n","\n","Epoch 307: val_loss improved from 0.12114 to 0.12053, saving model to ./model/307-0.1205.hdf5\n","\n","Epoch 308: val_loss improved from 0.12053 to 0.12028, saving model to ./model/308-0.1203.hdf5\n","\n","Epoch 309: val_loss improved from 0.12028 to 0.11994, saving model to ./model/309-0.1199.hdf5\n","\n","Epoch 310: val_loss improved from 0.11994 to 0.11940, saving model to ./model/310-0.1194.hdf5\n","\n","Epoch 311: val_loss improved from 0.11940 to 0.11837, saving model to ./model/311-0.1184.hdf5\n","\n","Epoch 312: val_loss improved from 0.11837 to 0.11769, saving model to ./model/312-0.1177.hdf5\n","\n","Epoch 313: val_loss did not improve from 0.11769\n","\n","Epoch 314: val_loss did not improve from 0.11769\n","\n","Epoch 315: val_loss improved from 0.11769 to 0.11699, saving model to ./model/315-0.1170.hdf5\n","\n","Epoch 316: val_loss improved from 0.11699 to 0.11579, saving model to ./model/316-0.1158.hdf5\n","\n","Epoch 317: val_loss improved from 0.11579 to 0.11492, saving model to ./model/317-0.1149.hdf5\n","\n","Epoch 318: val_loss improved from 0.11492 to 0.11456, saving model to ./model/318-0.1146.hdf5\n","\n","Epoch 319: val_loss improved from 0.11456 to 0.11440, saving model to ./model/319-0.1144.hdf5\n","\n","Epoch 320: val_loss improved from 0.11440 to 0.11402, saving model to ./model/320-0.1140.hdf5\n","\n","Epoch 321: val_loss improved from 0.11402 to 0.11343, saving model to ./model/321-0.1134.hdf5\n","\n","Epoch 322: val_loss improved from 0.11343 to 0.11270, saving model to ./model/322-0.1127.hdf5\n","\n","Epoch 323: val_loss improved from 0.11270 to 0.11232, saving model to ./model/323-0.1123.hdf5\n","\n","Epoch 324: val_loss did not improve from 0.11232\n","\n","Epoch 325: val_loss improved from 0.11232 to 0.11228, saving model to ./model/325-0.1123.hdf5\n","\n","Epoch 326: val_loss improved from 0.11228 to 0.11211, saving model to ./model/326-0.1121.hdf5\n","\n","Epoch 327: val_loss improved from 0.11211 to 0.11182, saving model to ./model/327-0.1118.hdf5\n","\n","Epoch 328: val_loss improved from 0.11182 to 0.11174, saving model to ./model/328-0.1117.hdf5\n","\n","Epoch 329: val_loss improved from 0.11174 to 0.11170, saving model to ./model/329-0.1117.hdf5\n","\n","Epoch 330: val_loss improved from 0.11170 to 0.11135, saving model to ./model/330-0.1114.hdf5\n","\n","Epoch 331: val_loss improved from 0.11135 to 0.11122, saving model to ./model/331-0.1112.hdf5\n","\n","Epoch 332: val_loss improved from 0.11122 to 0.11114, saving model to ./model/332-0.1111.hdf5\n","\n","Epoch 333: val_loss did not improve from 0.11114\n","\n","Epoch 334: val_loss improved from 0.11114 to 0.11097, saving model to ./model/334-0.1110.hdf5\n","\n","Epoch 335: val_loss improved from 0.11097 to 0.11059, saving model to ./model/335-0.1106.hdf5\n","\n","Epoch 336: val_loss improved from 0.11059 to 0.11054, saving model to ./model/336-0.1105.hdf5\n","\n","Epoch 337: val_loss did not improve from 0.11054\n","\n","Epoch 338: val_loss improved from 0.11054 to 0.11039, saving model to ./model/338-0.1104.hdf5\n","\n","Epoch 339: val_loss improved from 0.11039 to 0.11034, saving model to ./model/339-0.1103.hdf5\n","\n","Epoch 340: val_loss improved from 0.11034 to 0.11014, saving model to ./model/340-0.1101.hdf5\n","\n","Epoch 341: val_loss did not improve from 0.11014\n","\n","Epoch 342: val_loss did not improve from 0.11014\n","\n","Epoch 343: val_loss did not improve from 0.11014\n","\n","Epoch 344: val_loss did not improve from 0.11014\n","\n","Epoch 345: val_loss did not improve from 0.11014\n","\n","Epoch 346: val_loss improved from 0.11014 to 0.10981, saving model to ./model/346-0.1098.hdf5\n","\n","Epoch 347: val_loss improved from 0.10981 to 0.10942, saving model to ./model/347-0.1094.hdf5\n","\n","Epoch 348: val_loss improved from 0.10942 to 0.10938, saving model to ./model/348-0.1094.hdf5\n","\n","Epoch 349: val_loss improved from 0.10938 to 0.10932, saving model to ./model/349-0.1093.hdf5\n","\n","Epoch 350: val_loss improved from 0.10932 to 0.10916, saving model to ./model/350-0.1092.hdf5\n","\n","Epoch 351: val_loss did not improve from 0.10916\n","\n","Epoch 352: val_loss did not improve from 0.10916\n","\n","Epoch 353: val_loss did not improve from 0.10916\n","\n","Epoch 354: val_loss improved from 0.10916 to 0.10847, saving model to ./model/354-0.1085.hdf5\n","\n","Epoch 355: val_loss did not improve from 0.10847\n","\n","Epoch 356: val_loss did not improve from 0.10847\n","\n","Epoch 357: val_loss improved from 0.10847 to 0.10832, saving model to ./model/357-0.1083.hdf5\n","\n","Epoch 358: val_loss improved from 0.10832 to 0.10760, saving model to ./model/358-0.1076.hdf5\n","\n","Epoch 359: val_loss improved from 0.10760 to 0.10739, saving model to ./model/359-0.1074.hdf5\n","\n","Epoch 360: val_loss did not improve from 0.10739\n","\n","Epoch 361: val_loss did not improve from 0.10739\n","\n","Epoch 362: val_loss improved from 0.10739 to 0.10705, saving model to ./model/362-0.1071.hdf5\n","\n","Epoch 363: val_loss improved from 0.10705 to 0.10705, saving model to ./model/363-0.1071.hdf5\n","\n","Epoch 364: val_loss did not improve from 0.10705\n","\n","Epoch 365: val_loss did not improve from 0.10705\n","\n","Epoch 366: val_loss improved from 0.10705 to 0.10702, saving model to ./model/366-0.1070.hdf5\n","\n","Epoch 367: val_loss improved from 0.10702 to 0.10664, saving model to ./model/367-0.1066.hdf5\n","\n","Epoch 368: val_loss improved from 0.10664 to 0.10658, saving model to ./model/368-0.1066.hdf5\n","\n","Epoch 369: val_loss did not improve from 0.10658\n","\n","Epoch 370: val_loss did not improve from 0.10658\n","\n","Epoch 371: val_loss improved from 0.10658 to 0.10603, saving model to ./model/371-0.1060.hdf5\n","\n","Epoch 372: val_loss did not improve from 0.10603\n","\n","Epoch 373: val_loss did not improve from 0.10603\n","\n","Epoch 374: val_loss improved from 0.10603 to 0.10582, saving model to ./model/374-0.1058.hdf5\n","\n","Epoch 375: val_loss improved from 0.10582 to 0.10557, saving model to ./model/375-0.1056.hdf5\n","\n","Epoch 376: val_loss did not improve from 0.10557\n","\n","Epoch 377: val_loss did not improve from 0.10557\n","\n","Epoch 378: val_loss improved from 0.10557 to 0.10542, saving model to ./model/378-0.1054.hdf5\n","\n","Epoch 379: val_loss improved from 0.10542 to 0.10519, saving model to ./model/379-0.1052.hdf5\n","\n","Epoch 380: val_loss did not improve from 0.10519\n","\n","Epoch 381: val_loss did not improve from 0.10519\n","\n","Epoch 382: val_loss did not improve from 0.10519\n","\n","Epoch 383: val_loss did not improve from 0.10519\n","\n","Epoch 384: val_loss did not improve from 0.10519\n","\n","Epoch 385: val_loss did not improve from 0.10519\n","\n","Epoch 386: val_loss improved from 0.10519 to 0.10511, saving model to ./model/386-0.1051.hdf5\n","\n","Epoch 387: val_loss did not improve from 0.10511\n","\n","Epoch 388: val_loss did not improve from 0.10511\n","\n","Epoch 389: val_loss did not improve from 0.10511\n","\n","Epoch 390: val_loss improved from 0.10511 to 0.10500, saving model to ./model/390-0.1050.hdf5\n","\n","Epoch 391: val_loss did not improve from 0.10500\n","\n","Epoch 392: val_loss did not improve from 0.10500\n","\n","Epoch 393: val_loss improved from 0.10500 to 0.10491, saving model to ./model/393-0.1049.hdf5\n","\n","Epoch 394: val_loss improved from 0.10491 to 0.10425, saving model to ./model/394-0.1042.hdf5\n","\n","Epoch 395: val_loss improved from 0.10425 to 0.10423, saving model to ./model/395-0.1042.hdf5\n","\n","Epoch 396: val_loss did not improve from 0.10423\n","\n","Epoch 397: val_loss did not improve from 0.10423\n","\n","Epoch 398: val_loss did not improve from 0.10423\n","\n","Epoch 399: val_loss improved from 0.10423 to 0.10398, saving model to ./model/399-0.1040.hdf5\n","\n","Epoch 400: val_loss did not improve from 0.10398\n","\n","Epoch 401: val_loss did not improve from 0.10398\n","\n","Epoch 402: val_loss did not improve from 0.10398\n","\n","Epoch 403: val_loss did not improve from 0.10398\n","\n","Epoch 404: val_loss did not improve from 0.10398\n","\n","Epoch 405: val_loss did not improve from 0.10398\n","\n","Epoch 406: val_loss did not improve from 0.10398\n","\n","Epoch 407: val_loss did not improve from 0.10398\n","\n","Epoch 408: val_loss did not improve from 0.10398\n","\n","Epoch 409: val_loss did not improve from 0.10398\n","\n","Epoch 410: val_loss improved from 0.10398 to 0.10355, saving model to ./model/410-0.1035.hdf5\n","\n","Epoch 411: val_loss did not improve from 0.10355\n","\n","Epoch 412: val_loss did not improve from 0.10355\n","\n","Epoch 413: val_loss did not improve from 0.10355\n","\n","Epoch 414: val_loss did not improve from 0.10355\n","\n","Epoch 415: val_loss did not improve from 0.10355\n","\n","Epoch 416: val_loss did not improve from 0.10355\n","\n","Epoch 417: val_loss did not improve from 0.10355\n","\n","Epoch 418: val_loss improved from 0.10355 to 0.10313, saving model to ./model/418-0.1031.hdf5\n","\n","Epoch 419: val_loss did not improve from 0.10313\n","\n","Epoch 420: val_loss did not improve from 0.10313\n","\n","Epoch 421: val_loss did not improve from 0.10313\n","\n","Epoch 422: val_loss did not improve from 0.10313\n","\n","Epoch 423: val_loss did not improve from 0.10313\n","\n","Epoch 424: val_loss did not improve from 0.10313\n","\n","Epoch 425: val_loss did not improve from 0.10313\n","\n","Epoch 426: val_loss did not improve from 0.10313\n","\n","Epoch 427: val_loss did not improve from 0.10313\n","\n","Epoch 428: val_loss did not improve from 0.10313\n","\n","Epoch 429: val_loss did not improve from 0.10313\n","\n","Epoch 430: val_loss did not improve from 0.10313\n","\n","Epoch 431: val_loss did not improve from 0.10313\n","\n","Epoch 432: val_loss did not improve from 0.10313\n","\n","Epoch 433: val_loss did not improve from 0.10313\n","\n","Epoch 434: val_loss did not improve from 0.10313\n","\n","Epoch 435: val_loss improved from 0.10313 to 0.10289, saving model to ./model/435-0.1029.hdf5\n","\n","Epoch 436: val_loss improved from 0.10289 to 0.10279, saving model to ./model/436-0.1028.hdf5\n","\n","Epoch 437: val_loss did not improve from 0.10279\n","\n","Epoch 438: val_loss did not improve from 0.10279\n","\n","Epoch 439: val_loss did not improve from 0.10279\n","\n","Epoch 440: val_loss did not improve from 0.10279\n","\n","Epoch 441: val_loss improved from 0.10279 to 0.10269, saving model to ./model/441-0.1027.hdf5\n","\n","Epoch 442: val_loss did not improve from 0.10269\n","\n","Epoch 443: val_loss did not improve from 0.10269\n","\n","Epoch 444: val_loss did not improve from 0.10269\n","\n","Epoch 445: val_loss improved from 0.10269 to 0.10260, saving model to ./model/445-0.1026.hdf5\n","\n","Epoch 446: val_loss improved from 0.10260 to 0.10243, saving model to ./model/446-0.1024.hdf5\n","\n","Epoch 447: val_loss did not improve from 0.10243\n","\n","Epoch 448: val_loss did not improve from 0.10243\n","\n","Epoch 449: val_loss did not improve from 0.10243\n","\n","Epoch 450: val_loss improved from 0.10243 to 0.10214, saving model to ./model/450-0.1021.hdf5\n","\n","Epoch 451: val_loss improved from 0.10214 to 0.10194, saving model to ./model/451-0.1019.hdf5\n","\n","Epoch 452: val_loss did not improve from 0.10194\n","\n","Epoch 453: val_loss did not improve from 0.10194\n","\n","Epoch 454: val_loss did not improve from 0.10194\n","\n","Epoch 455: val_loss did not improve from 0.10194\n","\n","Epoch 456: val_loss did not improve from 0.10194\n","\n","Epoch 457: val_loss did not improve from 0.10194\n","\n","Epoch 458: val_loss did not improve from 0.10194\n","\n","Epoch 459: val_loss did not improve from 0.10194\n","\n","Epoch 460: val_loss did not improve from 0.10194\n","\n","Epoch 461: val_loss improved from 0.10194 to 0.10188, saving model to ./model/461-0.1019.hdf5\n","\n","Epoch 462: val_loss did not improve from 0.10188\n","\n","Epoch 463: val_loss did not improve from 0.10188\n","\n","Epoch 464: val_loss did not improve from 0.10188\n","\n","Epoch 465: val_loss did not improve from 0.10188\n","\n","Epoch 466: val_loss did not improve from 0.10188\n","\n","Epoch 467: val_loss did not improve from 0.10188\n","\n","Epoch 468: val_loss did not improve from 0.10188\n","\n","Epoch 469: val_loss improved from 0.10188 to 0.10186, saving model to ./model/469-0.1019.hdf5\n","\n","Epoch 470: val_loss did not improve from 0.10186\n","\n","Epoch 471: val_loss did not improve from 0.10186\n","\n","Epoch 472: val_loss did not improve from 0.10186\n","\n","Epoch 473: val_loss improved from 0.10186 to 0.10185, saving model to ./model/473-0.1019.hdf5\n","\n","Epoch 474: val_loss did not improve from 0.10185\n","\n","Epoch 475: val_loss did not improve from 0.10185\n","\n","Epoch 476: val_loss improved from 0.10185 to 0.10177, saving model to ./model/476-0.1018.hdf5\n","\n","Epoch 477: val_loss improved from 0.10177 to 0.10161, saving model to ./model/477-0.1016.hdf5\n","\n","Epoch 478: val_loss improved from 0.10161 to 0.10160, saving model to ./model/478-0.1016.hdf5\n","\n","Epoch 479: val_loss improved from 0.10160 to 0.10157, saving model to ./model/479-0.1016.hdf5\n","\n","Epoch 480: val_loss did not improve from 0.10157\n","\n","Epoch 481: val_loss improved from 0.10157 to 0.10125, saving model to ./model/481-0.1012.hdf5\n","\n","Epoch 482: val_loss improved from 0.10125 to 0.10097, saving model to ./model/482-0.1010.hdf5\n","\n","Epoch 483: val_loss did not improve from 0.10097\n","\n","Epoch 484: val_loss did not improve from 0.10097\n","\n","Epoch 485: val_loss did not improve from 0.10097\n","\n","Epoch 486: val_loss improved from 0.10097 to 0.10068, saving model to ./model/486-0.1007.hdf5\n","\n","Epoch 487: val_loss improved from 0.10068 to 0.10064, saving model to ./model/487-0.1006.hdf5\n","\n","Epoch 488: val_loss did not improve from 0.10064\n","\n","Epoch 489: val_loss did not improve from 0.10064\n","\n","Epoch 490: val_loss did not improve from 0.10064\n","\n","Epoch 491: val_loss improved from 0.10064 to 0.10050, saving model to ./model/491-0.1005.hdf5\n","\n","Epoch 492: val_loss did not improve from 0.10050\n","\n","Epoch 493: val_loss did not improve from 0.10050\n","\n","Epoch 494: val_loss did not improve from 0.10050\n","\n","Epoch 495: val_loss did not improve from 0.10050\n","\n","Epoch 496: val_loss improved from 0.10050 to 0.10043, saving model to ./model/496-0.1004.hdf5\n","\n","Epoch 497: val_loss did not improve from 0.10043\n","\n","Epoch 498: val_loss did not improve from 0.10043\n","\n","Epoch 499: val_loss did not improve from 0.10043\n","\n","Epoch 500: val_loss did not improve from 0.10043\n","\n","Epoch 501: val_loss did not improve from 0.10043\n","\n","Epoch 502: val_loss did not improve from 0.10043\n","\n","Epoch 503: val_loss did not improve from 0.10043\n","\n","Epoch 504: val_loss did not improve from 0.10043\n","\n","Epoch 505: val_loss did not improve from 0.10043\n","\n","Epoch 506: val_loss did not improve from 0.10043\n","\n","Epoch 507: val_loss did not improve from 0.10043\n","\n","Epoch 508: val_loss did not improve from 0.10043\n","\n","Epoch 509: val_loss did not improve from 0.10043\n","\n","Epoch 510: val_loss did not improve from 0.10043\n","\n","Epoch 511: val_loss did not improve from 0.10043\n","\n","Epoch 512: val_loss did not improve from 0.10043\n","\n","Epoch 513: val_loss did not improve from 0.10043\n","\n","Epoch 514: val_loss did not improve from 0.10043\n","\n","Epoch 515: val_loss did not improve from 0.10043\n","\n","Epoch 516: val_loss did not improve from 0.10043\n","\n","Epoch 517: val_loss did not improve from 0.10043\n","\n","Epoch 518: val_loss did not improve from 0.10043\n","\n","Epoch 519: val_loss did not improve from 0.10043\n","\n","Epoch 520: val_loss did not improve from 0.10043\n","\n","Epoch 521: val_loss did not improve from 0.10043\n","\n","Epoch 522: val_loss did not improve from 0.10043\n","\n","Epoch 523: val_loss did not improve from 0.10043\n","\n","Epoch 524: val_loss did not improve from 0.10043\n","\n","Epoch 525: val_loss did not improve from 0.10043\n","\n","Epoch 526: val_loss did not improve from 0.10043\n","\n","Epoch 527: val_loss did not improve from 0.10043\n","\n","Epoch 528: val_loss did not improve from 0.10043\n","\n","Epoch 529: val_loss did not improve from 0.10043\n","\n","Epoch 530: val_loss did not improve from 0.10043\n","\n","Epoch 531: val_loss did not improve from 0.10043\n","\n","Epoch 532: val_loss did not improve from 0.10043\n","\n","Epoch 533: val_loss did not improve from 0.10043\n","\n","Epoch 534: val_loss did not improve from 0.10043\n","\n","Epoch 535: val_loss improved from 0.10043 to 0.10036, saving model to ./model/535-0.1004.hdf5\n","\n","Epoch 536: val_loss did not improve from 0.10036\n","\n","Epoch 537: val_loss did not improve from 0.10036\n","\n","Epoch 538: val_loss did not improve from 0.10036\n","\n","Epoch 539: val_loss did not improve from 0.10036\n","\n","Epoch 540: val_loss did not improve from 0.10036\n","\n","Epoch 541: val_loss did not improve from 0.10036\n","\n","Epoch 542: val_loss did not improve from 0.10036\n","\n","Epoch 543: val_loss improved from 0.10036 to 0.10034, saving model to ./model/543-0.1003.hdf5\n","\n","Epoch 544: val_loss improved from 0.10034 to 0.10026, saving model to ./model/544-0.1003.hdf5\n","\n","Epoch 545: val_loss did not improve from 0.10026\n","\n","Epoch 546: val_loss did not improve from 0.10026\n","\n","Epoch 547: val_loss did not improve from 0.10026\n","\n","Epoch 548: val_loss improved from 0.10026 to 0.10024, saving model to ./model/548-0.1002.hdf5\n","\n","Epoch 549: val_loss did not improve from 0.10024\n","\n","Epoch 550: val_loss did not improve from 0.10024\n","\n","Epoch 551: val_loss did not improve from 0.10024\n","\n","Epoch 552: val_loss did not improve from 0.10024\n","\n","Epoch 553: val_loss did not improve from 0.10024\n","\n","Epoch 554: val_loss did not improve from 0.10024\n","\n","Epoch 555: val_loss did not improve from 0.10024\n","\n","Epoch 556: val_loss did not improve from 0.10024\n","\n","Epoch 557: val_loss did not improve from 0.10024\n","\n","Epoch 558: val_loss did not improve from 0.10024\n","\n","Epoch 559: val_loss did not improve from 0.10024\n","\n","Epoch 560: val_loss did not improve from 0.10024\n","\n","Epoch 561: val_loss did not improve from 0.10024\n","\n","Epoch 562: val_loss did not improve from 0.10024\n","\n","Epoch 563: val_loss did not improve from 0.10024\n","\n","Epoch 564: val_loss improved from 0.10024 to 0.10021, saving model to ./model/564-0.1002.hdf5\n","\n","Epoch 565: val_loss improved from 0.10021 to 0.10013, saving model to ./model/565-0.1001.hdf5\n","\n","Epoch 566: val_loss did not improve from 0.10013\n","\n","Epoch 567: val_loss did not improve from 0.10013\n","\n","Epoch 568: val_loss improved from 0.10013 to 0.10011, saving model to ./model/568-0.1001.hdf5\n","\n","Epoch 569: val_loss improved from 0.10011 to 0.10000, saving model to ./model/569-0.1000.hdf5\n","\n","Epoch 570: val_loss did not improve from 0.10000\n","\n","Epoch 571: val_loss did not improve from 0.10000\n","\n","Epoch 572: val_loss did not improve from 0.10000\n","\n","Epoch 573: val_loss did not improve from 0.10000\n","\n","Epoch 574: val_loss improved from 0.10000 to 0.09980, saving model to ./model/574-0.0998.hdf5\n","\n","Epoch 575: val_loss improved from 0.09980 to 0.09971, saving model to ./model/575-0.0997.hdf5\n","\n","Epoch 576: val_loss did not improve from 0.09971\n","\n","Epoch 577: val_loss did not improve from 0.09971\n","\n","Epoch 578: val_loss did not improve from 0.09971\n","\n","Epoch 579: val_loss did not improve from 0.09971\n","\n","Epoch 580: val_loss did not improve from 0.09971\n","\n","Epoch 581: val_loss did not improve from 0.09971\n","\n","Epoch 582: val_loss did not improve from 0.09971\n","\n","Epoch 583: val_loss did not improve from 0.09971\n","\n","Epoch 584: val_loss did not improve from 0.09971\n","\n","Epoch 585: val_loss did not improve from 0.09971\n","\n","Epoch 586: val_loss did not improve from 0.09971\n","\n","Epoch 587: val_loss did not improve from 0.09971\n","\n","Epoch 588: val_loss did not improve from 0.09971\n","\n","Epoch 589: val_loss did not improve from 0.09971\n","\n","Epoch 590: val_loss improved from 0.09971 to 0.09964, saving model to ./model/590-0.0996.hdf5\n","\n","Epoch 591: val_loss did not improve from 0.09964\n","\n","Epoch 592: val_loss did not improve from 0.09964\n","\n","Epoch 593: val_loss did not improve from 0.09964\n","\n","Epoch 594: val_loss did not improve from 0.09964\n","\n","Epoch 595: val_loss did not improve from 0.09964\n","\n","Epoch 596: val_loss did not improve from 0.09964\n","\n","Epoch 597: val_loss improved from 0.09964 to 0.09940, saving model to ./model/597-0.0994.hdf5\n","\n","Epoch 598: val_loss improved from 0.09940 to 0.09935, saving model to ./model/598-0.0993.hdf5\n","\n","Epoch 599: val_loss did not improve from 0.09935\n","\n","Epoch 600: val_loss did not improve from 0.09935\n","\n","Epoch 601: val_loss did not improve from 0.09935\n","\n","Epoch 602: val_loss did not improve from 0.09935\n","\n","Epoch 603: val_loss did not improve from 0.09935\n","\n","Epoch 604: val_loss improved from 0.09935 to 0.09922, saving model to ./model/604-0.0992.hdf5\n","\n","Epoch 605: val_loss did not improve from 0.09922\n","\n","Epoch 606: val_loss did not improve from 0.09922\n","\n","Epoch 607: val_loss did not improve from 0.09922\n","\n","Epoch 608: val_loss did not improve from 0.09922\n","\n","Epoch 609: val_loss did not improve from 0.09922\n","\n","Epoch 610: val_loss did not improve from 0.09922\n","\n","Epoch 611: val_loss did not improve from 0.09922\n","\n","Epoch 612: val_loss did not improve from 0.09922\n","\n","Epoch 613: val_loss did not improve from 0.09922\n","\n","Epoch 614: val_loss did not improve from 0.09922\n","\n","Epoch 615: val_loss did not improve from 0.09922\n","\n","Epoch 616: val_loss did not improve from 0.09922\n","\n","Epoch 617: val_loss did not improve from 0.09922\n","\n","Epoch 618: val_loss did not improve from 0.09922\n","\n","Epoch 619: val_loss did not improve from 0.09922\n","\n","Epoch 620: val_loss did not improve from 0.09922\n","\n","Epoch 621: val_loss did not improve from 0.09922\n","\n","Epoch 622: val_loss did not improve from 0.09922\n","\n","Epoch 623: val_loss improved from 0.09922 to 0.09916, saving model to ./model/623-0.0992.hdf5\n","\n","Epoch 624: val_loss improved from 0.09916 to 0.09900, saving model to ./model/624-0.0990.hdf5\n","\n","Epoch 625: val_loss did not improve from 0.09900\n","\n","Epoch 626: val_loss did not improve from 0.09900\n","\n","Epoch 627: val_loss did not improve from 0.09900\n","\n","Epoch 628: val_loss did not improve from 0.09900\n","\n","Epoch 629: val_loss did not improve from 0.09900\n","\n","Epoch 630: val_loss did not improve from 0.09900\n","\n","Epoch 631: val_loss did not improve from 0.09900\n","\n","Epoch 632: val_loss improved from 0.09900 to 0.09881, saving model to ./model/632-0.0988.hdf5\n","\n","Epoch 633: val_loss did not improve from 0.09881\n","\n","Epoch 634: val_loss did not improve from 0.09881\n","\n","Epoch 635: val_loss did not improve from 0.09881\n","\n","Epoch 636: val_loss did not improve from 0.09881\n","\n","Epoch 637: val_loss did not improve from 0.09881\n","\n","Epoch 638: val_loss did not improve from 0.09881\n","\n","Epoch 639: val_loss did not improve from 0.09881\n","\n","Epoch 640: val_loss did not improve from 0.09881\n","\n","Epoch 641: val_loss did not improve from 0.09881\n","\n","Epoch 642: val_loss did not improve from 0.09881\n","\n","Epoch 643: val_loss did not improve from 0.09881\n","\n","Epoch 644: val_loss did not improve from 0.09881\n","\n","Epoch 645: val_loss did not improve from 0.09881\n","\n","Epoch 646: val_loss did not improve from 0.09881\n","\n","Epoch 647: val_loss did not improve from 0.09881\n","\n","Epoch 648: val_loss did not improve from 0.09881\n","\n","Epoch 649: val_loss did not improve from 0.09881\n","\n","Epoch 650: val_loss did not improve from 0.09881\n","\n","Epoch 651: val_loss improved from 0.09881 to 0.09876, saving model to ./model/651-0.0988.hdf5\n","\n","Epoch 652: val_loss did not improve from 0.09876\n","\n","Epoch 653: val_loss did not improve from 0.09876\n","\n","Epoch 654: val_loss did not improve from 0.09876\n","\n","Epoch 655: val_loss improved from 0.09876 to 0.09875, saving model to ./model/655-0.0987.hdf5\n","\n","Epoch 656: val_loss improved from 0.09875 to 0.09868, saving model to ./model/656-0.0987.hdf5\n","\n","Epoch 657: val_loss did not improve from 0.09868\n","\n","Epoch 658: val_loss did not improve from 0.09868\n","\n","Epoch 659: val_loss improved from 0.09868 to 0.09864, saving model to ./model/659-0.0986.hdf5\n","\n","Epoch 660: val_loss did not improve from 0.09864\n","\n","Epoch 661: val_loss did not improve from 0.09864\n","\n","Epoch 662: val_loss did not improve from 0.09864\n","\n","Epoch 663: val_loss did not improve from 0.09864\n","\n","Epoch 664: val_loss did not improve from 0.09864\n","\n","Epoch 665: val_loss did not improve from 0.09864\n","\n","Epoch 666: val_loss did not improve from 0.09864\n","\n","Epoch 667: val_loss improved from 0.09864 to 0.09853, saving model to ./model/667-0.0985.hdf5\n","\n","Epoch 668: val_loss improved from 0.09853 to 0.09849, saving model to ./model/668-0.0985.hdf5\n","\n","Epoch 669: val_loss did not improve from 0.09849\n","\n","Epoch 670: val_loss did not improve from 0.09849\n","\n","Epoch 671: val_loss did not improve from 0.09849\n","\n","Epoch 672: val_loss did not improve from 0.09849\n","\n","Epoch 673: val_loss did not improve from 0.09849\n","\n","Epoch 674: val_loss did not improve from 0.09849\n","\n","Epoch 675: val_loss did not improve from 0.09849\n","\n","Epoch 676: val_loss did not improve from 0.09849\n","\n","Epoch 677: val_loss did not improve from 0.09849\n","\n","Epoch 678: val_loss improved from 0.09849 to 0.09846, saving model to ./model/678-0.0985.hdf5\n","\n","Epoch 679: val_loss improved from 0.09846 to 0.09845, saving model to ./model/679-0.0985.hdf5\n","\n","Epoch 680: val_loss did not improve from 0.09845\n","\n","Epoch 681: val_loss did not improve from 0.09845\n","\n","Epoch 682: val_loss did not improve from 0.09845\n","\n","Epoch 683: val_loss improved from 0.09845 to 0.09839, saving model to ./model/683-0.0984.hdf5\n","\n","Epoch 684: val_loss improved from 0.09839 to 0.09839, saving model to ./model/684-0.0984.hdf5\n","\n","Epoch 685: val_loss did not improve from 0.09839\n","\n","Epoch 686: val_loss did not improve from 0.09839\n","\n","Epoch 687: val_loss did not improve from 0.09839\n","\n","Epoch 688: val_loss did not improve from 0.09839\n","\n","Epoch 689: val_loss improved from 0.09839 to 0.09831, saving model to ./model/689-0.0983.hdf5\n","\n","Epoch 690: val_loss improved from 0.09831 to 0.09820, saving model to ./model/690-0.0982.hdf5\n","\n","Epoch 691: val_loss improved from 0.09820 to 0.09818, saving model to ./model/691-0.0982.hdf5\n","\n","Epoch 692: val_loss did not improve from 0.09818\n","\n","Epoch 693: val_loss did not improve from 0.09818\n","\n","Epoch 694: val_loss did not improve from 0.09818\n","\n","Epoch 695: val_loss did not improve from 0.09818\n","\n","Epoch 696: val_loss did not improve from 0.09818\n","\n","Epoch 697: val_loss did not improve from 0.09818\n","\n","Epoch 698: val_loss did not improve from 0.09818\n","\n","Epoch 699: val_loss did not improve from 0.09818\n","\n","Epoch 700: val_loss did not improve from 0.09818\n","\n","Epoch 701: val_loss did not improve from 0.09818\n","\n","Epoch 702: val_loss did not improve from 0.09818\n","\n","Epoch 703: val_loss did not improve from 0.09818\n","\n","Epoch 704: val_loss did not improve from 0.09818\n","\n","Epoch 705: val_loss did not improve from 0.09818\n","\n","Epoch 706: val_loss improved from 0.09818 to 0.09814, saving model to ./model/706-0.0981.hdf5\n","\n","Epoch 707: val_loss did not improve from 0.09814\n","\n","Epoch 708: val_loss did not improve from 0.09814\n","\n","Epoch 709: val_loss did not improve from 0.09814\n","\n","Epoch 710: val_loss did not improve from 0.09814\n","\n","Epoch 711: val_loss did not improve from 0.09814\n","\n","Epoch 712: val_loss did not improve from 0.09814\n","\n","Epoch 713: val_loss did not improve from 0.09814\n","\n","Epoch 714: val_loss did not improve from 0.09814\n","\n","Epoch 715: val_loss did not improve from 0.09814\n","\n","Epoch 716: val_loss did not improve from 0.09814\n","\n","Epoch 717: val_loss improved from 0.09814 to 0.09806, saving model to ./model/717-0.0981.hdf5\n","\n","Epoch 718: val_loss improved from 0.09806 to 0.09802, saving model to ./model/718-0.0980.hdf5\n","\n","Epoch 719: val_loss did not improve from 0.09802\n","\n","Epoch 720: val_loss did not improve from 0.09802\n","\n","Epoch 721: val_loss improved from 0.09802 to 0.09801, saving model to ./model/721-0.0980.hdf5\n","\n","Epoch 722: val_loss improved from 0.09801 to 0.09790, saving model to ./model/722-0.0979.hdf5\n","\n","Epoch 723: val_loss did not improve from 0.09790\n","\n","Epoch 724: val_loss did not improve from 0.09790\n","\n","Epoch 725: val_loss did not improve from 0.09790\n","\n","Epoch 726: val_loss did not improve from 0.09790\n","\n","Epoch 727: val_loss did not improve from 0.09790\n","\n","Epoch 728: val_loss did not improve from 0.09790\n","\n","Epoch 729: val_loss did not improve from 0.09790\n","\n","Epoch 730: val_loss did not improve from 0.09790\n","\n","Epoch 731: val_loss did not improve from 0.09790\n","\n","Epoch 732: val_loss did not improve from 0.09790\n","\n","Epoch 733: val_loss did not improve from 0.09790\n","\n","Epoch 734: val_loss did not improve from 0.09790\n","\n","Epoch 735: val_loss improved from 0.09790 to 0.09790, saving model to ./model/735-0.0979.hdf5\n","\n","Epoch 736: val_loss improved from 0.09790 to 0.09788, saving model to ./model/736-0.0979.hdf5\n","\n","Epoch 737: val_loss improved from 0.09788 to 0.09781, saving model to ./model/737-0.0978.hdf5\n","\n","Epoch 738: val_loss improved from 0.09781 to 0.09781, saving model to ./model/738-0.0978.hdf5\n","\n","Epoch 739: val_loss did not improve from 0.09781\n","\n","Epoch 740: val_loss did not improve from 0.09781\n","\n","Epoch 741: val_loss did not improve from 0.09781\n","\n","Epoch 742: val_loss improved from 0.09781 to 0.09771, saving model to ./model/742-0.0977.hdf5\n","\n","Epoch 743: val_loss improved from 0.09771 to 0.09759, saving model to ./model/743-0.0976.hdf5\n","\n","Epoch 744: val_loss improved from 0.09759 to 0.09759, saving model to ./model/744-0.0976.hdf5\n","\n","Epoch 745: val_loss did not improve from 0.09759\n","\n","Epoch 746: val_loss did not improve from 0.09759\n","\n","Epoch 747: val_loss did not improve from 0.09759\n","\n","Epoch 748: val_loss did not improve from 0.09759\n","\n","Epoch 749: val_loss did not improve from 0.09759\n","\n","Epoch 750: val_loss improved from 0.09759 to 0.09752, saving model to ./model/750-0.0975.hdf5\n","\n","Epoch 751: val_loss did not improve from 0.09752\n","\n","Epoch 752: val_loss did not improve from 0.09752\n","\n","Epoch 753: val_loss did not improve from 0.09752\n","\n","Epoch 754: val_loss did not improve from 0.09752\n","\n","Epoch 755: val_loss did not improve from 0.09752\n","\n","Epoch 756: val_loss did not improve from 0.09752\n","\n","Epoch 757: val_loss improved from 0.09752 to 0.09747, saving model to ./model/757-0.0975.hdf5\n","\n","Epoch 758: val_loss improved from 0.09747 to 0.09740, saving model to ./model/758-0.0974.hdf5\n","\n","Epoch 759: val_loss improved from 0.09740 to 0.09737, saving model to ./model/759-0.0974.hdf5\n","\n","Epoch 760: val_loss improved from 0.09737 to 0.09736, saving model to ./model/760-0.0974.hdf5\n","\n","Epoch 761: val_loss did not improve from 0.09736\n","\n","Epoch 762: val_loss improved from 0.09736 to 0.09735, saving model to ./model/762-0.0974.hdf5\n","\n","Epoch 763: val_loss improved from 0.09735 to 0.09728, saving model to ./model/763-0.0973.hdf5\n","\n","Epoch 764: val_loss improved from 0.09728 to 0.09719, saving model to ./model/764-0.0972.hdf5\n","\n","Epoch 765: val_loss improved from 0.09719 to 0.09711, saving model to ./model/765-0.0971.hdf5\n","\n","Epoch 766: val_loss did not improve from 0.09711\n","\n","Epoch 767: val_loss did not improve from 0.09711\n","\n","Epoch 768: val_loss improved from 0.09711 to 0.09702, saving model to ./model/768-0.0970.hdf5\n","\n","Epoch 769: val_loss improved from 0.09702 to 0.09695, saving model to ./model/769-0.0970.hdf5\n","\n","Epoch 770: val_loss improved from 0.09695 to 0.09694, saving model to ./model/770-0.0969.hdf5\n","\n","Epoch 771: val_loss did not improve from 0.09694\n","\n","Epoch 772: val_loss improved from 0.09694 to 0.09693, saving model to ./model/772-0.0969.hdf5\n","\n","Epoch 773: val_loss improved from 0.09693 to 0.09678, saving model to ./model/773-0.0968.hdf5\n","\n","Epoch 774: val_loss improved from 0.09678 to 0.09672, saving model to ./model/774-0.0967.hdf5\n","\n","Epoch 775: val_loss did not improve from 0.09672\n","\n","Epoch 776: val_loss did not improve from 0.09672\n","\n","Epoch 777: val_loss did not improve from 0.09672\n","\n","Epoch 778: val_loss improved from 0.09672 to 0.09666, saving model to ./model/778-0.0967.hdf5\n","\n","Epoch 779: val_loss improved from 0.09666 to 0.09657, saving model to ./model/779-0.0966.hdf5\n","\n","Epoch 780: val_loss did not improve from 0.09657\n","\n","Epoch 781: val_loss did not improve from 0.09657\n","\n","Epoch 782: val_loss did not improve from 0.09657\n","\n","Epoch 783: val_loss did not improve from 0.09657\n","\n","Epoch 784: val_loss improved from 0.09657 to 0.09639, saving model to ./model/784-0.0964.hdf5\n","\n","Epoch 785: val_loss improved from 0.09639 to 0.09630, saving model to ./model/785-0.0963.hdf5\n","\n","Epoch 786: val_loss did not improve from 0.09630\n","\n","Epoch 787: val_loss did not improve from 0.09630\n","\n","Epoch 788: val_loss did not improve from 0.09630\n","\n","Epoch 789: val_loss did not improve from 0.09630\n","\n","Epoch 790: val_loss improved from 0.09630 to 0.09615, saving model to ./model/790-0.0961.hdf5\n","\n","Epoch 791: val_loss improved from 0.09615 to 0.09612, saving model to ./model/791-0.0961.hdf5\n","\n","Epoch 792: val_loss did not improve from 0.09612\n","\n","Epoch 793: val_loss did not improve from 0.09612\n","\n","Epoch 794: val_loss did not improve from 0.09612\n","\n","Epoch 795: val_loss did not improve from 0.09612\n","\n","Epoch 796: val_loss improved from 0.09612 to 0.09605, saving model to ./model/796-0.0960.hdf5\n","\n","Epoch 797: val_loss improved from 0.09605 to 0.09602, saving model to ./model/797-0.0960.hdf5\n","\n","Epoch 798: val_loss did not improve from 0.09602\n","\n","Epoch 799: val_loss did not improve from 0.09602\n","\n","Epoch 800: val_loss did not improve from 0.09602\n","\n","Epoch 801: val_loss improved from 0.09602 to 0.09591, saving model to ./model/801-0.0959.hdf5\n","\n","Epoch 802: val_loss improved from 0.09591 to 0.09586, saving model to ./model/802-0.0959.hdf5\n","\n","Epoch 803: val_loss did not improve from 0.09586\n","\n","Epoch 804: val_loss did not improve from 0.09586\n","\n","Epoch 805: val_loss improved from 0.09586 to 0.09574, saving model to ./model/805-0.0957.hdf5\n","\n","Epoch 806: val_loss improved from 0.09574 to 0.09574, saving model to ./model/806-0.0957.hdf5\n","\n","Epoch 807: val_loss improved from 0.09574 to 0.09573, saving model to ./model/807-0.0957.hdf5\n","\n","Epoch 808: val_loss improved from 0.09573 to 0.09569, saving model to ./model/808-0.0957.hdf5\n","\n","Epoch 809: val_loss did not improve from 0.09569\n","\n","Epoch 810: val_loss did not improve from 0.09569\n","\n","Epoch 811: val_loss improved from 0.09569 to 0.09567, saving model to ./model/811-0.0957.hdf5\n","\n","Epoch 812: val_loss improved from 0.09567 to 0.09564, saving model to ./model/812-0.0956.hdf5\n","\n","Epoch 813: val_loss improved from 0.09564 to 0.09561, saving model to ./model/813-0.0956.hdf5\n","\n","Epoch 814: val_loss improved from 0.09561 to 0.09560, saving model to ./model/814-0.0956.hdf5\n","\n","Epoch 815: val_loss improved from 0.09560 to 0.09558, saving model to ./model/815-0.0956.hdf5\n","\n","Epoch 816: val_loss improved from 0.09558 to 0.09555, saving model to ./model/816-0.0956.hdf5\n","\n","Epoch 817: val_loss improved from 0.09555 to 0.09553, saving model to ./model/817-0.0955.hdf5\n","\n","Epoch 818: val_loss did not improve from 0.09553\n","\n","Epoch 819: val_loss did not improve from 0.09553\n","\n","Epoch 820: val_loss did not improve from 0.09553\n","\n","Epoch 821: val_loss improved from 0.09553 to 0.09552, saving model to ./model/821-0.0955.hdf5\n","\n","Epoch 822: val_loss improved from 0.09552 to 0.09539, saving model to ./model/822-0.0954.hdf5\n","\n","Epoch 823: val_loss improved from 0.09539 to 0.09535, saving model to ./model/823-0.0953.hdf5\n","\n","Epoch 824: val_loss did not improve from 0.09535\n","\n","Epoch 825: val_loss did not improve from 0.09535\n","\n","Epoch 826: val_loss improved from 0.09535 to 0.09531, saving model to ./model/826-0.0953.hdf5\n","\n","Epoch 827: val_loss improved from 0.09531 to 0.09529, saving model to ./model/827-0.0953.hdf5\n","\n","Epoch 828: val_loss did not improve from 0.09529\n","\n","Epoch 829: val_loss did not improve from 0.09529\n","\n","Epoch 830: val_loss improved from 0.09529 to 0.09515, saving model to ./model/830-0.0951.hdf5\n","\n","Epoch 831: val_loss improved from 0.09515 to 0.09508, saving model to ./model/831-0.0951.hdf5\n","\n","Epoch 832: val_loss did not improve from 0.09508\n","\n","Epoch 833: val_loss did not improve from 0.09508\n","\n","Epoch 834: val_loss did not improve from 0.09508\n","\n","Epoch 835: val_loss improved from 0.09508 to 0.09505, saving model to ./model/835-0.0950.hdf5\n","\n","Epoch 836: val_loss improved from 0.09505 to 0.09493, saving model to ./model/836-0.0949.hdf5\n","\n","Epoch 837: val_loss improved from 0.09493 to 0.09491, saving model to ./model/837-0.0949.hdf5\n","\n","Epoch 838: val_loss did not improve from 0.09491\n","\n","Epoch 839: val_loss did not improve from 0.09491\n","\n","Epoch 840: val_loss did not improve from 0.09491\n","\n","Epoch 841: val_loss did not improve from 0.09491\n","\n","Epoch 842: val_loss improved from 0.09491 to 0.09488, saving model to ./model/842-0.0949.hdf5\n","\n","Epoch 843: val_loss improved from 0.09488 to 0.09488, saving model to ./model/843-0.0949.hdf5\n","\n","Epoch 844: val_loss did not improve from 0.09488\n","\n","Epoch 845: val_loss did not improve from 0.09488\n","\n","Epoch 846: val_loss improved from 0.09488 to 0.09481, saving model to ./model/846-0.0948.hdf5\n","\n","Epoch 847: val_loss improved from 0.09481 to 0.09474, saving model to ./model/847-0.0947.hdf5\n","\n","Epoch 848: val_loss did not improve from 0.09474\n","\n","Epoch 849: val_loss did not improve from 0.09474\n","\n","Epoch 850: val_loss improved from 0.09474 to 0.09473, saving model to ./model/850-0.0947.hdf5\n","\n","Epoch 851: val_loss improved from 0.09473 to 0.09464, saving model to ./model/851-0.0946.hdf5\n","\n","Epoch 852: val_loss improved from 0.09464 to 0.09463, saving model to ./model/852-0.0946.hdf5\n","\n","Epoch 853: val_loss did not improve from 0.09463\n","\n","Epoch 854: val_loss did not improve from 0.09463\n","\n","Epoch 855: val_loss improved from 0.09463 to 0.09455, saving model to ./model/855-0.0945.hdf5\n","\n","Epoch 856: val_loss improved from 0.09455 to 0.09450, saving model to ./model/856-0.0945.hdf5\n","\n","Epoch 857: val_loss did not improve from 0.09450\n","\n","Epoch 858: val_loss did not improve from 0.09450\n","\n","Epoch 859: val_loss improved from 0.09450 to 0.09441, saving model to ./model/859-0.0944.hdf5\n","\n","Epoch 860: val_loss improved from 0.09441 to 0.09439, saving model to ./model/860-0.0944.hdf5\n","\n","Epoch 861: val_loss did not improve from 0.09439\n","\n","Epoch 862: val_loss did not improve from 0.09439\n","\n","Epoch 863: val_loss did not improve from 0.09439\n","\n","Epoch 864: val_loss improved from 0.09439 to 0.09437, saving model to ./model/864-0.0944.hdf5\n","\n","Epoch 865: val_loss did not improve from 0.09437\n","\n","Epoch 866: val_loss did not improve from 0.09437\n","\n","Epoch 867: val_loss did not improve from 0.09437\n","\n","Epoch 868: val_loss improved from 0.09437 to 0.09427, saving model to ./model/868-0.0943.hdf5\n","\n","Epoch 869: val_loss improved from 0.09427 to 0.09423, saving model to ./model/869-0.0942.hdf5\n","\n","Epoch 870: val_loss did not improve from 0.09423\n","\n","Epoch 871: val_loss did not improve from 0.09423\n","\n","Epoch 872: val_loss did not improve from 0.09423\n","\n","Epoch 873: val_loss did not improve from 0.09423\n","\n","Epoch 874: val_loss improved from 0.09423 to 0.09422, saving model to ./model/874-0.0942.hdf5\n","\n","Epoch 875: val_loss did not improve from 0.09422\n","\n","Epoch 876: val_loss improved from 0.09422 to 0.09421, saving model to ./model/876-0.0942.hdf5\n","\n","Epoch 877: val_loss improved from 0.09421 to 0.09412, saving model to ./model/877-0.0941.hdf5\n","\n","Epoch 878: val_loss improved from 0.09412 to 0.09408, saving model to ./model/878-0.0941.hdf5\n","\n","Epoch 879: val_loss improved from 0.09408 to 0.09407, saving model to ./model/879-0.0941.hdf5\n","\n","Epoch 880: val_loss did not improve from 0.09407\n","\n","Epoch 881: val_loss did not improve from 0.09407\n","\n","Epoch 882: val_loss improved from 0.09407 to 0.09407, saving model to ./model/882-0.0941.hdf5\n","\n","Epoch 883: val_loss improved from 0.09407 to 0.09400, saving model to ./model/883-0.0940.hdf5\n","\n","Epoch 884: val_loss improved from 0.09400 to 0.09397, saving model to ./model/884-0.0940.hdf5\n","\n","Epoch 885: val_loss did not improve from 0.09397\n","\n","Epoch 886: val_loss did not improve from 0.09397\n","\n","Epoch 887: val_loss improved from 0.09397 to 0.09393, saving model to ./model/887-0.0939.hdf5\n","\n","Epoch 888: val_loss improved from 0.09393 to 0.09387, saving model to ./model/888-0.0939.hdf5\n","\n","Epoch 889: val_loss improved from 0.09387 to 0.09385, saving model to ./model/889-0.0938.hdf5\n","\n","Epoch 890: val_loss did not improve from 0.09385\n","\n","Epoch 891: val_loss did not improve from 0.09385\n","\n","Epoch 892: val_loss did not improve from 0.09385\n","\n","Epoch 893: val_loss improved from 0.09385 to 0.09376, saving model to ./model/893-0.0938.hdf5\n","\n","Epoch 894: val_loss improved from 0.09376 to 0.09363, saving model to ./model/894-0.0936.hdf5\n","\n","Epoch 895: val_loss did not improve from 0.09363\n","\n","Epoch 896: val_loss did not improve from 0.09363\n","\n","Epoch 897: val_loss did not improve from 0.09363\n","\n","Epoch 898: val_loss did not improve from 0.09363\n","\n","Epoch 899: val_loss did not improve from 0.09363\n","\n","Epoch 900: val_loss did not improve from 0.09363\n","\n","Epoch 901: val_loss did not improve from 0.09363\n","\n","Epoch 902: val_loss did not improve from 0.09363\n","\n","Epoch 903: val_loss improved from 0.09363 to 0.09359, saving model to ./model/903-0.0936.hdf5\n","\n","Epoch 904: val_loss did not improve from 0.09359\n","\n","Epoch 905: val_loss did not improve from 0.09359\n","\n","Epoch 906: val_loss improved from 0.09359 to 0.09359, saving model to ./model/906-0.0936.hdf5\n","\n","Epoch 907: val_loss improved from 0.09359 to 0.09353, saving model to ./model/907-0.0935.hdf5\n","\n","Epoch 908: val_loss did not improve from 0.09353\n","\n","Epoch 909: val_loss did not improve from 0.09353\n","\n","Epoch 910: val_loss improved from 0.09353 to 0.09346, saving model to ./model/910-0.0935.hdf5\n","\n","Epoch 911: val_loss improved from 0.09346 to 0.09343, saving model to ./model/911-0.0934.hdf5\n","\n","Epoch 912: val_loss did not improve from 0.09343\n","\n","Epoch 913: val_loss did not improve from 0.09343\n","\n","Epoch 914: val_loss improved from 0.09343 to 0.09342, saving model to ./model/914-0.0934.hdf5\n","\n","Epoch 915: val_loss improved from 0.09342 to 0.09332, saving model to ./model/915-0.0933.hdf5\n","\n","Epoch 916: val_loss did not improve from 0.09332\n","\n","Epoch 917: val_loss did not improve from 0.09332\n","\n","Epoch 918: val_loss did not improve from 0.09332\n","\n","Epoch 919: val_loss did not improve from 0.09332\n","\n","Epoch 920: val_loss did not improve from 0.09332\n","\n","Epoch 921: val_loss improved from 0.09332 to 0.09322, saving model to ./model/921-0.0932.hdf5\n","\n","Epoch 922: val_loss improved from 0.09322 to 0.09316, saving model to ./model/922-0.0932.hdf5\n","\n","Epoch 923: val_loss did not improve from 0.09316\n","\n","Epoch 924: val_loss did not improve from 0.09316\n","\n","Epoch 925: val_loss did not improve from 0.09316\n","\n","Epoch 926: val_loss did not improve from 0.09316\n","\n","Epoch 927: val_loss did not improve from 0.09316\n","\n","Epoch 928: val_loss did not improve from 0.09316\n","\n","Epoch 929: val_loss did not improve from 0.09316\n","\n","Epoch 930: val_loss improved from 0.09316 to 0.09314, saving model to ./model/930-0.0931.hdf5\n","\n","Epoch 931: val_loss did not improve from 0.09314\n","\n","Epoch 932: val_loss improved from 0.09314 to 0.09312, saving model to ./model/932-0.0931.hdf5\n","\n","Epoch 933: val_loss improved from 0.09312 to 0.09306, saving model to ./model/933-0.0931.hdf5\n","\n","Epoch 934: val_loss improved from 0.09306 to 0.09303, saving model to ./model/934-0.0930.hdf5\n","\n","Epoch 935: val_loss did not improve from 0.09303\n","\n","Epoch 936: val_loss did not improve from 0.09303\n","\n","Epoch 937: val_loss did not improve from 0.09303\n","\n","Epoch 938: val_loss improved from 0.09303 to 0.09299, saving model to ./model/938-0.0930.hdf5\n","\n","Epoch 939: val_loss improved from 0.09299 to 0.09296, saving model to ./model/939-0.0930.hdf5\n","\n","Epoch 940: val_loss improved from 0.09296 to 0.09290, saving model to ./model/940-0.0929.hdf5\n","\n","Epoch 941: val_loss did not improve from 0.09290\n","\n","Epoch 942: val_loss did not improve from 0.09290\n","\n","Epoch 943: val_loss did not improve from 0.09290\n","\n","Epoch 944: val_loss improved from 0.09290 to 0.09283, saving model to ./model/944-0.0928.hdf5\n","\n","Epoch 945: val_loss improved from 0.09283 to 0.09280, saving model to ./model/945-0.0928.hdf5\n","\n","Epoch 946: val_loss did not improve from 0.09280\n","\n","Epoch 947: val_loss did not improve from 0.09280\n","\n","Epoch 948: val_loss did not improve from 0.09280\n","\n","Epoch 949: val_loss improved from 0.09280 to 0.09266, saving model to ./model/949-0.0927.hdf5\n","\n","Epoch 950: val_loss improved from 0.09266 to 0.09263, saving model to ./model/950-0.0926.hdf5\n","\n","Epoch 951: val_loss did not improve from 0.09263\n","\n","Epoch 952: val_loss did not improve from 0.09263\n","\n","Epoch 953: val_loss did not improve from 0.09263\n","\n","Epoch 954: val_loss did not improve from 0.09263\n","\n","Epoch 955: val_loss improved from 0.09263 to 0.09262, saving model to ./model/955-0.0926.hdf5\n","\n","Epoch 956: val_loss did not improve from 0.09262\n","\n","Epoch 957: val_loss did not improve from 0.09262\n","\n","Epoch 958: val_loss did not improve from 0.09262\n","\n","Epoch 959: val_loss did not improve from 0.09262\n","\n","Epoch 960: val_loss did not improve from 0.09262\n","\n","Epoch 961: val_loss improved from 0.09262 to 0.09260, saving model to ./model/961-0.0926.hdf5\n","\n","Epoch 962: val_loss improved from 0.09260 to 0.09259, saving model to ./model/962-0.0926.hdf5\n","\n","Epoch 963: val_loss improved from 0.09259 to 0.09254, saving model to ./model/963-0.0925.hdf5\n","\n","Epoch 964: val_loss improved from 0.09254 to 0.09247, saving model to ./model/964-0.0925.hdf5\n","\n","Epoch 965: val_loss improved from 0.09247 to 0.09242, saving model to ./model/965-0.0924.hdf5\n","\n","Epoch 966: val_loss improved from 0.09242 to 0.09241, saving model to ./model/966-0.0924.hdf5\n","\n","Epoch 967: val_loss did not improve from 0.09241\n","\n","Epoch 968: val_loss did not improve from 0.09241\n","\n","Epoch 969: val_loss did not improve from 0.09241\n","\n","Epoch 970: val_loss improved from 0.09241 to 0.09236, saving model to ./model/970-0.0924.hdf5\n","\n","Epoch 971: val_loss improved from 0.09236 to 0.09230, saving model to ./model/971-0.0923.hdf5\n","\n","Epoch 972: val_loss did not improve from 0.09230\n","\n","Epoch 973: val_loss did not improve from 0.09230\n","\n","Epoch 974: val_loss improved from 0.09230 to 0.09223, saving model to ./model/974-0.0922.hdf5\n","\n","Epoch 975: val_loss improved from 0.09223 to 0.09223, saving model to ./model/975-0.0922.hdf5\n","\n","Epoch 976: val_loss did not improve from 0.09223\n","\n","Epoch 977: val_loss improved from 0.09223 to 0.09220, saving model to ./model/977-0.0922.hdf5\n","\n","Epoch 978: val_loss did not improve from 0.09220\n","\n","Epoch 979: val_loss did not improve from 0.09220\n","\n","Epoch 980: val_loss improved from 0.09220 to 0.09212, saving model to ./model/980-0.0921.hdf5\n","\n","Epoch 981: val_loss improved from 0.09212 to 0.09212, saving model to ./model/981-0.0921.hdf5\n","\n","Epoch 982: val_loss did not improve from 0.09212\n","\n","Epoch 983: val_loss did not improve from 0.09212\n","\n","Epoch 984: val_loss did not improve from 0.09212\n","\n","Epoch 985: val_loss did not improve from 0.09212\n","\n","Epoch 986: val_loss did not improve from 0.09212\n","\n","Epoch 987: val_loss did not improve from 0.09212\n","\n","Epoch 988: val_loss improved from 0.09212 to 0.09211, saving model to ./model/988-0.0921.hdf5\n","\n","Epoch 989: val_loss did not improve from 0.09211\n","\n","Epoch 990: val_loss improved from 0.09211 to 0.09207, saving model to ./model/990-0.0921.hdf5\n","\n","Epoch 991: val_loss improved from 0.09207 to 0.09205, saving model to ./model/991-0.0920.hdf5\n","\n","Epoch 992: val_loss did not improve from 0.09205\n","\n","Epoch 993: val_loss did not improve from 0.09205\n","\n","Epoch 994: val_loss did not improve from 0.09205\n","\n","Epoch 995: val_loss improved from 0.09205 to 0.09191, saving model to ./model/995-0.0919.hdf5\n","\n","Epoch 996: val_loss improved from 0.09191 to 0.09184, saving model to ./model/996-0.0918.hdf5\n","\n","Epoch 997: val_loss did not improve from 0.09184\n","\n","Epoch 998: val_loss did not improve from 0.09184\n","\n","Epoch 999: val_loss did not improve from 0.09184\n","\n","Epoch 1000: val_loss improved from 0.09184 to 0.09181, saving model to ./model/1000-0.0918.hdf5\n","\n","Epoch 1001: val_loss improved from 0.09181 to 0.09175, saving model to ./model/1001-0.0918.hdf5\n","\n","Epoch 1002: val_loss did not improve from 0.09175\n","\n","Epoch 1003: val_loss did not improve from 0.09175\n","\n","Epoch 1004: val_loss did not improve from 0.09175\n","\n","Epoch 1005: val_loss did not improve from 0.09175\n","\n","Epoch 1006: val_loss did not improve from 0.09175\n","\n","Epoch 1007: val_loss did not improve from 0.09175\n","\n","Epoch 1008: val_loss did not improve from 0.09175\n","\n","Epoch 1009: val_loss did not improve from 0.09175\n","\n","Epoch 1010: val_loss did not improve from 0.09175\n","\n","Epoch 1011: val_loss improved from 0.09175 to 0.09175, saving model to ./model/1011-0.0917.hdf5\n","\n","Epoch 1012: val_loss improved from 0.09175 to 0.09169, saving model to ./model/1012-0.0917.hdf5\n","\n","Epoch 1013: val_loss improved from 0.09169 to 0.09162, saving model to ./model/1013-0.0916.hdf5\n","\n","Epoch 1014: val_loss improved from 0.09162 to 0.09159, saving model to ./model/1014-0.0916.hdf5\n","\n","Epoch 1015: val_loss improved from 0.09159 to 0.09157, saving model to ./model/1015-0.0916.hdf5\n","\n","Epoch 1016: val_loss did not improve from 0.09157\n","\n","Epoch 1017: val_loss did not improve from 0.09157\n","\n","Epoch 1018: val_loss did not improve from 0.09157\n","\n","Epoch 1019: val_loss did not improve from 0.09157\n","\n","Epoch 1020: val_loss did not improve from 0.09157\n","\n","Epoch 1021: val_loss did not improve from 0.09157\n","\n","Epoch 1022: val_loss did not improve from 0.09157\n","\n","Epoch 1023: val_loss improved from 0.09157 to 0.09156, saving model to ./model/1023-0.0916.hdf5\n","\n","Epoch 1024: val_loss improved from 0.09156 to 0.09146, saving model to ./model/1024-0.0915.hdf5\n","\n","Epoch 1025: val_loss did not improve from 0.09146\n","\n","Epoch 1026: val_loss did not improve from 0.09146\n","\n","Epoch 1027: val_loss did not improve from 0.09146\n","\n","Epoch 1028: val_loss did not improve from 0.09146\n","\n","Epoch 1029: val_loss did not improve from 0.09146\n","\n","Epoch 1030: val_loss improved from 0.09146 to 0.09143, saving model to ./model/1030-0.0914.hdf5\n","\n","Epoch 1031: val_loss improved from 0.09143 to 0.09140, saving model to ./model/1031-0.0914.hdf5\n","\n","Epoch 1032: val_loss did not improve from 0.09140\n","\n","Epoch 1033: val_loss did not improve from 0.09140\n","\n","Epoch 1034: val_loss did not improve from 0.09140\n","\n","Epoch 1035: val_loss did not improve from 0.09140\n","\n","Epoch 1036: val_loss improved from 0.09140 to 0.09134, saving model to ./model/1036-0.0913.hdf5\n","\n","Epoch 1037: val_loss did not improve from 0.09134\n","\n","Epoch 1038: val_loss did not improve from 0.09134\n","\n","Epoch 1039: val_loss improved from 0.09134 to 0.09132, saving model to ./model/1039-0.0913.hdf5\n","\n","Epoch 1040: val_loss improved from 0.09132 to 0.09131, saving model to ./model/1040-0.0913.hdf5\n","\n","Epoch 1041: val_loss improved from 0.09131 to 0.09130, saving model to ./model/1041-0.0913.hdf5\n","\n","Epoch 1042: val_loss improved from 0.09130 to 0.09129, saving model to ./model/1042-0.0913.hdf5\n","\n","Epoch 1043: val_loss improved from 0.09129 to 0.09127, saving model to ./model/1043-0.0913.hdf5\n","\n","Epoch 1044: val_loss improved from 0.09127 to 0.09124, saving model to ./model/1044-0.0912.hdf5\n","\n","Epoch 1045: val_loss improved from 0.09124 to 0.09121, saving model to ./model/1045-0.0912.hdf5\n","\n","Epoch 1046: val_loss did not improve from 0.09121\n","\n","Epoch 1047: val_loss did not improve from 0.09121\n","\n","Epoch 1048: val_loss did not improve from 0.09121\n","\n","Epoch 1049: val_loss did not improve from 0.09121\n","\n","Epoch 1050: val_loss improved from 0.09121 to 0.09112, saving model to ./model/1050-0.0911.hdf5\n","\n","Epoch 1051: val_loss improved from 0.09112 to 0.09107, saving model to ./model/1051-0.0911.hdf5\n","\n","Epoch 1052: val_loss did not improve from 0.09107\n","\n","Epoch 1053: val_loss did not improve from 0.09107\n","\n","Epoch 1054: val_loss did not improve from 0.09107\n","\n","Epoch 1055: val_loss did not improve from 0.09107\n","\n","Epoch 1056: val_loss improved from 0.09107 to 0.09106, saving model to ./model/1056-0.0911.hdf5\n","\n","Epoch 1057: val_loss did not improve from 0.09106\n","\n","Epoch 1058: val_loss did not improve from 0.09106\n","\n","Epoch 1059: val_loss did not improve from 0.09106\n","\n","Epoch 1060: val_loss improved from 0.09106 to 0.09103, saving model to ./model/1060-0.0910.hdf5\n","\n","Epoch 1061: val_loss improved from 0.09103 to 0.09095, saving model to ./model/1061-0.0909.hdf5\n","\n","Epoch 1062: val_loss improved from 0.09095 to 0.09095, saving model to ./model/1062-0.0909.hdf5\n","\n","Epoch 1063: val_loss did not improve from 0.09095\n","\n","Epoch 1064: val_loss did not improve from 0.09095\n","\n","Epoch 1065: val_loss improved from 0.09095 to 0.09093, saving model to ./model/1065-0.0909.hdf5\n","\n","Epoch 1066: val_loss did not improve from 0.09093\n","\n","Epoch 1067: val_loss did not improve from 0.09093\n","\n","Epoch 1068: val_loss did not improve from 0.09093\n","\n","Epoch 1069: val_loss did not improve from 0.09093\n","\n","Epoch 1070: val_loss improved from 0.09093 to 0.09091, saving model to ./model/1070-0.0909.hdf5\n","\n","Epoch 1071: val_loss did not improve from 0.09091\n","\n","Epoch 1072: val_loss did not improve from 0.09091\n","\n","Epoch 1073: val_loss improved from 0.09091 to 0.09091, saving model to ./model/1073-0.0909.hdf5\n","\n","Epoch 1074: val_loss improved from 0.09091 to 0.09088, saving model to ./model/1074-0.0909.hdf5\n","\n","Epoch 1075: val_loss did not improve from 0.09088\n","\n","Epoch 1076: val_loss improved from 0.09088 to 0.09086, saving model to ./model/1076-0.0909.hdf5\n","\n","Epoch 1077: val_loss improved from 0.09086 to 0.09081, saving model to ./model/1077-0.0908.hdf5\n","\n","Epoch 1078: val_loss did not improve from 0.09081\n","\n","Epoch 1079: val_loss improved from 0.09081 to 0.09081, saving model to ./model/1079-0.0908.hdf5\n","\n","Epoch 1080: val_loss improved from 0.09081 to 0.09077, saving model to ./model/1080-0.0908.hdf5\n","\n","Epoch 1081: val_loss improved from 0.09077 to 0.09075, saving model to ./model/1081-0.0908.hdf5\n","\n","Epoch 1082: val_loss did not improve from 0.09075\n","\n","Epoch 1083: val_loss did not improve from 0.09075\n","\n","Epoch 1084: val_loss improved from 0.09075 to 0.09074, saving model to ./model/1084-0.0907.hdf5\n","\n","Epoch 1085: val_loss improved from 0.09074 to 0.09064, saving model to ./model/1085-0.0906.hdf5\n","\n","Epoch 1086: val_loss improved from 0.09064 to 0.09062, saving model to ./model/1086-0.0906.hdf5\n","\n","Epoch 1087: val_loss did not improve from 0.09062\n","\n","Epoch 1088: val_loss did not improve from 0.09062\n","\n","Epoch 1089: val_loss did not improve from 0.09062\n","\n","Epoch 1090: val_loss did not improve from 0.09062\n","\n","Epoch 1091: val_loss did not improve from 0.09062\n","\n","Epoch 1092: val_loss improved from 0.09062 to 0.09062, saving model to ./model/1092-0.0906.hdf5\n","\n","Epoch 1093: val_loss improved from 0.09062 to 0.09060, saving model to ./model/1093-0.0906.hdf5\n","\n","Epoch 1094: val_loss did not improve from 0.09060\n","\n","Epoch 1095: val_loss did not improve from 0.09060\n","\n","Epoch 1096: val_loss did not improve from 0.09060\n","\n","Epoch 1097: val_loss did not improve from 0.09060\n","\n","Epoch 1098: val_loss did not improve from 0.09060\n","\n","Epoch 1099: val_loss improved from 0.09060 to 0.09059, saving model to ./model/1099-0.0906.hdf5\n","\n","Epoch 1100: val_loss improved from 0.09059 to 0.09057, saving model to ./model/1100-0.0906.hdf5\n","\n","Epoch 1101: val_loss did not improve from 0.09057\n","\n","Epoch 1102: val_loss did not improve from 0.09057\n","\n","Epoch 1103: val_loss did not improve from 0.09057\n","\n","Epoch 1104: val_loss improved from 0.09057 to 0.09053, saving model to ./model/1104-0.0905.hdf5\n","\n","Epoch 1105: val_loss improved from 0.09053 to 0.09047, saving model to ./model/1105-0.0905.hdf5\n","\n","Epoch 1106: val_loss improved from 0.09047 to 0.09047, saving model to ./model/1106-0.0905.hdf5\n","\n","Epoch 1107: val_loss did not improve from 0.09047\n","\n","Epoch 1108: val_loss did not improve from 0.09047\n","\n","Epoch 1109: val_loss did not improve from 0.09047\n","\n","Epoch 1110: val_loss did not improve from 0.09047\n","\n","Epoch 1111: val_loss improved from 0.09047 to 0.09037, saving model to ./model/1111-0.0904.hdf5\n","\n","Epoch 1112: val_loss improved from 0.09037 to 0.09032, saving model to ./model/1112-0.0903.hdf5\n","\n","Epoch 1113: val_loss did not improve from 0.09032\n","\n","Epoch 1114: val_loss did not improve from 0.09032\n","\n","Epoch 1115: val_loss did not improve from 0.09032\n","\n","Epoch 1116: val_loss did not improve from 0.09032\n","\n","Epoch 1117: val_loss improved from 0.09032 to 0.09028, saving model to ./model/1117-0.0903.hdf5\n","\n","Epoch 1118: val_loss improved from 0.09028 to 0.09026, saving model to ./model/1118-0.0903.hdf5\n","\n","Epoch 1119: val_loss did not improve from 0.09026\n","\n","Epoch 1120: val_loss did not improve from 0.09026\n","\n","Epoch 1121: val_loss did not improve from 0.09026\n","\n","Epoch 1122: val_loss did not improve from 0.09026\n","\n","Epoch 1123: val_loss improved from 0.09026 to 0.09022, saving model to ./model/1123-0.0902.hdf5\n","\n","Epoch 1124: val_loss did not improve from 0.09022\n","\n","Epoch 1125: val_loss did not improve from 0.09022\n","\n","Epoch 1126: val_loss did not improve from 0.09022\n","\n","Epoch 1127: val_loss did not improve from 0.09022\n","\n","Epoch 1128: val_loss improved from 0.09022 to 0.09021, saving model to ./model/1128-0.0902.hdf5\n","\n","Epoch 1129: val_loss did not improve from 0.09021\n","\n","Epoch 1130: val_loss did not improve from 0.09021\n","\n","Epoch 1131: val_loss improved from 0.09021 to 0.09019, saving model to ./model/1131-0.0902.hdf5\n","\n","Epoch 1132: val_loss improved from 0.09019 to 0.09011, saving model to ./model/1132-0.0901.hdf5\n","\n","Epoch 1133: val_loss improved from 0.09011 to 0.09006, saving model to ./model/1133-0.0901.hdf5\n","\n","Epoch 1134: val_loss did not improve from 0.09006\n","\n","Epoch 1135: val_loss did not improve from 0.09006\n","\n","Epoch 1136: val_loss did not improve from 0.09006\n","\n","Epoch 1137: val_loss did not improve from 0.09006\n","\n","Epoch 1138: val_loss did not improve from 0.09006\n","\n","Epoch 1139: val_loss did not improve from 0.09006\n","\n","Epoch 1140: val_loss did not improve from 0.09006\n","\n","Epoch 1141: val_loss did not improve from 0.09006\n","\n","Epoch 1142: val_loss improved from 0.09006 to 0.09003, saving model to ./model/1142-0.0900.hdf5\n","\n","Epoch 1143: val_loss improved from 0.09003 to 0.09002, saving model to ./model/1143-0.0900.hdf5\n","\n","Epoch 1144: val_loss did not improve from 0.09002\n","\n","Epoch 1145: val_loss did not improve from 0.09002\n","\n","Epoch 1146: val_loss did not improve from 0.09002\n","\n","Epoch 1147: val_loss improved from 0.09002 to 0.09000, saving model to ./model/1147-0.0900.hdf5\n","\n","Epoch 1148: val_loss improved from 0.09000 to 0.08997, saving model to ./model/1148-0.0900.hdf5\n","\n","Epoch 1149: val_loss improved from 0.08997 to 0.08996, saving model to ./model/1149-0.0900.hdf5\n","\n","Epoch 1150: val_loss improved from 0.08996 to 0.08995, saving model to ./model/1150-0.0900.hdf5\n","\n","Epoch 1151: val_loss improved from 0.08995 to 0.08995, saving model to ./model/1151-0.0900.hdf5\n","\n","Epoch 1152: val_loss did not improve from 0.08995\n","\n","Epoch 1153: val_loss did not improve from 0.08995\n","\n","Epoch 1154: val_loss did not improve from 0.08995\n","\n","Epoch 1155: val_loss improved from 0.08995 to 0.08993, saving model to ./model/1155-0.0899.hdf5\n","\n","Epoch 1156: val_loss improved from 0.08993 to 0.08991, saving model to ./model/1156-0.0899.hdf5\n","\n","Epoch 1157: val_loss did not improve from 0.08991\n","\n","Epoch 1158: val_loss did not improve from 0.08991\n","\n","Epoch 1159: val_loss improved from 0.08991 to 0.08987, saving model to ./model/1159-0.0899.hdf5\n","\n","Epoch 1160: val_loss improved from 0.08987 to 0.08983, saving model to ./model/1160-0.0898.hdf5\n","\n","Epoch 1161: val_loss did not improve from 0.08983\n","\n","Epoch 1162: val_loss improved from 0.08983 to 0.08983, saving model to ./model/1162-0.0898.hdf5\n","\n","Epoch 1163: val_loss improved from 0.08983 to 0.08981, saving model to ./model/1163-0.0898.hdf5\n","\n","Epoch 1164: val_loss did not improve from 0.08981\n","\n","Epoch 1165: val_loss did not improve from 0.08981\n","\n","Epoch 1166: val_loss improved from 0.08981 to 0.08979, saving model to ./model/1166-0.0898.hdf5\n","\n","Epoch 1167: val_loss improved from 0.08979 to 0.08974, saving model to ./model/1167-0.0897.hdf5\n","\n","Epoch 1168: val_loss improved from 0.08974 to 0.08973, saving model to ./model/1168-0.0897.hdf5\n","\n","Epoch 1169: val_loss did not improve from 0.08973\n","\n","Epoch 1170: val_loss did not improve from 0.08973\n","\n","Epoch 1171: val_loss did not improve from 0.08973\n","\n","Epoch 1172: val_loss did not improve from 0.08973\n","\n","Epoch 1173: val_loss improved from 0.08973 to 0.08969, saving model to ./model/1173-0.0897.hdf5\n","\n","Epoch 1174: val_loss improved from 0.08969 to 0.08965, saving model to ./model/1174-0.0897.hdf5\n","\n","Epoch 1175: val_loss did not improve from 0.08965\n","\n","Epoch 1176: val_loss did not improve from 0.08965\n","\n","Epoch 1177: val_loss did not improve from 0.08965\n","\n","Epoch 1178: val_loss did not improve from 0.08965\n","\n","Epoch 1179: val_loss did not improve from 0.08965\n","\n","Epoch 1180: val_loss improved from 0.08965 to 0.08961, saving model to ./model/1180-0.0896.hdf5\n","\n","Epoch 1181: val_loss improved from 0.08961 to 0.08961, saving model to ./model/1181-0.0896.hdf5\n","\n","Epoch 1182: val_loss did not improve from 0.08961\n","\n","Epoch 1183: val_loss did not improve from 0.08961\n","\n","Epoch 1184: val_loss improved from 0.08961 to 0.08956, saving model to ./model/1184-0.0896.hdf5\n","\n","Epoch 1185: val_loss improved from 0.08956 to 0.08952, saving model to ./model/1185-0.0895.hdf5\n","\n","Epoch 1186: val_loss did not improve from 0.08952\n","\n","Epoch 1187: val_loss did not improve from 0.08952\n","\n","Epoch 1188: val_loss did not improve from 0.08952\n","\n","Epoch 1189: val_loss did not improve from 0.08952\n","\n","Epoch 1190: val_loss did not improve from 0.08952\n","\n","Epoch 1191: val_loss improved from 0.08952 to 0.08947, saving model to ./model/1191-0.0895.hdf5\n","\n","Epoch 1192: val_loss improved from 0.08947 to 0.08946, saving model to ./model/1192-0.0895.hdf5\n","\n","Epoch 1193: val_loss did not improve from 0.08946\n","\n","Epoch 1194: val_loss did not improve from 0.08946\n","\n","Epoch 1195: val_loss did not improve from 0.08946\n","\n","Epoch 1196: val_loss improved from 0.08946 to 0.08941, saving model to ./model/1196-0.0894.hdf5\n","\n","Epoch 1197: val_loss improved from 0.08941 to 0.08935, saving model to ./model/1197-0.0893.hdf5\n","\n","Epoch 1198: val_loss improved from 0.08935 to 0.08933, saving model to ./model/1198-0.0893.hdf5\n","\n","Epoch 1199: val_loss did not improve from 0.08933\n","\n","Epoch 1200: val_loss did not improve from 0.08933\n","\n","Epoch 1201: val_loss did not improve from 0.08933\n","\n","Epoch 1202: val_loss did not improve from 0.08933\n","\n","Epoch 1203: val_loss did not improve from 0.08933\n","\n","Epoch 1204: val_loss did not improve from 0.08933\n","\n","Epoch 1205: val_loss did not improve from 0.08933\n","\n","Epoch 1206: val_loss did not improve from 0.08933\n","\n","Epoch 1207: val_loss did not improve from 0.08933\n","\n","Epoch 1208: val_loss did not improve from 0.08933\n","\n","Epoch 1209: val_loss did not improve from 0.08933\n","\n","Epoch 1210: val_loss improved from 0.08933 to 0.08927, saving model to ./model/1210-0.0893.hdf5\n","\n","Epoch 1211: val_loss improved from 0.08927 to 0.08925, saving model to ./model/1211-0.0893.hdf5\n","\n","Epoch 1212: val_loss did not improve from 0.08925\n","\n","Epoch 1213: val_loss did not improve from 0.08925\n","\n","Epoch 1214: val_loss did not improve from 0.08925\n","\n","Epoch 1215: val_loss did not improve from 0.08925\n","\n","Epoch 1216: val_loss did not improve from 0.08925\n","\n","Epoch 1217: val_loss did not improve from 0.08925\n","\n","Epoch 1218: val_loss did not improve from 0.08925\n","\n","Epoch 1219: val_loss did not improve from 0.08925\n","\n","Epoch 1220: val_loss did not improve from 0.08925\n","\n","Epoch 1221: val_loss improved from 0.08925 to 0.08919, saving model to ./model/1221-0.0892.hdf5\n","\n","Epoch 1222: val_loss improved from 0.08919 to 0.08916, saving model to ./model/1222-0.0892.hdf5\n","\n","Epoch 1223: val_loss did not improve from 0.08916\n","\n","Epoch 1224: val_loss did not improve from 0.08916\n","\n","Epoch 1225: val_loss did not improve from 0.08916\n","\n","Epoch 1226: val_loss did not improve from 0.08916\n","\n","Epoch 1227: val_loss did not improve from 0.08916\n","\n","Epoch 1228: val_loss improved from 0.08916 to 0.08909, saving model to ./model/1228-0.0891.hdf5\n","\n","Epoch 1229: val_loss improved from 0.08909 to 0.08905, saving model to ./model/1229-0.0891.hdf5\n","\n","Epoch 1230: val_loss did not improve from 0.08905\n","\n","Epoch 1231: val_loss did not improve from 0.08905\n","\n","Epoch 1232: val_loss did not improve from 0.08905\n","\n","Epoch 1233: val_loss did not improve from 0.08905\n","\n","Epoch 1234: val_loss did not improve from 0.08905\n","\n","Epoch 1235: val_loss did not improve from 0.08905\n","\n","Epoch 1236: val_loss did not improve from 0.08905\n","\n","Epoch 1237: val_loss improved from 0.08905 to 0.08900, saving model to ./model/1237-0.0890.hdf5\n","\n","Epoch 1238: val_loss improved from 0.08900 to 0.08897, saving model to ./model/1238-0.0890.hdf5\n","\n","Epoch 1239: val_loss did not improve from 0.08897\n","\n","Epoch 1240: val_loss did not improve from 0.08897\n","\n","Epoch 1241: val_loss did not improve from 0.08897\n","\n","Epoch 1242: val_loss did not improve from 0.08897\n","\n","Epoch 1243: val_loss did not improve from 0.08897\n","\n","Epoch 1244: val_loss did not improve from 0.08897\n","\n","Epoch 1245: val_loss improved from 0.08897 to 0.08895, saving model to ./model/1245-0.0889.hdf5\n","\n","Epoch 1246: val_loss improved from 0.08895 to 0.08888, saving model to ./model/1246-0.0889.hdf5\n","\n","Epoch 1247: val_loss improved from 0.08888 to 0.08886, saving model to ./model/1247-0.0889.hdf5\n","\n","Epoch 1248: val_loss did not improve from 0.08886\n","\n","Epoch 1249: val_loss did not improve from 0.08886\n","\n","Epoch 1250: val_loss did not improve from 0.08886\n","\n","Epoch 1251: val_loss did not improve from 0.08886\n","\n","Epoch 1252: val_loss did not improve from 0.08886\n","\n","Epoch 1253: val_loss improved from 0.08886 to 0.08885, saving model to ./model/1253-0.0888.hdf5\n","\n","Epoch 1254: val_loss improved from 0.08885 to 0.08881, saving model to ./model/1254-0.0888.hdf5\n","\n","Epoch 1255: val_loss did not improve from 0.08881\n","\n","Epoch 1256: val_loss did not improve from 0.08881\n","\n","Epoch 1257: val_loss did not improve from 0.08881\n","\n","Epoch 1258: val_loss did not improve from 0.08881\n","\n","Epoch 1259: val_loss improved from 0.08881 to 0.08879, saving model to ./model/1259-0.0888.hdf5\n","\n","Epoch 1260: val_loss improved from 0.08879 to 0.08877, saving model to ./model/1260-0.0888.hdf5\n","\n","Epoch 1261: val_loss did not improve from 0.08877\n","\n","Epoch 1262: val_loss did not improve from 0.08877\n","\n","Epoch 1263: val_loss did not improve from 0.08877\n","\n","Epoch 1264: val_loss improved from 0.08877 to 0.08875, saving model to ./model/1264-0.0888.hdf5\n","\n","Epoch 1265: val_loss improved from 0.08875 to 0.08871, saving model to ./model/1265-0.0887.hdf5\n","\n","Epoch 1266: val_loss improved from 0.08871 to 0.08868, saving model to ./model/1266-0.0887.hdf5\n","\n","Epoch 1267: val_loss did not improve from 0.08868\n","\n","Epoch 1268: val_loss improved from 0.08868 to 0.08868, saving model to ./model/1268-0.0887.hdf5\n","\n","Epoch 1269: val_loss did not improve from 0.08868\n","\n","Epoch 1270: val_loss did not improve from 0.08868\n","\n","Epoch 1271: val_loss did not improve from 0.08868\n","\n","Epoch 1272: val_loss improved from 0.08868 to 0.08863, saving model to ./model/1272-0.0886.hdf5\n","\n","Epoch 1273: val_loss improved from 0.08863 to 0.08856, saving model to ./model/1273-0.0886.hdf5\n","\n","Epoch 1274: val_loss improved from 0.08856 to 0.08853, saving model to ./model/1274-0.0885.hdf5\n","\n","Epoch 1275: val_loss did not improve from 0.08853\n","\n","Epoch 1276: val_loss did not improve from 0.08853\n","\n","Epoch 1277: val_loss did not improve from 0.08853\n","\n","Epoch 1278: val_loss did not improve from 0.08853\n","\n","Epoch 1279: val_loss improved from 0.08853 to 0.08852, saving model to ./model/1279-0.0885.hdf5\n","\n","Epoch 1280: val_loss improved from 0.08852 to 0.08846, saving model to ./model/1280-0.0885.hdf5\n","\n","Epoch 1281: val_loss improved from 0.08846 to 0.08845, saving model to ./model/1281-0.0885.hdf5\n","\n","Epoch 1282: val_loss did not improve from 0.08845\n","\n","Epoch 1283: val_loss did not improve from 0.08845\n","\n","Epoch 1284: val_loss did not improve from 0.08845\n","\n","Epoch 1285: val_loss did not improve from 0.08845\n","\n","Epoch 1286: val_loss did not improve from 0.08845\n","\n","Epoch 1287: val_loss did not improve from 0.08845\n","\n","Epoch 1288: val_loss did not improve from 0.08845\n","\n","Epoch 1289: val_loss did not improve from 0.08845\n","\n","Epoch 1290: val_loss did not improve from 0.08845\n","\n","Epoch 1291: val_loss did not improve from 0.08845\n","\n","Epoch 1292: val_loss did not improve from 0.08845\n","\n","Epoch 1293: val_loss did not improve from 0.08845\n","\n","Epoch 1294: val_loss did not improve from 0.08845\n","\n","Epoch 1295: val_loss improved from 0.08845 to 0.08844, saving model to ./model/1295-0.0884.hdf5\n","\n","Epoch 1296: val_loss improved from 0.08844 to 0.08841, saving model to ./model/1296-0.0884.hdf5\n","\n","Epoch 1297: val_loss improved from 0.08841 to 0.08840, saving model to ./model/1297-0.0884.hdf5\n","\n","Epoch 1298: val_loss improved from 0.08840 to 0.08840, saving model to ./model/1298-0.0884.hdf5\n","\n","Epoch 1299: val_loss did not improve from 0.08840\n","\n","Epoch 1300: val_loss did not improve from 0.08840\n","\n","Epoch 1301: val_loss did not improve from 0.08840\n","\n","Epoch 1302: val_loss improved from 0.08840 to 0.08832, saving model to ./model/1302-0.0883.hdf5\n","\n","Epoch 1303: val_loss improved from 0.08832 to 0.08829, saving model to ./model/1303-0.0883.hdf5\n","\n","Epoch 1304: val_loss did not improve from 0.08829\n","\n","Epoch 1305: val_loss did not improve from 0.08829\n","\n","Epoch 1306: val_loss did not improve from 0.08829\n","\n","Epoch 1307: val_loss did not improve from 0.08829\n","\n","Epoch 1308: val_loss improved from 0.08829 to 0.08826, saving model to ./model/1308-0.0883.hdf5\n","\n","Epoch 1309: val_loss improved from 0.08826 to 0.08825, saving model to ./model/1309-0.0882.hdf5\n","\n","Epoch 1310: val_loss did not improve from 0.08825\n","\n","Epoch 1311: val_loss did not improve from 0.08825\n","\n","Epoch 1312: val_loss did not improve from 0.08825\n","\n","Epoch 1313: val_loss improved from 0.08825 to 0.08819, saving model to ./model/1313-0.0882.hdf5\n","\n","Epoch 1314: val_loss improved from 0.08819 to 0.08814, saving model to ./model/1314-0.0881.hdf5\n","\n","Epoch 1315: val_loss did not improve from 0.08814\n","\n","Epoch 1316: val_loss did not improve from 0.08814\n","\n","Epoch 1317: val_loss did not improve from 0.08814\n","\n","Epoch 1318: val_loss did not improve from 0.08814\n","\n","Epoch 1319: val_loss did not improve from 0.08814\n","\n","Epoch 1320: val_loss did not improve from 0.08814\n","\n","Epoch 1321: val_loss did not improve from 0.08814\n","\n","Epoch 1322: val_loss did not improve from 0.08814\n","\n","Epoch 1323: val_loss did not improve from 0.08814\n","\n","Epoch 1324: val_loss improved from 0.08814 to 0.08810, saving model to ./model/1324-0.0881.hdf5\n","\n","Epoch 1325: val_loss improved from 0.08810 to 0.08810, saving model to ./model/1325-0.0881.hdf5\n","\n","Epoch 1326: val_loss did not improve from 0.08810\n","\n","Epoch 1327: val_loss did not improve from 0.08810\n","\n","Epoch 1328: val_loss did not improve from 0.08810\n","\n","Epoch 1329: val_loss improved from 0.08810 to 0.08806, saving model to ./model/1329-0.0881.hdf5\n","\n","Epoch 1330: val_loss improved from 0.08806 to 0.08805, saving model to ./model/1330-0.0881.hdf5\n","\n","Epoch 1331: val_loss did not improve from 0.08805\n","\n","Epoch 1332: val_loss improved from 0.08805 to 0.08804, saving model to ./model/1332-0.0880.hdf5\n","\n","Epoch 1333: val_loss improved from 0.08804 to 0.08802, saving model to ./model/1333-0.0880.hdf5\n","\n","Epoch 1334: val_loss did not improve from 0.08802\n","\n","Epoch 1335: val_loss did not improve from 0.08802\n","\n","Epoch 1336: val_loss did not improve from 0.08802\n","\n","Epoch 1337: val_loss did not improve from 0.08802\n","\n","Epoch 1338: val_loss did not improve from 0.08802\n","\n","Epoch 1339: val_loss improved from 0.08802 to 0.08801, saving model to ./model/1339-0.0880.hdf5\n","\n","Epoch 1340: val_loss did not improve from 0.08801\n","\n","Epoch 1341: val_loss improved from 0.08801 to 0.08799, saving model to ./model/1341-0.0880.hdf5\n","\n","Epoch 1342: val_loss improved from 0.08799 to 0.08794, saving model to ./model/1342-0.0879.hdf5\n","\n","Epoch 1343: val_loss improved from 0.08794 to 0.08792, saving model to ./model/1343-0.0879.hdf5\n","\n","Epoch 1344: val_loss did not improve from 0.08792\n","\n","Epoch 1345: val_loss did not improve from 0.08792\n","\n","Epoch 1346: val_loss did not improve from 0.08792\n","\n","Epoch 1347: val_loss improved from 0.08792 to 0.08788, saving model to ./model/1347-0.0879.hdf5\n","\n","Epoch 1348: val_loss improved from 0.08788 to 0.08786, saving model to ./model/1348-0.0879.hdf5\n","\n","Epoch 1349: val_loss did not improve from 0.08786\n","\n","Epoch 1350: val_loss did not improve from 0.08786\n","\n","Epoch 1351: val_loss improved from 0.08786 to 0.08784, saving model to ./model/1351-0.0878.hdf5\n","\n","Epoch 1352: val_loss improved from 0.08784 to 0.08780, saving model to ./model/1352-0.0878.hdf5\n","\n","Epoch 1353: val_loss improved from 0.08780 to 0.08778, saving model to ./model/1353-0.0878.hdf5\n","\n","Epoch 1354: val_loss did not improve from 0.08778\n","\n","Epoch 1355: val_loss did not improve from 0.08778\n","\n","Epoch 1356: val_loss did not improve from 0.08778\n","\n","Epoch 1357: val_loss improved from 0.08778 to 0.08777, saving model to ./model/1357-0.0878.hdf5\n","\n","Epoch 1358: val_loss did not improve from 0.08777\n","\n","Epoch 1359: val_loss did not improve from 0.08777\n","\n","Epoch 1360: val_loss did not improve from 0.08777\n","\n","Epoch 1361: val_loss did not improve from 0.08777\n","\n","Epoch 1362: val_loss improved from 0.08777 to 0.08774, saving model to ./model/1362-0.0877.hdf5\n","\n","Epoch 1363: val_loss improved from 0.08774 to 0.08773, saving model to ./model/1363-0.0877.hdf5\n","\n","Epoch 1364: val_loss did not improve from 0.08773\n","\n","Epoch 1365: val_loss did not improve from 0.08773\n","\n","Epoch 1366: val_loss improved from 0.08773 to 0.08771, saving model to ./model/1366-0.0877.hdf5\n","\n","Epoch 1367: val_loss improved from 0.08771 to 0.08769, saving model to ./model/1367-0.0877.hdf5\n","\n","Epoch 1368: val_loss improved from 0.08769 to 0.08767, saving model to ./model/1368-0.0877.hdf5\n","\n","Epoch 1369: val_loss improved from 0.08767 to 0.08766, saving model to ./model/1369-0.0877.hdf5\n","\n","Epoch 1370: val_loss improved from 0.08766 to 0.08765, saving model to ./model/1370-0.0876.hdf5\n","\n","Epoch 1371: val_loss did not improve from 0.08765\n","\n","Epoch 1372: val_loss did not improve from 0.08765\n","\n","Epoch 1373: val_loss did not improve from 0.08765\n","\n","Epoch 1374: val_loss did not improve from 0.08765\n","\n","Epoch 1375: val_loss did not improve from 0.08765\n","\n","Epoch 1376: val_loss did not improve from 0.08765\n","\n","Epoch 1377: val_loss improved from 0.08765 to 0.08761, saving model to ./model/1377-0.0876.hdf5\n","\n","Epoch 1378: val_loss improved from 0.08761 to 0.08759, saving model to ./model/1378-0.0876.hdf5\n","\n","Epoch 1379: val_loss did not improve from 0.08759\n","\n","Epoch 1380: val_loss did not improve from 0.08759\n","\n","Epoch 1381: val_loss improved from 0.08759 to 0.08756, saving model to ./model/1381-0.0876.hdf5\n","\n","Epoch 1382: val_loss improved from 0.08756 to 0.08755, saving model to ./model/1382-0.0876.hdf5\n","\n","Epoch 1383: val_loss improved from 0.08755 to 0.08753, saving model to ./model/1383-0.0875.hdf5\n","\n","Epoch 1384: val_loss improved from 0.08753 to 0.08752, saving model to ./model/1384-0.0875.hdf5\n","\n","Epoch 1385: val_loss improved from 0.08752 to 0.08752, saving model to ./model/1385-0.0875.hdf5\n","\n","Epoch 1386: val_loss improved from 0.08752 to 0.08749, saving model to ./model/1386-0.0875.hdf5\n","\n","Epoch 1387: val_loss improved from 0.08749 to 0.08744, saving model to ./model/1387-0.0874.hdf5\n","\n","Epoch 1388: val_loss did not improve from 0.08744\n","\n","Epoch 1389: val_loss did not improve from 0.08744\n","\n","Epoch 1390: val_loss did not improve from 0.08744\n","\n","Epoch 1391: val_loss did not improve from 0.08744\n","\n","Epoch 1392: val_loss did not improve from 0.08744\n","\n","Epoch 1393: val_loss improved from 0.08744 to 0.08743, saving model to ./model/1393-0.0874.hdf5\n","\n","Epoch 1394: val_loss improved from 0.08743 to 0.08741, saving model to ./model/1394-0.0874.hdf5\n","\n","Epoch 1395: val_loss did not improve from 0.08741\n","\n","Epoch 1396: val_loss did not improve from 0.08741\n","\n","Epoch 1397: val_loss did not improve from 0.08741\n","\n","Epoch 1398: val_loss did not improve from 0.08741\n","\n","Epoch 1399: val_loss did not improve from 0.08741\n","\n","Epoch 1400: val_loss did not improve from 0.08741\n","\n","Epoch 1401: val_loss did not improve from 0.08741\n","\n","Epoch 1402: val_loss did not improve from 0.08741\n","\n","Epoch 1403: val_loss improved from 0.08741 to 0.08734, saving model to ./model/1403-0.0873.hdf5\n","\n","Epoch 1404: val_loss improved from 0.08734 to 0.08730, saving model to ./model/1404-0.0873.hdf5\n","\n","Epoch 1405: val_loss did not improve from 0.08730\n","\n","Epoch 1406: val_loss did not improve from 0.08730\n","\n","Epoch 1407: val_loss did not improve from 0.08730\n","\n","Epoch 1408: val_loss did not improve from 0.08730\n","\n","Epoch 1409: val_loss improved from 0.08730 to 0.08729, saving model to ./model/1409-0.0873.hdf5\n","\n","Epoch 1410: val_loss improved from 0.08729 to 0.08727, saving model to ./model/1410-0.0873.hdf5\n","\n","Epoch 1411: val_loss did not improve from 0.08727\n","\n","Epoch 1412: val_loss improved from 0.08727 to 0.08725, saving model to ./model/1412-0.0873.hdf5\n","\n","Epoch 1413: val_loss improved from 0.08725 to 0.08723, saving model to ./model/1413-0.0872.hdf5\n","\n","Epoch 1414: val_loss improved from 0.08723 to 0.08721, saving model to ./model/1414-0.0872.hdf5\n","\n","Epoch 1415: val_loss did not improve from 0.08721\n","\n","Epoch 1416: val_loss did not improve from 0.08721\n","\n","Epoch 1417: val_loss did not improve from 0.08721\n","\n","Epoch 1418: val_loss did not improve from 0.08721\n","\n","Epoch 1419: val_loss did not improve from 0.08721\n","\n","Epoch 1420: val_loss did not improve from 0.08721\n","\n","Epoch 1421: val_loss did not improve from 0.08721\n","\n","Epoch 1422: val_loss did not improve from 0.08721\n","\n","Epoch 1423: val_loss did not improve from 0.08721\n","\n","Epoch 1424: val_loss improved from 0.08721 to 0.08720, saving model to ./model/1424-0.0872.hdf5\n","\n","Epoch 1425: val_loss improved from 0.08720 to 0.08718, saving model to ./model/1425-0.0872.hdf5\n","\n","Epoch 1426: val_loss did not improve from 0.08718\n","\n","Epoch 1427: val_loss improved from 0.08718 to 0.08717, saving model to ./model/1427-0.0872.hdf5\n","\n","Epoch 1428: val_loss improved from 0.08717 to 0.08714, saving model to ./model/1428-0.0871.hdf5\n","\n","Epoch 1429: val_loss improved from 0.08714 to 0.08713, saving model to ./model/1429-0.0871.hdf5\n","\n","Epoch 1430: val_loss did not improve from 0.08713\n","\n","Epoch 1431: val_loss did not improve from 0.08713\n","\n","Epoch 1432: val_loss did not improve from 0.08713\n","\n","Epoch 1433: val_loss improved from 0.08713 to 0.08712, saving model to ./model/1433-0.0871.hdf5\n","\n","Epoch 1434: val_loss did not improve from 0.08712\n","\n","Epoch 1435: val_loss did not improve from 0.08712\n","\n","Epoch 1436: val_loss did not improve from 0.08712\n","\n","Epoch 1437: val_loss did not improve from 0.08712\n","\n","Epoch 1438: val_loss improved from 0.08712 to 0.08711, saving model to ./model/1438-0.0871.hdf5\n","\n","Epoch 1439: val_loss did not improve from 0.08711\n","\n","Epoch 1440: val_loss did not improve from 0.08711\n","\n","Epoch 1441: val_loss did not improve from 0.08711\n","\n","Epoch 1442: val_loss did not improve from 0.08711\n","\n","Epoch 1443: val_loss improved from 0.08711 to 0.08706, saving model to ./model/1443-0.0871.hdf5\n","\n","Epoch 1444: val_loss improved from 0.08706 to 0.08705, saving model to ./model/1444-0.0870.hdf5\n","\n","Epoch 1445: val_loss did not improve from 0.08705\n","\n","Epoch 1446: val_loss did not improve from 0.08705\n","\n","Epoch 1447: val_loss did not improve from 0.08705\n","\n","Epoch 1448: val_loss improved from 0.08705 to 0.08705, saving model to ./model/1448-0.0870.hdf5\n","\n","Epoch 1449: val_loss improved from 0.08705 to 0.08703, saving model to ./model/1449-0.0870.hdf5\n","\n","Epoch 1450: val_loss did not improve from 0.08703\n","\n","Epoch 1451: val_loss did not improve from 0.08703\n","\n","Epoch 1452: val_loss improved from 0.08703 to 0.08703, saving model to ./model/1452-0.0870.hdf5\n","\n","Epoch 1453: val_loss improved from 0.08703 to 0.08698, saving model to ./model/1453-0.0870.hdf5\n","\n","Epoch 1454: val_loss improved from 0.08698 to 0.08696, saving model to ./model/1454-0.0870.hdf5\n","\n","Epoch 1455: val_loss did not improve from 0.08696\n","\n","Epoch 1456: val_loss did not improve from 0.08696\n","\n","Epoch 1457: val_loss did not improve from 0.08696\n","\n","Epoch 1458: val_loss did not improve from 0.08696\n","\n","Epoch 1459: val_loss did not improve from 0.08696\n","\n","Epoch 1460: val_loss did not improve from 0.08696\n","\n","Epoch 1461: val_loss did not improve from 0.08696\n","\n","Epoch 1462: val_loss did not improve from 0.08696\n","\n","Epoch 1463: val_loss improved from 0.08696 to 0.08695, saving model to ./model/1463-0.0870.hdf5\n","\n","Epoch 1464: val_loss improved from 0.08695 to 0.08694, saving model to ./model/1464-0.0869.hdf5\n","\n","Epoch 1465: val_loss did not improve from 0.08694\n","\n","Epoch 1466: val_loss did not improve from 0.08694\n","\n","Epoch 1467: val_loss improved from 0.08694 to 0.08693, saving model to ./model/1467-0.0869.hdf5\n","\n","Epoch 1468: val_loss improved from 0.08693 to 0.08692, saving model to ./model/1468-0.0869.hdf5\n","\n","Epoch 1469: val_loss did not improve from 0.08692\n","\n","Epoch 1470: val_loss did not improve from 0.08692\n","\n","Epoch 1471: val_loss improved from 0.08692 to 0.08690, saving model to ./model/1471-0.0869.hdf5\n","\n","Epoch 1472: val_loss improved from 0.08690 to 0.08687, saving model to ./model/1472-0.0869.hdf5\n","\n","Epoch 1473: val_loss did not improve from 0.08687\n","\n","Epoch 1474: val_loss did not improve from 0.08687\n","\n","Epoch 1475: val_loss did not improve from 0.08687\n","\n","Epoch 1476: val_loss did not improve from 0.08687\n","\n","Epoch 1477: val_loss did not improve from 0.08687\n","\n","Epoch 1478: val_loss did not improve from 0.08687\n","\n","Epoch 1479: val_loss did not improve from 0.08687\n","\n","Epoch 1480: val_loss did not improve from 0.08687\n","\n","Epoch 1481: val_loss improved from 0.08687 to 0.08686, saving model to ./model/1481-0.0869.hdf5\n","\n","Epoch 1482: val_loss did not improve from 0.08686\n","\n","Epoch 1483: val_loss did not improve from 0.08686\n","\n","Epoch 1484: val_loss did not improve from 0.08686\n","\n","Epoch 1485: val_loss improved from 0.08686 to 0.08685, saving model to ./model/1485-0.0869.hdf5\n","\n","Epoch 1486: val_loss improved from 0.08685 to 0.08684, saving model to ./model/1486-0.0868.hdf5\n","\n","Epoch 1487: val_loss did not improve from 0.08684\n","\n","Epoch 1488: val_loss did not improve from 0.08684\n","\n","Epoch 1489: val_loss did not improve from 0.08684\n","\n","Epoch 1490: val_loss improved from 0.08684 to 0.08683, saving model to ./model/1490-0.0868.hdf5\n","\n","Epoch 1491: val_loss improved from 0.08683 to 0.08680, saving model to ./model/1491-0.0868.hdf5\n","\n","Epoch 1492: val_loss did not improve from 0.08680\n","\n","Epoch 1493: val_loss did not improve from 0.08680\n","\n","Epoch 1494: val_loss did not improve from 0.08680\n","\n","Epoch 1495: val_loss improved from 0.08680 to 0.08680, saving model to ./model/1495-0.0868.hdf5\n","\n","Epoch 1496: val_loss did not improve from 0.08680\n","\n","Epoch 1497: val_loss did not improve from 0.08680\n","\n","Epoch 1498: val_loss did not improve from 0.08680\n","\n","Epoch 1499: val_loss did not improve from 0.08680\n","\n","Epoch 1500: val_loss did not improve from 0.08680\n","\n","Epoch 1501: val_loss did not improve from 0.08680\n","\n","Epoch 1502: val_loss did not improve from 0.08680\n","\n","Epoch 1503: val_loss did not improve from 0.08680\n","\n","Epoch 1504: val_loss did not improve from 0.08680\n","\n","Epoch 1505: val_loss did not improve from 0.08680\n","\n","Epoch 1506: val_loss did not improve from 0.08680\n","\n","Epoch 1507: val_loss did not improve from 0.08680\n","\n","Epoch 1508: val_loss improved from 0.08680 to 0.08680, saving model to ./model/1508-0.0868.hdf5\n","\n","Epoch 1509: val_loss did not improve from 0.08680\n","\n","Epoch 1510: val_loss did not improve from 0.08680\n","\n","Epoch 1511: val_loss did not improve from 0.08680\n","\n","Epoch 1512: val_loss did not improve from 0.08680\n","\n","Epoch 1513: val_loss improved from 0.08680 to 0.08679, saving model to ./model/1513-0.0868.hdf5\n","\n","Epoch 1514: val_loss improved from 0.08679 to 0.08675, saving model to ./model/1514-0.0867.hdf5\n","\n","Epoch 1515: val_loss did not improve from 0.08675\n","\n","Epoch 1516: val_loss did not improve from 0.08675\n","\n","Epoch 1517: val_loss did not improve from 0.08675\n","\n","Epoch 1518: val_loss did not improve from 0.08675\n","\n","Epoch 1519: val_loss did not improve from 0.08675\n","\n","Epoch 1520: val_loss did not improve from 0.08675\n","\n","Epoch 1521: val_loss did not improve from 0.08675\n","\n","Epoch 1522: val_loss did not improve from 0.08675\n","\n","Epoch 1523: val_loss did not improve from 0.08675\n","\n","Epoch 1524: val_loss did not improve from 0.08675\n","\n","Epoch 1525: val_loss did not improve from 0.08675\n","\n","Epoch 1526: val_loss did not improve from 0.08675\n","\n","Epoch 1527: val_loss did not improve from 0.08675\n","\n","Epoch 1528: val_loss did not improve from 0.08675\n","\n","Epoch 1529: val_loss did not improve from 0.08675\n","\n","Epoch 1530: val_loss did not improve from 0.08675\n","\n","Epoch 1531: val_loss did not improve from 0.08675\n","\n","Epoch 1532: val_loss did not improve from 0.08675\n","\n","Epoch 1533: val_loss did not improve from 0.08675\n","\n","Epoch 1534: val_loss did not improve from 0.08675\n","\n","Epoch 1535: val_loss improved from 0.08675 to 0.08673, saving model to ./model/1535-0.0867.hdf5\n","\n","Epoch 1536: val_loss did not improve from 0.08673\n","\n","Epoch 1537: val_loss did not improve from 0.08673\n","\n","Epoch 1538: val_loss did not improve from 0.08673\n","\n","Epoch 1539: val_loss did not improve from 0.08673\n","\n","Epoch 1540: val_loss did not improve from 0.08673\n","\n","Epoch 1541: val_loss did not improve from 0.08673\n","\n","Epoch 1542: val_loss did not improve from 0.08673\n","\n","Epoch 1543: val_loss did not improve from 0.08673\n","\n","Epoch 1544: val_loss did not improve from 0.08673\n","\n","Epoch 1545: val_loss did not improve from 0.08673\n","\n","Epoch 1546: val_loss did not improve from 0.08673\n","\n","Epoch 1547: val_loss did not improve from 0.08673\n","\n","Epoch 1548: val_loss did not improve from 0.08673\n","\n","Epoch 1549: val_loss did not improve from 0.08673\n","\n","Epoch 1550: val_loss did not improve from 0.08673\n","\n","Epoch 1551: val_loss did not improve from 0.08673\n","\n","Epoch 1552: val_loss did not improve from 0.08673\n","\n","Epoch 1553: val_loss did not improve from 0.08673\n","\n","Epoch 1554: val_loss did not improve from 0.08673\n","\n","Epoch 1555: val_loss did not improve from 0.08673\n","\n","Epoch 1556: val_loss did not improve from 0.08673\n","\n","Epoch 1557: val_loss did not improve from 0.08673\n","\n","Epoch 1558: val_loss did not improve from 0.08673\n","\n","Epoch 1559: val_loss did not improve from 0.08673\n","\n","Epoch 1560: val_loss did not improve from 0.08673\n","\n","Epoch 1561: val_loss improved from 0.08673 to 0.08673, saving model to ./model/1561-0.0867.hdf5\n","\n","Epoch 1562: val_loss did not improve from 0.08673\n","\n","Epoch 1563: val_loss did not improve from 0.08673\n","\n","Epoch 1564: val_loss did not improve from 0.08673\n","\n","Epoch 1565: val_loss did not improve from 0.08673\n","\n","Epoch 1566: val_loss did not improve from 0.08673\n","\n","Epoch 1567: val_loss did not improve from 0.08673\n","\n","Epoch 1568: val_loss did not improve from 0.08673\n","\n","Epoch 1569: val_loss did not improve from 0.08673\n","\n","Epoch 1570: val_loss did not improve from 0.08673\n","\n","Epoch 1571: val_loss did not improve from 0.08673\n","\n","Epoch 1572: val_loss did not improve from 0.08673\n","\n","Epoch 1573: val_loss improved from 0.08673 to 0.08672, saving model to ./model/1573-0.0867.hdf5\n","\n","Epoch 1574: val_loss improved from 0.08672 to 0.08672, saving model to ./model/1574-0.0867.hdf5\n","\n","Epoch 1575: val_loss did not improve from 0.08672\n","\n","Epoch 1576: val_loss did not improve from 0.08672\n","\n","Epoch 1577: val_loss did not improve from 0.08672\n","\n","Epoch 1578: val_loss did not improve from 0.08672\n","\n","Epoch 1579: val_loss did not improve from 0.08672\n","\n","Epoch 1580: val_loss did not improve from 0.08672\n","\n","Epoch 1581: val_loss did not improve from 0.08672\n","\n","Epoch 1582: val_loss improved from 0.08672 to 0.08671, saving model to ./model/1582-0.0867.hdf5\n","\n","Epoch 1583: val_loss did not improve from 0.08671\n","\n","Epoch 1584: val_loss did not improve from 0.08671\n","\n","Epoch 1585: val_loss did not improve from 0.08671\n","\n","Epoch 1586: val_loss did not improve from 0.08671\n","\n","Epoch 1587: val_loss did not improve from 0.08671\n","\n","Epoch 1588: val_loss did not improve from 0.08671\n","\n","Epoch 1589: val_loss did not improve from 0.08671\n","\n","Epoch 1590: val_loss did not improve from 0.08671\n","\n","Epoch 1591: val_loss did not improve from 0.08671\n","\n","Epoch 1592: val_loss did not improve from 0.08671\n","\n","Epoch 1593: val_loss did not improve from 0.08671\n","\n","Epoch 1594: val_loss did not improve from 0.08671\n","\n","Epoch 1595: val_loss did not improve from 0.08671\n","\n","Epoch 1596: val_loss did not improve from 0.08671\n","\n","Epoch 1597: val_loss did not improve from 0.08671\n","\n","Epoch 1598: val_loss improved from 0.08671 to 0.08671, saving model to ./model/1598-0.0867.hdf5\n","\n","Epoch 1599: val_loss did not improve from 0.08671\n","\n","Epoch 1600: val_loss did not improve from 0.08671\n","\n","Epoch 1601: val_loss did not improve from 0.08671\n","\n","Epoch 1602: val_loss did not improve from 0.08671\n","\n","Epoch 1603: val_loss improved from 0.08671 to 0.08670, saving model to ./model/1603-0.0867.hdf5\n","\n","Epoch 1604: val_loss improved from 0.08670 to 0.08669, saving model to ./model/1604-0.0867.hdf5\n","\n","Epoch 1605: val_loss did not improve from 0.08669\n","\n","Epoch 1606: val_loss did not improve from 0.08669\n","\n","Epoch 1607: val_loss did not improve from 0.08669\n","\n","Epoch 1608: val_loss did not improve from 0.08669\n","\n","Epoch 1609: val_loss did not improve from 0.08669\n","\n","Epoch 1610: val_loss did not improve from 0.08669\n","\n","Epoch 1611: val_loss did not improve from 0.08669\n","\n","Epoch 1612: val_loss did not improve from 0.08669\n","\n","Epoch 1613: val_loss did not improve from 0.08669\n","\n","Epoch 1614: val_loss did not improve from 0.08669\n","\n","Epoch 1615: val_loss did not improve from 0.08669\n","\n","Epoch 1616: val_loss did not improve from 0.08669\n","\n","Epoch 1617: val_loss did not improve from 0.08669\n","\n","Epoch 1618: val_loss did not improve from 0.08669\n","\n","Epoch 1619: val_loss improved from 0.08669 to 0.08668, saving model to ./model/1619-0.0867.hdf5\n","\n","Epoch 1620: val_loss improved from 0.08668 to 0.08667, saving model to ./model/1620-0.0867.hdf5\n","\n","Epoch 1621: val_loss did not improve from 0.08667\n","\n","Epoch 1622: val_loss did not improve from 0.08667\n","\n","Epoch 1623: val_loss did not improve from 0.08667\n","\n","Epoch 1624: val_loss did not improve from 0.08667\n","\n","Epoch 1625: val_loss did not improve from 0.08667\n","\n","Epoch 1626: val_loss did not improve from 0.08667\n","\n","Epoch 1627: val_loss did not improve from 0.08667\n","\n","Epoch 1628: val_loss did not improve from 0.08667\n","\n","Epoch 1629: val_loss did not improve from 0.08667\n","\n","Epoch 1630: val_loss did not improve from 0.08667\n","\n","Epoch 1631: val_loss did not improve from 0.08667\n","\n","Epoch 1632: val_loss did not improve from 0.08667\n","\n","Epoch 1633: val_loss did not improve from 0.08667\n","\n","Epoch 1634: val_loss did not improve from 0.08667\n","\n","Epoch 1635: val_loss did not improve from 0.08667\n","\n","Epoch 1636: val_loss did not improve from 0.08667\n","\n","Epoch 1637: val_loss did not improve from 0.08667\n","\n","Epoch 1638: val_loss did not improve from 0.08667\n","\n","Epoch 1639: val_loss did not improve from 0.08667\n","\n","Epoch 1640: val_loss did not improve from 0.08667\n","\n","Epoch 1641: val_loss did not improve from 0.08667\n","\n","Epoch 1642: val_loss did not improve from 0.08667\n","\n","Epoch 1643: val_loss did not improve from 0.08667\n","\n","Epoch 1644: val_loss did not improve from 0.08667\n","\n","Epoch 1645: val_loss did not improve from 0.08667\n","\n","Epoch 1646: val_loss did not improve from 0.08667\n","\n","Epoch 1647: val_loss did not improve from 0.08667\n","\n","Epoch 1648: val_loss did not improve from 0.08667\n","\n","Epoch 1649: val_loss improved from 0.08667 to 0.08666, saving model to ./model/1649-0.0867.hdf5\n","\n","Epoch 1650: val_loss did not improve from 0.08666\n","\n","Epoch 1651: val_loss did not improve from 0.08666\n","\n","Epoch 1652: val_loss did not improve from 0.08666\n","\n","Epoch 1653: val_loss improved from 0.08666 to 0.08666, saving model to ./model/1653-0.0867.hdf5\n","\n","Epoch 1654: val_loss improved from 0.08666 to 0.08666, saving model to ./model/1654-0.0867.hdf5\n","\n","Epoch 1655: val_loss did not improve from 0.08666\n","\n","Epoch 1656: val_loss did not improve from 0.08666\n","\n","Epoch 1657: val_loss did not improve from 0.08666\n","\n","Epoch 1658: val_loss improved from 0.08666 to 0.08663, saving model to ./model/1658-0.0866.hdf5\n","\n","Epoch 1659: val_loss improved from 0.08663 to 0.08661, saving model to ./model/1659-0.0866.hdf5\n","\n","Epoch 1660: val_loss did not improve from 0.08661\n","\n","Epoch 1661: val_loss did not improve from 0.08661\n","\n","Epoch 1662: val_loss did not improve from 0.08661\n","\n","Epoch 1663: val_loss did not improve from 0.08661\n","\n","Epoch 1664: val_loss did not improve from 0.08661\n","\n","Epoch 1665: val_loss did not improve from 0.08661\n","\n","Epoch 1666: val_loss did not improve from 0.08661\n","\n","Epoch 1667: val_loss did not improve from 0.08661\n","\n","Epoch 1668: val_loss did not improve from 0.08661\n","\n","Epoch 1669: val_loss did not improve from 0.08661\n","\n","Epoch 1670: val_loss did not improve from 0.08661\n","\n","Epoch 1671: val_loss did not improve from 0.08661\n","\n","Epoch 1672: val_loss did not improve from 0.08661\n","\n","Epoch 1673: val_loss did not improve from 0.08661\n","\n","Epoch 1674: val_loss did not improve from 0.08661\n","\n","Epoch 1675: val_loss improved from 0.08661 to 0.08660, saving model to ./model/1675-0.0866.hdf5\n","\n","Epoch 1676: val_loss improved from 0.08660 to 0.08656, saving model to ./model/1676-0.0866.hdf5\n","\n","Epoch 1677: val_loss did not improve from 0.08656\n","\n","Epoch 1678: val_loss did not improve from 0.08656\n","\n","Epoch 1679: val_loss did not improve from 0.08656\n","\n","Epoch 1680: val_loss did not improve from 0.08656\n","\n","Epoch 1681: val_loss did not improve from 0.08656\n","\n","Epoch 1682: val_loss did not improve from 0.08656\n","\n","Epoch 1683: val_loss did not improve from 0.08656\n","\n","Epoch 1684: val_loss did not improve from 0.08656\n","\n","Epoch 1685: val_loss did not improve from 0.08656\n","\n","Epoch 1686: val_loss improved from 0.08656 to 0.08655, saving model to ./model/1686-0.0865.hdf5\n","\n","Epoch 1687: val_loss did not improve from 0.08655\n","\n","Epoch 1688: val_loss did not improve from 0.08655\n","\n","Epoch 1689: val_loss did not improve from 0.08655\n","\n","Epoch 1690: val_loss did not improve from 0.08655\n","\n","Epoch 1691: val_loss improved from 0.08655 to 0.08654, saving model to ./model/1691-0.0865.hdf5\n","\n","Epoch 1692: val_loss improved from 0.08654 to 0.08650, saving model to ./model/1692-0.0865.hdf5\n","\n","Epoch 1693: val_loss did not improve from 0.08650\n","\n","Epoch 1694: val_loss did not improve from 0.08650\n","\n","Epoch 1695: val_loss did not improve from 0.08650\n","\n","Epoch 1696: val_loss did not improve from 0.08650\n","\n","Epoch 1697: val_loss did not improve from 0.08650\n","\n","Epoch 1698: val_loss did not improve from 0.08650\n","\n","Epoch 1699: val_loss did not improve from 0.08650\n","\n","Epoch 1700: val_loss did not improve from 0.08650\n","\n","Epoch 1701: val_loss did not improve from 0.08650\n","\n","Epoch 1702: val_loss did not improve from 0.08650\n","\n","Epoch 1703: val_loss did not improve from 0.08650\n","\n","Epoch 1704: val_loss did not improve from 0.08650\n","\n","Epoch 1705: val_loss did not improve from 0.08650\n","\n","Epoch 1706: val_loss did not improve from 0.08650\n","\n","Epoch 1707: val_loss did not improve from 0.08650\n","\n","Epoch 1708: val_loss did not improve from 0.08650\n","\n","Epoch 1709: val_loss did not improve from 0.08650\n","\n","Epoch 1710: val_loss did not improve from 0.08650\n","\n","Epoch 1711: val_loss did not improve from 0.08650\n","\n","Epoch 1712: val_loss did not improve from 0.08650\n","\n","Epoch 1713: val_loss did not improve from 0.08650\n","\n","Epoch 1714: val_loss did not improve from 0.08650\n","\n","Epoch 1715: val_loss did not improve from 0.08650\n","\n","Epoch 1716: val_loss did not improve from 0.08650\n","\n","Epoch 1717: val_loss did not improve from 0.08650\n","\n","Epoch 1718: val_loss did not improve from 0.08650\n","\n","Epoch 1719: val_loss did not improve from 0.08650\n","\n","Epoch 1720: val_loss did not improve from 0.08650\n","\n","Epoch 1721: val_loss improved from 0.08650 to 0.08650, saving model to ./model/1721-0.0865.hdf5\n","\n","Epoch 1722: val_loss improved from 0.08650 to 0.08647, saving model to ./model/1722-0.0865.hdf5\n","\n","Epoch 1723: val_loss did not improve from 0.08647\n","\n","Epoch 1724: val_loss did not improve from 0.08647\n","\n","Epoch 1725: val_loss did not improve from 0.08647\n","\n","Epoch 1726: val_loss did not improve from 0.08647\n","\n","Epoch 1727: val_loss did not improve from 0.08647\n","\n","Epoch 1728: val_loss did not improve from 0.08647\n","\n","Epoch 1729: val_loss did not improve from 0.08647\n","\n","Epoch 1730: val_loss did not improve from 0.08647\n","\n","Epoch 1731: val_loss did not improve from 0.08647\n","\n","Epoch 1732: val_loss did not improve from 0.08647\n","\n","Epoch 1733: val_loss did not improve from 0.08647\n","\n","Epoch 1734: val_loss did not improve from 0.08647\n","\n","Epoch 1735: val_loss did not improve from 0.08647\n","\n","Epoch 1736: val_loss did not improve from 0.08647\n","\n","Epoch 1737: val_loss did not improve from 0.08647\n","\n","Epoch 1738: val_loss did not improve from 0.08647\n","\n","Epoch 1739: val_loss did not improve from 0.08647\n","\n","Epoch 1740: val_loss did not improve from 0.08647\n","\n","Epoch 1741: val_loss did not improve from 0.08647\n","\n","Epoch 1742: val_loss did not improve from 0.08647\n","\n","Epoch 1743: val_loss did not improve from 0.08647\n","\n","Epoch 1744: val_loss did not improve from 0.08647\n","\n","Epoch 1745: val_loss did not improve from 0.08647\n","\n","Epoch 1746: val_loss did not improve from 0.08647\n","\n","Epoch 1747: val_loss did not improve from 0.08647\n","\n","Epoch 1748: val_loss did not improve from 0.08647\n","\n","Epoch 1749: val_loss improved from 0.08647 to 0.08646, saving model to ./model/1749-0.0865.hdf5\n","\n","Epoch 1750: val_loss improved from 0.08646 to 0.08645, saving model to ./model/1750-0.0864.hdf5\n","\n","Epoch 1751: val_loss did not improve from 0.08645\n","\n","Epoch 1752: val_loss did not improve from 0.08645\n","\n","Epoch 1753: val_loss did not improve from 0.08645\n","\n","Epoch 1754: val_loss did not improve from 0.08645\n","\n","Epoch 1755: val_loss did not improve from 0.08645\n","\n","Epoch 1756: val_loss did not improve from 0.08645\n","\n","Epoch 1757: val_loss did not improve from 0.08645\n","\n","Epoch 1758: val_loss did not improve from 0.08645\n","\n","Epoch 1759: val_loss did not improve from 0.08645\n","\n","Epoch 1760: val_loss did not improve from 0.08645\n","\n","Epoch 1761: val_loss did not improve from 0.08645\n","\n","Epoch 1762: val_loss did not improve from 0.08645\n","\n","Epoch 1763: val_loss improved from 0.08645 to 0.08644, saving model to ./model/1763-0.0864.hdf5\n","\n","Epoch 1764: val_loss improved from 0.08644 to 0.08642, saving model to ./model/1764-0.0864.hdf5\n","\n","Epoch 1765: val_loss did not improve from 0.08642\n","\n","Epoch 1766: val_loss did not improve from 0.08642\n","\n","Epoch 1767: val_loss did not improve from 0.08642\n","\n","Epoch 1768: val_loss did not improve from 0.08642\n","\n","Epoch 1769: val_loss improved from 0.08642 to 0.08642, saving model to ./model/1769-0.0864.hdf5\n","\n","Epoch 1770: val_loss improved from 0.08642 to 0.08641, saving model to ./model/1770-0.0864.hdf5\n","\n","Epoch 1771: val_loss did not improve from 0.08641\n","\n","Epoch 1772: val_loss did not improve from 0.08641\n","\n","Epoch 1773: val_loss did not improve from 0.08641\n","\n","Epoch 1774: val_loss did not improve from 0.08641\n","\n","Epoch 1775: val_loss did not improve from 0.08641\n","\n","Epoch 1776: val_loss improved from 0.08641 to 0.08640, saving model to ./model/1776-0.0864.hdf5\n","\n","Epoch 1777: val_loss improved from 0.08640 to 0.08640, saving model to ./model/1777-0.0864.hdf5\n","\n","Epoch 1778: val_loss did not improve from 0.08640\n","\n","Epoch 1779: val_loss did not improve from 0.08640\n","\n","Epoch 1780: val_loss did not improve from 0.08640\n","\n","Epoch 1781: val_loss did not improve from 0.08640\n","\n","Epoch 1782: val_loss improved from 0.08640 to 0.08640, saving model to ./model/1782-0.0864.hdf5\n","\n","Epoch 1783: val_loss improved from 0.08640 to 0.08639, saving model to ./model/1783-0.0864.hdf5\n","\n","Epoch 1784: val_loss did not improve from 0.08639\n","\n","Epoch 1785: val_loss did not improve from 0.08639\n","\n","Epoch 1786: val_loss did not improve from 0.08639\n","\n","Epoch 1787: val_loss did not improve from 0.08639\n","\n","Epoch 1788: val_loss did not improve from 0.08639\n","\n","Epoch 1789: val_loss did not improve from 0.08639\n","\n","Epoch 1790: val_loss did not improve from 0.08639\n","\n","Epoch 1791: val_loss did not improve from 0.08639\n","\n","Epoch 1792: val_loss did not improve from 0.08639\n","\n","Epoch 1793: val_loss did not improve from 0.08639\n","\n","Epoch 1794: val_loss did not improve from 0.08639\n","\n","Epoch 1795: val_loss improved from 0.08639 to 0.08638, saving model to ./model/1795-0.0864.hdf5\n","\n","Epoch 1796: val_loss improved from 0.08638 to 0.08637, saving model to ./model/1796-0.0864.hdf5\n","\n","Epoch 1797: val_loss did not improve from 0.08637\n","\n","Epoch 1798: val_loss did not improve from 0.08637\n","\n","Epoch 1799: val_loss did not improve from 0.08637\n","\n","Epoch 1800: val_loss did not improve from 0.08637\n","\n","Epoch 1801: val_loss did not improve from 0.08637\n","\n","Epoch 1802: val_loss did not improve from 0.08637\n","\n","Epoch 1803: val_loss did not improve from 0.08637\n","\n","Epoch 1804: val_loss did not improve from 0.08637\n","\n","Epoch 1805: val_loss did not improve from 0.08637\n","\n","Epoch 1806: val_loss did not improve from 0.08637\n","\n","Epoch 1807: val_loss did not improve from 0.08637\n","\n","Epoch 1808: val_loss did not improve from 0.08637\n","\n","Epoch 1809: val_loss did not improve from 0.08637\n","\n","Epoch 1810: val_loss did not improve from 0.08637\n","\n","Epoch 1811: val_loss did not improve from 0.08637\n","\n","Epoch 1812: val_loss did not improve from 0.08637\n","\n","Epoch 1813: val_loss did not improve from 0.08637\n","\n","Epoch 1814: val_loss did not improve from 0.08637\n","\n","Epoch 1815: val_loss did not improve from 0.08637\n","\n","Epoch 1816: val_loss improved from 0.08637 to 0.08637, saving model to ./model/1816-0.0864.hdf5\n","\n","Epoch 1817: val_loss did not improve from 0.08637\n","\n","Epoch 1818: val_loss did not improve from 0.08637\n","\n","Epoch 1819: val_loss did not improve from 0.08637\n","\n","Epoch 1820: val_loss did not improve from 0.08637\n","\n","Epoch 1821: val_loss improved from 0.08637 to 0.08637, saving model to ./model/1821-0.0864.hdf5\n","\n","Epoch 1822: val_loss did not improve from 0.08637\n","\n","Epoch 1823: val_loss did not improve from 0.08637\n","\n","Epoch 1824: val_loss did not improve from 0.08637\n","\n","Epoch 1825: val_loss did not improve from 0.08637\n","\n","Epoch 1826: val_loss did not improve from 0.08637\n","\n","Epoch 1827: val_loss did not improve from 0.08637\n","\n","Epoch 1828: val_loss did not improve from 0.08637\n","\n","Epoch 1829: val_loss did not improve from 0.08637\n","\n","Epoch 1830: val_loss did not improve from 0.08637\n","\n","Epoch 1831: val_loss did not improve from 0.08637\n","\n","Epoch 1832: val_loss did not improve from 0.08637\n","\n","Epoch 1833: val_loss did not improve from 0.08637\n","\n","Epoch 1834: val_loss did not improve from 0.08637\n","\n","Epoch 1835: val_loss did not improve from 0.08637\n","\n","Epoch 1836: val_loss improved from 0.08637 to 0.08636, saving model to ./model/1836-0.0864.hdf5\n","\n","Epoch 1837: val_loss did not improve from 0.08636\n","\n","Epoch 1838: val_loss did not improve from 0.08636\n","\n","Epoch 1839: val_loss did not improve from 0.08636\n","\n","Epoch 1840: val_loss did not improve from 0.08636\n","\n","Epoch 1841: val_loss did not improve from 0.08636\n","\n","Epoch 1842: val_loss did not improve from 0.08636\n","\n","Epoch 1843: val_loss did not improve from 0.08636\n","\n","Epoch 1844: val_loss did not improve from 0.08636\n","\n","Epoch 1845: val_loss did not improve from 0.08636\n","\n","Epoch 1846: val_loss did not improve from 0.08636\n","\n","Epoch 1847: val_loss improved from 0.08636 to 0.08635, saving model to ./model/1847-0.0864.hdf5\n","\n","Epoch 1848: val_loss improved from 0.08635 to 0.08633, saving model to ./model/1848-0.0863.hdf5\n","\n","Epoch 1849: val_loss did not improve from 0.08633\n","\n","Epoch 1850: val_loss did not improve from 0.08633\n","\n","Epoch 1851: val_loss did not improve from 0.08633\n","\n","Epoch 1852: val_loss did not improve from 0.08633\n","\n","Epoch 1853: val_loss did not improve from 0.08633\n","\n","Epoch 1854: val_loss did not improve from 0.08633\n","\n","Epoch 1855: val_loss did not improve from 0.08633\n","\n","Epoch 1856: val_loss did not improve from 0.08633\n","\n","Epoch 1857: val_loss did not improve from 0.08633\n","\n","Epoch 1858: val_loss did not improve from 0.08633\n","\n","Epoch 1859: val_loss did not improve from 0.08633\n","\n","Epoch 1860: val_loss did not improve from 0.08633\n","\n","Epoch 1861: val_loss did not improve from 0.08633\n","\n","Epoch 1862: val_loss improved from 0.08633 to 0.08633, saving model to ./model/1862-0.0863.hdf5\n","\n","Epoch 1863: val_loss did not improve from 0.08633\n","\n","Epoch 1864: val_loss did not improve from 0.08633\n","\n","Epoch 1865: val_loss did not improve from 0.08633\n","\n","Epoch 1866: val_loss did not improve from 0.08633\n","\n","Epoch 1867: val_loss improved from 0.08633 to 0.08633, saving model to ./model/1867-0.0863.hdf5\n","\n","Epoch 1868: val_loss did not improve from 0.08633\n","\n","Epoch 1869: val_loss did not improve from 0.08633\n","\n","Epoch 1870: val_loss did not improve from 0.08633\n","\n","Epoch 1871: val_loss did not improve from 0.08633\n","\n","Epoch 1872: val_loss did not improve from 0.08633\n","\n","Epoch 1873: val_loss did not improve from 0.08633\n","\n","Epoch 1874: val_loss did not improve from 0.08633\n","\n","Epoch 1875: val_loss did not improve from 0.08633\n","\n","Epoch 1876: val_loss did not improve from 0.08633\n","\n","Epoch 1877: val_loss did not improve from 0.08633\n","\n","Epoch 1878: val_loss did not improve from 0.08633\n","\n","Epoch 1879: val_loss did not improve from 0.08633\n","\n","Epoch 1880: val_loss did not improve from 0.08633\n","\n","Epoch 1881: val_loss did not improve from 0.08633\n","\n","Epoch 1882: val_loss did not improve from 0.08633\n","\n","Epoch 1883: val_loss did not improve from 0.08633\n","\n","Epoch 1884: val_loss did not improve from 0.08633\n","\n","Epoch 1885: val_loss did not improve from 0.08633\n","\n","Epoch 1886: val_loss improved from 0.08633 to 0.08632, saving model to ./model/1886-0.0863.hdf5\n","\n","Epoch 1887: val_loss did not improve from 0.08632\n","\n","Epoch 1888: val_loss did not improve from 0.08632\n","\n","Epoch 1889: val_loss did not improve from 0.08632\n","\n","Epoch 1890: val_loss did not improve from 0.08632\n","\n","Epoch 1891: val_loss did not improve from 0.08632\n","\n","Epoch 1892: val_loss did not improve from 0.08632\n","\n","Epoch 1893: val_loss did not improve from 0.08632\n","\n","Epoch 1894: val_loss did not improve from 0.08632\n","\n","Epoch 1895: val_loss did not improve from 0.08632\n","\n","Epoch 1896: val_loss did not improve from 0.08632\n","\n","Epoch 1897: val_loss did not improve from 0.08632\n","\n","Epoch 1898: val_loss did not improve from 0.08632\n","\n","Epoch 1899: val_loss did not improve from 0.08632\n","\n","Epoch 1900: val_loss did not improve from 0.08632\n","\n","Epoch 1901: val_loss did not improve from 0.08632\n","\n","Epoch 1902: val_loss did not improve from 0.08632\n","\n","Epoch 1903: val_loss did not improve from 0.08632\n","\n","Epoch 1904: val_loss did not improve from 0.08632\n","\n","Epoch 1905: val_loss improved from 0.08632 to 0.08632, saving model to ./model/1905-0.0863.hdf5\n","\n","Epoch 1906: val_loss improved from 0.08632 to 0.08631, saving model to ./model/1906-0.0863.hdf5\n","\n","Epoch 1907: val_loss did not improve from 0.08631\n","\n","Epoch 1908: val_loss did not improve from 0.08631\n","\n","Epoch 1909: val_loss did not improve from 0.08631\n","\n","Epoch 1910: val_loss did not improve from 0.08631\n","\n","Epoch 1911: val_loss did not improve from 0.08631\n","\n","Epoch 1912: val_loss did not improve from 0.08631\n","\n","Epoch 1913: val_loss did not improve from 0.08631\n","\n","Epoch 1914: val_loss did not improve from 0.08631\n","\n","Epoch 1915: val_loss did not improve from 0.08631\n","\n","Epoch 1916: val_loss did not improve from 0.08631\n","\n","Epoch 1917: val_loss did not improve from 0.08631\n","\n","Epoch 1918: val_loss did not improve from 0.08631\n","\n","Epoch 1919: val_loss did not improve from 0.08631\n","\n","Epoch 1920: val_loss did not improve from 0.08631\n","\n","Epoch 1921: val_loss improved from 0.08631 to 0.08630, saving model to ./model/1921-0.0863.hdf5\n","\n","Epoch 1922: val_loss did not improve from 0.08630\n","\n","Epoch 1923: val_loss did not improve from 0.08630\n","\n","Epoch 1924: val_loss did not improve from 0.08630\n","\n","Epoch 1925: val_loss did not improve from 0.08630\n","\n","Epoch 1926: val_loss did not improve from 0.08630\n","\n","Epoch 1927: val_loss did not improve from 0.08630\n","\n","Epoch 1928: val_loss did not improve from 0.08630\n","\n","Epoch 1929: val_loss did not improve from 0.08630\n","\n","Epoch 1930: val_loss did not improve from 0.08630\n","\n","Epoch 1931: val_loss did not improve from 0.08630\n","\n","Epoch 1932: val_loss did not improve from 0.08630\n","\n","Epoch 1933: val_loss did not improve from 0.08630\n","\n","Epoch 1934: val_loss did not improve from 0.08630\n","\n","Epoch 1935: val_loss did not improve from 0.08630\n","\n","Epoch 1936: val_loss did not improve from 0.08630\n","\n","Epoch 1937: val_loss did not improve from 0.08630\n","\n","Epoch 1938: val_loss did not improve from 0.08630\n","\n","Epoch 1939: val_loss did not improve from 0.08630\n","\n","Epoch 1940: val_loss did not improve from 0.08630\n","\n","Epoch 1941: val_loss did not improve from 0.08630\n","\n","Epoch 1942: val_loss did not improve from 0.08630\n","\n","Epoch 1943: val_loss did not improve from 0.08630\n","\n","Epoch 1944: val_loss improved from 0.08630 to 0.08628, saving model to ./model/1944-0.0863.hdf5\n","\n","Epoch 1945: val_loss did not improve from 0.08628\n","\n","Epoch 1946: val_loss did not improve from 0.08628\n","\n","Epoch 1947: val_loss did not improve from 0.08628\n","\n","Epoch 1948: val_loss did not improve from 0.08628\n","\n","Epoch 1949: val_loss did not improve from 0.08628\n","\n","Epoch 1950: val_loss did not improve from 0.08628\n","\n","Epoch 1951: val_loss did not improve from 0.08628\n","\n","Epoch 1952: val_loss did not improve from 0.08628\n","\n","Epoch 1953: val_loss did not improve from 0.08628\n","\n","Epoch 1954: val_loss did not improve from 0.08628\n","\n","Epoch 1955: val_loss did not improve from 0.08628\n","\n","Epoch 1956: val_loss did not improve from 0.08628\n","\n","Epoch 1957: val_loss did not improve from 0.08628\n","\n","Epoch 1958: val_loss did not improve from 0.08628\n","\n","Epoch 1959: val_loss did not improve from 0.08628\n","\n","Epoch 1960: val_loss did not improve from 0.08628\n","\n","Epoch 1961: val_loss did not improve from 0.08628\n","\n","Epoch 1962: val_loss did not improve from 0.08628\n","\n","Epoch 1963: val_loss did not improve from 0.08628\n","\n","Epoch 1964: val_loss did not improve from 0.08628\n","\n","Epoch 1965: val_loss did not improve from 0.08628\n","\n","Epoch 1966: val_loss did not improve from 0.08628\n","\n","Epoch 1967: val_loss did not improve from 0.08628\n","\n","Epoch 1968: val_loss did not improve from 0.08628\n","\n","Epoch 1969: val_loss did not improve from 0.08628\n","\n","Epoch 1970: val_loss improved from 0.08628 to 0.08627, saving model to ./model/1970-0.0863.hdf5\n","\n","Epoch 1971: val_loss improved from 0.08627 to 0.08625, saving model to ./model/1971-0.0863.hdf5\n","\n","Epoch 1972: val_loss did not improve from 0.08625\n","\n","Epoch 1973: val_loss did not improve from 0.08625\n","\n","Epoch 1974: val_loss did not improve from 0.08625\n","\n","Epoch 1975: val_loss did not improve from 0.08625\n","\n","Epoch 1976: val_loss did not improve from 0.08625\n","\n","Epoch 1977: val_loss did not improve from 0.08625\n","\n","Epoch 1978: val_loss did not improve from 0.08625\n","\n","Epoch 1979: val_loss did not improve from 0.08625\n","\n","Epoch 1980: val_loss did not improve from 0.08625\n","\n","Epoch 1981: val_loss did not improve from 0.08625\n","\n","Epoch 1982: val_loss did not improve from 0.08625\n","\n","Epoch 1983: val_loss did not improve from 0.08625\n","\n","Epoch 1984: val_loss did not improve from 0.08625\n","\n","Epoch 1985: val_loss did not improve from 0.08625\n","\n","Epoch 1986: val_loss did not improve from 0.08625\n","\n","Epoch 1987: val_loss did not improve from 0.08625\n","\n","Epoch 1988: val_loss did not improve from 0.08625\n","\n","Epoch 1989: val_loss did not improve from 0.08625\n","\n","Epoch 1990: val_loss did not improve from 0.08625\n","\n","Epoch 1991: val_loss did not improve from 0.08625\n","\n","Epoch 1992: val_loss did not improve from 0.08625\n","\n","Epoch 1993: val_loss did not improve from 0.08625\n","\n","Epoch 1994: val_loss did not improve from 0.08625\n","\n","Epoch 1995: val_loss did not improve from 0.08625\n","\n","Epoch 1996: val_loss did not improve from 0.08625\n","\n","Epoch 1997: val_loss did not improve from 0.08625\n","\n","Epoch 1998: val_loss did not improve from 0.08625\n","\n","Epoch 1999: val_loss did not improve from 0.08625\n","\n","Epoch 2000: val_loss did not improve from 0.08625\n","\n","Epoch 2001: val_loss did not improve from 0.08625\n","\n","Epoch 2002: val_loss did not improve from 0.08625\n","\n","Epoch 2003: val_loss did not improve from 0.08625\n","\n","Epoch 2004: val_loss did not improve from 0.08625\n","\n","Epoch 2005: val_loss did not improve from 0.08625\n","\n","Epoch 2006: val_loss did not improve from 0.08625\n","\n","Epoch 2007: val_loss did not improve from 0.08625\n","\n","Epoch 2008: val_loss did not improve from 0.08625\n","\n","Epoch 2009: val_loss did not improve from 0.08625\n","\n","Epoch 2010: val_loss did not improve from 0.08625\n","\n","Epoch 2011: val_loss did not improve from 0.08625\n","\n","Epoch 2012: val_loss did not improve from 0.08625\n","\n","Epoch 2013: val_loss did not improve from 0.08625\n","\n","Epoch 2014: val_loss did not improve from 0.08625\n","\n","Epoch 2015: val_loss did not improve from 0.08625\n","\n","Epoch 2016: val_loss did not improve from 0.08625\n","\n","Epoch 2017: val_loss did not improve from 0.08625\n","\n","Epoch 2018: val_loss did not improve from 0.08625\n","\n","Epoch 2019: val_loss did not improve from 0.08625\n","\n","Epoch 2020: val_loss did not improve from 0.08625\n","\n","Epoch 2021: val_loss did not improve from 0.08625\n","\n","Epoch 2022: val_loss did not improve from 0.08625\n","\n","Epoch 2023: val_loss did not improve from 0.08625\n","\n","Epoch 2024: val_loss did not improve from 0.08625\n","\n","Epoch 2025: val_loss did not improve from 0.08625\n","\n","Epoch 2026: val_loss did not improve from 0.08625\n","\n","Epoch 2027: val_loss did not improve from 0.08625\n","\n","Epoch 2028: val_loss did not improve from 0.08625\n","\n","Epoch 2029: val_loss did not improve from 0.08625\n","\n","Epoch 2030: val_loss did not improve from 0.08625\n","\n","Epoch 2031: val_loss did not improve from 0.08625\n","\n","Epoch 2032: val_loss did not improve from 0.08625\n","\n","Epoch 2033: val_loss did not improve from 0.08625\n","\n","Epoch 2034: val_loss did not improve from 0.08625\n","\n","Epoch 2035: val_loss did not improve from 0.08625\n","\n","Epoch 2036: val_loss did not improve from 0.08625\n","\n","Epoch 2037: val_loss did not improve from 0.08625\n","\n","Epoch 2038: val_loss did not improve from 0.08625\n","\n","Epoch 2039: val_loss did not improve from 0.08625\n","\n","Epoch 2040: val_loss did not improve from 0.08625\n","\n","Epoch 2041: val_loss did not improve from 0.08625\n","\n","Epoch 2042: val_loss did not improve from 0.08625\n","\n","Epoch 2043: val_loss did not improve from 0.08625\n","\n","Epoch 2044: val_loss did not improve from 0.08625\n","\n","Epoch 2045: val_loss did not improve from 0.08625\n","\n","Epoch 2046: val_loss did not improve from 0.08625\n","\n","Epoch 2047: val_loss did not improve from 0.08625\n","\n","Epoch 2048: val_loss did not improve from 0.08625\n","\n","Epoch 2049: val_loss did not improve from 0.08625\n","\n","Epoch 2050: val_loss did not improve from 0.08625\n","\n","Epoch 2051: val_loss did not improve from 0.08625\n","\n","Epoch 2052: val_loss did not improve from 0.08625\n","\n","Epoch 2053: val_loss did not improve from 0.08625\n","\n","Epoch 2054: val_loss did not improve from 0.08625\n","\n","Epoch 2055: val_loss did not improve from 0.08625\n","\n","Epoch 2056: val_loss did not improve from 0.08625\n","\n","Epoch 2057: val_loss did not improve from 0.08625\n","\n","Epoch 2058: val_loss did not improve from 0.08625\n","\n","Epoch 2059: val_loss did not improve from 0.08625\n","\n","Epoch 2060: val_loss did not improve from 0.08625\n","\n","Epoch 2061: val_loss improved from 0.08625 to 0.08624, saving model to ./model/2061-0.0862.hdf5\n","\n","Epoch 2062: val_loss did not improve from 0.08624\n","\n","Epoch 2063: val_loss did not improve from 0.08624\n","\n","Epoch 2064: val_loss did not improve from 0.08624\n","\n","Epoch 2065: val_loss did not improve from 0.08624\n","\n","Epoch 2066: val_loss did not improve from 0.08624\n","\n","Epoch 2067: val_loss did not improve from 0.08624\n","\n","Epoch 2068: val_loss did not improve from 0.08624\n","\n","Epoch 2069: val_loss did not improve from 0.08624\n","\n","Epoch 2070: val_loss did not improve from 0.08624\n","\n","Epoch 2071: val_loss did not improve from 0.08624\n","\n","Epoch 2072: val_loss did not improve from 0.08624\n","\n","Epoch 2073: val_loss did not improve from 0.08624\n","\n","Epoch 2074: val_loss did not improve from 0.08624\n","\n","Epoch 2075: val_loss did not improve from 0.08624\n","\n","Epoch 2076: val_loss did not improve from 0.08624\n","\n","Epoch 2077: val_loss did not improve from 0.08624\n","\n","Epoch 2078: val_loss did not improve from 0.08624\n","\n","Epoch 2079: val_loss did not improve from 0.08624\n","\n","Epoch 2080: val_loss did not improve from 0.08624\n","\n","Epoch 2081: val_loss did not improve from 0.08624\n","\n","Epoch 2082: val_loss did not improve from 0.08624\n","\n","Epoch 2083: val_loss did not improve from 0.08624\n","\n","Epoch 2084: val_loss did not improve from 0.08624\n","\n","Epoch 2085: val_loss did not improve from 0.08624\n","\n","Epoch 2086: val_loss did not improve from 0.08624\n","\n","Epoch 2087: val_loss did not improve from 0.08624\n","\n","Epoch 2088: val_loss did not improve from 0.08624\n","\n","Epoch 2089: val_loss did not improve from 0.08624\n","\n","Epoch 2090: val_loss did not improve from 0.08624\n","\n","Epoch 2091: val_loss did not improve from 0.08624\n","\n","Epoch 2092: val_loss did not improve from 0.08624\n","\n","Epoch 2093: val_loss did not improve from 0.08624\n","\n","Epoch 2094: val_loss did not improve from 0.08624\n","\n","Epoch 2095: val_loss did not improve from 0.08624\n","\n","Epoch 2096: val_loss did not improve from 0.08624\n","\n","Epoch 2097: val_loss did not improve from 0.08624\n","\n","Epoch 2098: val_loss did not improve from 0.08624\n","\n","Epoch 2099: val_loss did not improve from 0.08624\n","\n","Epoch 2100: val_loss did not improve from 0.08624\n","\n","Epoch 2101: val_loss did not improve from 0.08624\n","\n","Epoch 2102: val_loss did not improve from 0.08624\n","\n","Epoch 2103: val_loss did not improve from 0.08624\n","\n","Epoch 2104: val_loss did not improve from 0.08624\n","\n","Epoch 2105: val_loss did not improve from 0.08624\n","\n","Epoch 2106: val_loss did not improve from 0.08624\n","\n","Epoch 2107: val_loss did not improve from 0.08624\n","\n","Epoch 2108: val_loss did not improve from 0.08624\n","\n","Epoch 2109: val_loss did not improve from 0.08624\n","\n","Epoch 2110: val_loss did not improve from 0.08624\n","\n","Epoch 2111: val_loss did not improve from 0.08624\n","\n","Epoch 2112: val_loss did not improve from 0.08624\n","\n","Epoch 2113: val_loss did not improve from 0.08624\n","\n","Epoch 2114: val_loss did not improve from 0.08624\n","\n","Epoch 2115: val_loss did not improve from 0.08624\n","\n","Epoch 2116: val_loss did not improve from 0.08624\n","\n","Epoch 2117: val_loss did not improve from 0.08624\n","\n","Epoch 2118: val_loss did not improve from 0.08624\n","\n","Epoch 2119: val_loss did not improve from 0.08624\n","\n","Epoch 2120: val_loss did not improve from 0.08624\n","\n","Epoch 2121: val_loss did not improve from 0.08624\n","\n","Epoch 2122: val_loss did not improve from 0.08624\n","\n","Epoch 2123: val_loss did not improve from 0.08624\n","\n","Epoch 2124: val_loss did not improve from 0.08624\n","\n","Epoch 2125: val_loss did not improve from 0.08624\n","\n","Epoch 2126: val_loss did not improve from 0.08624\n","\n","Epoch 2127: val_loss did not improve from 0.08624\n","\n","Epoch 2128: val_loss did not improve from 0.08624\n","\n","Epoch 2129: val_loss did not improve from 0.08624\n","\n","Epoch 2130: val_loss did not improve from 0.08624\n","\n","Epoch 2131: val_loss did not improve from 0.08624\n","\n","Epoch 2132: val_loss did not improve from 0.08624\n","\n","Epoch 2133: val_loss did not improve from 0.08624\n","\n","Epoch 2134: val_loss did not improve from 0.08624\n","\n","Epoch 2135: val_loss did not improve from 0.08624\n","\n","Epoch 2136: val_loss did not improve from 0.08624\n","\n","Epoch 2137: val_loss did not improve from 0.08624\n","\n","Epoch 2138: val_loss did not improve from 0.08624\n","\n","Epoch 2139: val_loss did not improve from 0.08624\n","\n","Epoch 2140: val_loss did not improve from 0.08624\n","\n","Epoch 2141: val_loss did not improve from 0.08624\n","\n","Epoch 2142: val_loss did not improve from 0.08624\n","\n","Epoch 2143: val_loss did not improve from 0.08624\n","\n","Epoch 2144: val_loss did not improve from 0.08624\n","\n","Epoch 2145: val_loss did not improve from 0.08624\n","\n","Epoch 2146: val_loss did not improve from 0.08624\n","\n","Epoch 2147: val_loss did not improve from 0.08624\n","\n","Epoch 2148: val_loss did not improve from 0.08624\n","\n","Epoch 2149: val_loss did not improve from 0.08624\n","\n","Epoch 2150: val_loss did not improve from 0.08624\n","\n","Epoch 2151: val_loss did not improve from 0.08624\n","\n","Epoch 2152: val_loss did not improve from 0.08624\n","\n","Epoch 2153: val_loss did not improve from 0.08624\n","\n","Epoch 2154: val_loss did not improve from 0.08624\n","\n","Epoch 2155: val_loss did not improve from 0.08624\n","\n","Epoch 2156: val_loss did not improve from 0.08624\n","\n","Epoch 2157: val_loss did not improve from 0.08624\n","\n","Epoch 2158: val_loss did not improve from 0.08624\n","\n","Epoch 2159: val_loss did not improve from 0.08624\n","\n","Epoch 2160: val_loss did not improve from 0.08624\n","\n","Epoch 2161: val_loss did not improve from 0.08624\n"]},{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7afdaa3335e0>]"]},"metadata":{},"execution_count":29},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import pandas as pd\n","import numpy\n","import tensorflow as tf\n","import os\n","import matplotlib.pyplot as plt\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","\n","# seed 값 설정\n","seed = 0\n","numpy.random.seed(seed)\n","tf.random.set_seed(3)\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/080228-master/deeplearning/dataset/sonar.csv\", header=None)\n","dataset = df.values # 벡터로 변환\n","X = dataset[:, 0:60].astype(float)\n","Y_obj = dataset[:, 60]\n","\n","e = LabelEncoder()\n","e.fit(Y_obj)\n","Y = e.transform(Y_obj)\n","\n","# 학습셋과 테스트셋의 구분\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n","\n","model = Sequential()\n","model.add(Dense(24, input_dim=60, activation='relu'))\n","model.add(Dense(10, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","\n","# 모델 저장 폴더 설정\n","MODEL_DIR = \"./model\"\n","if not os.path.exists(MODEL_DIR):\n","  os.mkdir(MODEL_DIR)\n","\n","# 모델 저장 조건 설정\n","modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n","checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True) # val_loss = 테스트셋 오차\n","\n","# 학습 자동 중단 설정\n","early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)\n","\n","# 모델 실행\n","history = model.fit(X_train, Y_train, validation_split=0.1, epochs=3500, batch_size=500, verbose=0,\n","                    callbacks=[early_stopping_callback, checkpointer])\n","\n","# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n","y_vloss = history.history['val_loss']\n","\n","# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n","y_acc = history.history['accuracy']\n","\n","# 테스트셋으로 실험 결과의 정확도 값을 저장\n","y_vacc = history.history['val_accuracy']\n","\n","# x 값을 지정하고 학습셋 정확도를 파란색, 테스트셋 오차를 빨간색, 테스트셋 정확도를 노란색으로 표시\n","x_len = numpy.arange(len(y_acc))\n","plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n","plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n","plt.plot(x_len, y_vacc, \"o\", c=\"yellow\", markersize=3)"]}]}